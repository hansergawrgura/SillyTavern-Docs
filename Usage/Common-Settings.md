---  

order: 160  
icon: sliders  
---  

# ⚙️ 通用设置  

此处设置控制使用语言模型生成文本时的采样过程。这些设置的含义对所有支持的**后端**是通用的。  

## 📖 上下文设置  

### 生成长度（词元数）  

API 生成响应所使用的**最大词元数**。  

- 生成长度越高，生成响应所需时间越长。  
- 如果 API 支持，可启用 `流式传输`，以便在响应生成过程中逐段显示。  
- 关闭 `流式传输` 后，响应将在完成后一次性显示。  

### 上下文长度（词元数）  

SillyTavern 作为提示词发送给 API 的**最大词元数**（需减去响应长度）。  

- 上下文包含角色信息、系统提示、聊天历史等。  
- 消息之间的虚线表示聊天的上下文范围，该线上方的消息不会发送给 AI。  
- 生成消息后，点击 `提示词分解` 消息选项（展开 `...` 菜单并点击带线方框图标）可查看上下文的组成。  

## 🎛️ 采样器参数  

### 温度 (Temperature)  

控制词元选择的随机性：  

- **低温度** (<1.0) 生成更可预测的文本，偏向高概率词元。  
- **高温度** (>1.0) 通过增加低概率词元的选择机会，提升输出的创造性和多样性。  

设置为 **1** 可使用原始概率。  

### 重复惩罚 (Repetition Penalty)  

通过根据词元在上下文中出现的频率进行惩罚，以**抑制重复**。  

设置为 **1** 可禁用此效果。  

#### 重复惩罚范围 (Repetition Penalty Range)  

考虑重复惩罚的、从最后一个生成词元算起的词元数量。设置过高会破坏响应，因为常见词（如 “the”、“a”、“and” 等）将受到最大惩罚。  

设置为 **0** 可禁用此效果。  

#### 重复惩罚斜率 (Repetition Penalty Slope)  

如果此项和 `重复惩罚范围` 均大于 0，则重复惩罚在提示词末尾的效果更强。值越高，效果越强。  

设置为 **0** 可禁用此效果。  

### 前 K 采样 (Top K)  

设置可供选择的最大顶级词元数量。例如，如果 Top K 为 20，则意味着只保留排名最高的 20 个词元（无论其概率分布广泛还是有限）。  

设置为 **0**（或根据后端设置为 -1）可禁用。  

### 前 P 采样 (Top P)  

前 P 采样（又称核采样）累加顶级词元，直至达到目标百分比。如果前 2 个词元概率均为 25%，且 Top P 为 0.50，则仅考虑前 2 个词元。  

设置为 **1** 可禁用此效果。  

### 典型 P 采样 (Typical P)  

根据词元与集合平均熵的偏差来优先选择词元。它保留累积概率接近预定义阈值（例如 0.5）的词元，强调那些具有平均信息量的词元。  

设置为 **1** 可禁用此效果。  

### 最小 P 采样 (Min P)  

通过剔除与顶级词元相比概率较低的词元来限制词元池。可生成更连贯的响应，但设置过高也可能加剧重复。  

- 在较低值（如 `0.1-0.01`）下效果最佳，但也可与高 `温度` 配合设置更高值。例如：`温度: 5, 最小 P: 0.5`  

设置为 **0** 可禁用此效果。  

### 前 A 采样 (Top A)  

根据最高词元概率的平方设置词元选择阈值。例如，如果 Top-A 值为 0.2，且顶级词元概率为 50%，则概率低于 5% (0.2 * 0.5^2) 的词元将被排除。  

设置为 **0** 可禁用此效果。  

### 无尾采样 (Tail Free Sampling, TFS)  

通过使用导数分析词元概率的变化率，搜索分布中的低概率词元尾。它根据归一化二阶导数保留达到阈值（例如 0.3）的词元。越接近 0，丢弃的词元越多。  

设置为 **1** 可禁用此效果。  

### 平滑因子 (Smoothing Factor)  

使用二次变换增加高概率词元的可能性，同时降低低概率词元的可能性。旨在无论 `温度` 如何，都能产生更具创造性的响应。  

- 不与截断采样器（如 `Top K`、`Top P`、`Min P` 等）一起使用时效果最佳。  

设置为 **0** 可禁用此效果。  

### 动态温度 (Dynamic Temperature)  

根据顶级词元的可能性动态调整温度。旨在不牺牲连贯性的前提下产生更具创造性的输出。  

- 接受从最小到最大的温度范围。例如：`最小温度: 0.75` 和 `最大温度: 1.25`  
- `指数` 根据顶级词元应用指数曲线。  

取消勾选可禁用此效果。  

### Epsilon 截断 (Epsilon Cutoff)  

设置一个概率下限，低于该值的词元将被排除在采样之外。单位为 1e-4；合理值为 3。  

设置为 **0** 可禁用。  

### Eta 截断 (Eta Cutoff)  

特殊 Eta 采样技术的主要参数。单位为 1e-4；合理值为 3。详情参见论文 [Truncation Sampling as Language Model Desmoothing by Hewitt et al. (2022)](https://arxiv.org/abs/2210.15191)。  

设置为 **0** 可禁用。  

### DRY 重复惩罚 (DRY Repetition Penalty)  

DRY 会惩罚那些将输入末尾扩展为输入中先前出现过的序列的词元。如果您想允许逐字重复某些序列（例如名称），可以将其添加到序列中断器列表中。参见 Pull Request [此处](https://github.com/oobabooga/text-generation-webui/pull/5677)。  

将乘数设置为 **0** 可禁用。  

### 排除顶级选择 (Exclude Top Choices, XTC)  

XTC 采样算法移除最可能的词元而非修剪最不可能的词元。它以给定概率移除除符合给定阈值的最不可能词元之外的所有词元。这确保了至少有一个“可行”选择保留，从而保持连贯性。参见 Pull Request [此处](https://github.com/oobabooga/text-generation-webui/pull/6335)。  

将概率设置为 **0** 可禁用。  

### Mirostat  

Mirostat 将输出复杂度与输入匹配，从而避免重复陷阱（自回归推理生成文本时，输出复杂度趋于零）和混淆陷阱（复杂度发散）。详情参见论文 [Mirostat: A Neural Text Decoding Algorithm that Directly Controls Perplexity by Basu et al. (2020)](https://arxiv.org/abs/2007.14966)。  

模式选择 Mirostat 版本。  

- 0 = 禁用，  
- 1 = Mirostat 1.0（仅限 llama.cpp），  
- 2 = Mirostat 2.0。  

### 束搜索 (Beam Search)  

一种用于 LLM 采样的贪婪暴力算法，用于查找最可能的单词或词元序列。它同时扩展多个候选序列，并在每一步保留固定数量（束宽）的顶级序列。  

### Top nsigma  

一种基于统计特性过滤逻辑值的采样方法。它保留最大逻辑值 n 个标准偏差范围内的词元，提供了一种更简单的 top-p/top-k 采样替代方案，同时在不同温度下保持采样稳定性。