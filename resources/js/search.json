[[{"l":"什么是 SillyTavern？ \uD83E\uDD16","p":["SillyTavern - 面向高阶用户的LLM前端界面","SillyTavern（简称 ST）是一款本地安装的用户界面，可让您与文本生成大语言模型（LLM）、图像生成引擎及 TTS 语音模型互动。我们的目标是为用户提供强大的功能和对 LLM 提示词的极致控制，将陡峭的学习曲线视为乐趣的一部分。","SillyTavern 是由热情的 LLM 爱好者社区倾心打造的项目，永远免费开源。自 2023 年 2 月从 TavernAI 1.2.8 分叉而来，SillyTavern 现已汇聚 200 多位贡献者，历经 2 年独立开发，持续为资深 AI 爱好者提供领先软件体验。"]},{"l":"界面预览 \uD83D\uDDBC️","p":["API 连接","聊天界面","高级格式化","世界背景设定"]},{"l":"安装要求 ⚙️","p":["硬件要求极低：可运行 NodeJS 18 及以上版本的设备皆可。若需本地运行 LLM 推理，推荐使用显存至少 6GB 的英伟达 3000 系列显卡。","按平台查看安装指南：","Windows\uD83E\uDE9F","Linux 和 Mac\uD83D\uDC27\uD83C\uDF4E","Android\uD83E\uDD16","Docker\uD83D\uDC33"]},{"l":"分支说明 \uD83C\uDF3F","p":["SillyTavern 采用双分支开发模式，确保所有用户获得流畅体验。","release- \uD83C\uDF1F 推荐大多数用户使用。 最稳定的推荐分支，仅在有重大发布时更新。适合绝大多数用户。通常每月更新一次。","staging- ⚠️ 不推荐日常使用。 此分支包含最新功能，但请注意它可能随时出现故障。仅面向高阶用户和爱好者。每日更新数次。"]},{"l":"还需准备什么？ \uD83D\uDD0C","p":["SillyTavern 仅是一个界面，您需要接入一个 LLM 后端来提供推理能力。您可使用 AI Horde 实现开箱即用的聊天体验。此外，我们还支持许多其他本地及云端 LLM 后端：OpenAI 兼容 API、KoboldAI、Tabby 等。更多支持的 API 请参阅 API 连接 章节。"]},{"l":"角色卡片 \uD83C\uDCCF","p":["SillyTavern 围绕“角色卡片”概念构建。角色卡片是一组设定 LLM 行为的提示词集合，是在 SillyTavern 中进行持续性对话所必需的。其功能类似于 ChatGPT 的 GPTs 或 Poe 的 bots。角色卡片的内容可以是任何事物：抽象场景、为特定任务定制的助手、名人或虚构角色。","若想快速对话而无需选择角色卡片，或仅测试 LLM 连接，只需在打开 SillyTavern 后的 欢迎屏幕 上的输入栏中输入您的提示词。这将创建一个空的“助手”角色卡片，您之后可进行自定义。","要了解如何定义角色卡片，可参考默认角色 (Seraphina) 或从“下载扩展与资源”菜单中获取精选的社区制作卡片。","您也可以从头创建自己的角色卡片。更多信息请参阅 角色设计 指南。"]},{"l":"核心特性 ✨","p":["高级 文本生成设置，包含众多社区制作的预设","世界背景信息支持：创建丰富的背景故事或为角色卡片节省 Token","群聊功能：多机器人房间，让角色与您和/或彼此交谈","丰富的 UI 自定义选项：主题颜色、背景图像、自定义 CSS 等","用户人设：让 AI 了解您的一些信息以增强沉浸感","内置 RAG 支持：向聊天中添加文档供 AI 参考","广泛的 聊天命令 子系统及自有 脚本引擎"]},{"l":"扩展功能 \uD83D\uDD0C","p":["SillyTavern 支持功能扩展。","角色情绪表情（立绘）","聊天历史自动摘要","自动 UI 及 聊天翻译","Stable Diffusion/FLUX/DALL-E 图像生成","AI 回复消息的文本转语音（通过 ElevenLabs、Silero 或操作系统系统 TTS）","网络搜索功能，为您的提示词添加额外真实世界上下文","更多扩展可从“下载扩展与资源”菜单中获取。"]},{"l":"如何直接联系开发者？ \uD83D\uDCDE","p":["Discord: cohee, rossascends, wolfsblvt","Reddit: /u/RossAscends, /u/sillylossy, u/Wolfsblvt","提交 GitHub Issue"]},{"l":"我喜欢你们的项目！如何贡献？ \uD83E\uDD1D","p":["我们欢迎 Pull Requests！请遵循 贡献指南 开始贡献。","我们也欢迎使用 GitHub 提供模板的有益且详实的错误报告。","我们不接受针对项目本身的货币捐赠。"]},{"l":"个人捐赠 \uD83D\uDE4F","p":["感谢您对个人贡献者的支持，但这不会影响 SillyTavern 的整体开发方向。","RossAscends 拥有个人 Patreon 和 Kofi 页面。"]},{"l":"许可证 \uD83D\uDCC4","p":["SillyTavern 是一个免费开源项目，基于 AGPL-3.0 许可证 发布。"]}],[{"l":"\uD83D\uDCE6 安装指南","p":["请根据您的平台选择对应的安装指南：","\uD83E\uDE9F Windows 系统","\uD83D\uDC27 Linux 和 \uD83C\uDF4E macOS 系统","\uD83D\uDCF1 Android 系统","\uD83D\uDC33 Docker 容器"]},{"l":"\uD83C\uDF3F 分支说明","p":["SillyTavern 采用双分支开发模式，确保所有用户都能获得流畅的使用体验。","release- \uD83C\uDF1F 推荐大多数用户使用。最稳定的推荐分支，仅在重大发布时更新。适合绝大多数用户。通常每月更新一次。","staging- ⚠️ 不推荐日常使用。此分支包含最新功能，但请注意可能随时出现故障。仅适合高级用户和爱好者。每日更新多次。"]},{"l":"\uD83C\uDF0D 全局模式 / 独立模式","p":["SillyTavern 有两种运行模式，区别在于配置和数据路径的处理方式：","独立模式（默认）- 使用服务器目录中的 config.yaml 文件和 data 目录。所有数据将限制在安装路径内。推荐大多数用户使用此模式。","全局模式- 使用系统范围的配置和数据路径。适用于将 SillyTavern 作为软件包安装，或希望在多个安装间共享相同配置和数据的情况。","使用 官方 npm 包（例如 npx sillytavern@latest）进行的安装默认使用全局模式。"]},{"l":"数据路径说明","p":["独立模式 路径相对于 SillyTavern 安装目录：","配置路径: ./config.yaml","数据根目录: ./data/","全局模式 路径取决于操作系统：","Linux: ~/.local/share/SillyTavern/config.yaml（或 $XDG_DATA_HOME/SillyTavern/config.yaml）和 ~/.local/share/SillyTavern/data/（或 $XDG_DATA_HOME/SillyTavern/data/）","Windows: %APPDATA%\\SillyTavern\\config.yaml 和 %APPDATA%\\SillyTavern\\data\\","macOS: ~/Library/Application Support/SillyTavern/config.yaml 和 ~/Library/Application Support/SillyTavern/data/"]},{"l":"如何运行全局模式","p":["在全局模式下运行时，无法通过 CLI 参数 或 config.yaml 覆盖 dataRoot 和 configPath。","向服务器启动命令传递 --global 参数（例如 node server.js --global）","向 shell 启动脚本传递 --global 参数（例如 Start.bat --global 或 ./start.sh --global）","使用 package.json 文件中的 start:global 脚本（例如 npm run start:global）"]}],[{"l":"\uD83E\uDE9F Windows 系统安装指南","p":["请勿安装在任何受 Windows 保护的文件夹内（如 Program Files、System32 等）","切勿使用管理员权限运行 Start.bat","Windows 7 无法运行 NodeJS 18.16，故不支持安装"]},{"l":"\uD83D\uDCE6 通过 Git 安装","p":["安装 NodeJS（推荐最新 LTS 版本）","安装 Git for Windows","打开文件资源管理器（ Win+E）","浏览或创建一个不受 Windows 管控的文件夹（例如： C:\\MySpecialFolder\\)","点击顶部地址栏，输入 cmd 并按回车，在该文件夹内打开命令提示符","在命令提示符窗口中输入以下命令之一并按回车：","发布分支： git clone https://github.com/SillyTavern/SillyTavern -b release","开发分支： git clone https://github.com/SillyTavern/SillyTavern -b staging","克隆完成后，双击 Start.bat，NodeJS 将自动安装依赖","服务器启动后，SillyTavern 将在浏览器中打开"]},{"l":"\uD83D\uDE80 通过启动器安装","p":["按下 Win + R 打开运行对话框，执行以下命令安装 Git：","按下 Win + E 打开文件资源管理器，进入目标安装文件夹，在地址栏输入 cmd 并按回车，然后执行："]},{"l":"\uD83D\uDDA5️ 通过 GitHub Desktop 安装","p":["（此方法仅限在 GitHub Desktop 中使用 Git。如需在命令行使用 Git，仍需安装 Git for Windows）","安装 NodeJS（推荐最新 LTS 版本）","安装 GitHub Desktop","安装后点击 Clone a repository from the internet...（无需 GitHub 账户） 步骤1","选择 URL 标签页，输入 https://github.com/SillyTavern/SillyTavern 并点击 Clone。可修改本地路径调整安装位置 步骤2","通过文件资源管理器进入克隆的仓库目录（默认路径： C:\\Users\\[用户名]\\Documents\\GitHub\\SillyTavern）","双击 Start.bat 文件（若系统隐藏扩展名，则显示为\"Start\"） 步骤3","命令提示符窗口将打开并自动安装依赖","安装完成后，命令窗口将显示如下界面，浏览器自动打开 SillyTavern： 步骤4","连接任意 支持的 API 即可开始聊天！"]}],[{"l":"\uD83D\uDC27 Linux & \uD83C\uDF4E macOS 安装指南"},{"l":"\uD83D\uDCE6 手动 Git 安装","p":["以下操作均需在终端中完成（\uD83C\uDF4E macOS / \uD83D\uDC27 Linux 系统）。","安装 git 和 NodeJS（安装方法因操作系统而异）","克隆代码库：","发布分支： git clone https://github.com/SillyTavern/SillyTavern -b release","开发分支： git clone https://github.com/SillyTavern/SillyTavern -b staging","使用 cd SillyTavern 进入安装目录","通过以下任一命令运行 start.sh 脚本：","./start.sh","bash start.sh"]},{"l":"\uD83D\uDE80 SillyTavern 启动器安装"},{"l":"\uD83D\uDC27 Linux 用户","p":["打开终端并安装 git","下载启动器： git clone https://github.com/SillyTavern/SillyTavern-Launcher.git","进入目录： cd SillyTavern-Launcher","运行安装脚本： chmod +x install.sh ./install.sh 并选择需要安装的内容","安装完成后启动： chmod +x launcher.sh ./launcher.sh"]},{"l":"\uD83C\uDF4E macOS 用户","p":["打开终端，通过以下命令安装 Homebrew：/bin/bash -c $(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)","安装 git： brew install git","下载启动器： git clone https://github.com/SillyTavern/SillyTavern-Launcher.git","进入目录： cd SillyTavern-Launcher","运行安装脚本： chmod +x install.sh ./install.sh 并选择需要安装的内容","安装完成后启动： chmod +x launcher.sh ./launcher.sh"]}],[{"l":"\uD83D\uDCF1 Android (Termux) 安装指南","p":["SillyTavern 可通过 Termux 在 Android 设备上原生运行。"]},{"l":"\uD83D\uDD27 安装 Termux","p":["请避免从 Google Play 商店安装 Termux，该版本已停止维护。 建议从 F-Droid（推荐）或 GitHub releases 获取最新版本。","从 F-Droid 或 GitHub releases 下载 Termux","安装下载的 APK 文件","打开 Termux 并运行第一条命令：","选择「Mirror group」并选择最近的服务器。可通过触摸屏幕或使用 Unexpected Keyboard 的手势操作","更新 Termux："]},{"l":"\uD83D\uDCE6 安装依赖项","p":["安装所需软件包：","若您运行的是 32 位 Android 系统，请参阅下方的 常见错误 章节获取额外步骤。"]},{"l":"\uD83D\uDE80 安装 SillyTavern","p":["克隆 SillyTavern 代码库（ 如何选择分支）：","发布分支：","开发分支："]},{"l":"⚡ 运行 SillyTavern","p":["运行 SillyTavern 请进入克隆目录并执行启动脚本：","更新 SillyTavern 请进入目录并执行：","可参阅下方的 别名设置 章节创建快捷命令简化此过程。"]},{"l":"❌ 常见错误"},{"l":"平台不支持：android arm LEtime-web","p":["32 位 Android 系统需要无法通过 npm 安装的外部依赖。","使用以下命令安装：","然后继续执行上述安装步骤。"]},{"l":"\uD83C\uDFAF 可选：创建别名","p":["您可为常用命令创建快捷方式以简化操作流程。","打开编辑器修改 .bashrc 文件：","添加以下行创建别名：","保存文件并退出编辑器（在 nano 中按 CTRL + X，然后按 Y，最后按 Enter）","运行以下命令使更改生效：","现在您可以使用以下命令：","st 启动 SillyTavern","stup 更新 SillyTavern","pkgup 更新 Termux 软件包"]},{"l":"\uD83D\uDCDA 扩展阅读","p":["以下指南并非由 SillyTavern 团队维护。","ArroganceComplex#2659 提供的 Termux 使用指南： https://rentry.org/STAI-Termux","使用 Material Files 访问 Termux 文件： https://www.learntermux.tech/2020/10/Termux-File-Manager.html","防止 Termux 进程深度休眠： https://wiki.termux.com/wiki/Termux-wake-lock"]}],[{"l":"\uD83D\uDC33 Docker 安装指南","p":["本指南假设您已安装 Docker，能够通过命令行安装容器，并熟悉其基本操作。"]},{"l":"\uD83D\uDCE5 使用 GitHub 容器镜像库","p":["使用预构建镜像是通过 Docker 运行 SillyTavern 最快捷简便的方式。您可以从 GitHub 容器镜像库拉取最新镜像。"]},{"l":"Docker Compose（推荐方式）","p":["从 GitHub 代码库 下载 docker-compose.yml 文件，并在该文件所在目录运行以下命令。这将从 GitHub 容器镜像库拉取最新的发布版本镜像并启动容器，自动创建必要的卷。","您可以编辑该文件并根据需求进行自定义配置：","默认端口为 8000，可通过修改 ports 部分更改","如需使用开发分支而非稳定版，可将 image 标签改为 staging","如需通过环境变量调整服务器配置，请查阅 环境变量 页面"]},{"l":"Docker CLI（高级用法）","p":["您需要两个必需的目录映射和一个端口映射才能使 SillyTavern 正常运行。在命令中替换以下位置的内容："]},{"l":"容器变量"},{"l":"卷映射","p":["CONFIG_PATH- SillyTavern 配置文件在主机上的存储目录","DATA_PATH- SillyTavern 用户数据（包括角色）在主机上的存储目录","PLUGINS_PATH- （可选）SillyTavern 服务器插件在主机上的存储目录","EXTENSIONS_PATH- （可选）全局 UI 扩展在主机上的存储目录"]},{"l":"端口映射","p":["PUBLIC_PORT- 对外暴露流量的端口。此为必需项，因为您需要从虚拟机容器外部访问实例。在没有实施额外安全服务的情况下，请勿将此端口暴露给互联网。"]},{"l":"附加设置","p":["SILLYTAVERN_VERSION- 在本 GitHub 页面右侧可以看到 \"Packages\"。选择 \"sillytavern\" 包即可查看镜像版本。\"latest\" 镜像标签将保持与当前发布版本同步。您也可以使用 \"staging\" 标签指向相应分支的每日构建镜像。"]},{"l":"运行容器","p":["打开命令行","在要存储配置和数据文件的文件夹中运行以下命令：","默认情况下容器将在前台运行。如需在后台运行，请在 docker run 命令中添加 -d 标志。"]},{"l":"\uD83D\uDD28 构建 Docker 镜像","p":["以下部分假设您在非 root（非管理员）文件夹中安装了 SillyTavern。如果在 root 文件夹中安装，可能需要使用管理员权限运行部分命令 [sudo, doas, 命令提示符（管理员）]。","如需自行构建 Docker 镜像，可按照以下步骤操作。这对于自定义镜像或用于开发目的非常有用。"]},{"l":"\uD83D\uDC27 Linux 系统","p":["Arch Linux (Manjaro/EndeavourOS 等)","Debian (Ubuntu/Pop! OS 等)","Fedora, Red Hat Enterprise Linux (RHEL) 等","享受吧！:D","使用 sudo 打开 nano 并运行以下命令","使用包管理器安装 Git","克隆 SillyTavern 代码库","发布版（稳定分支）","在 127.0.0.1 下方添加新行，并输入从 Docker 复制的 IP。完成后应类似以下内容","在 Docker 文件夹内运行以下命令执行 docker compose","在 nano 中，转到 whitelist。您应该看到类似以下内容","复制 Gateway 中看到的 IP，这很重要","开发版（开发分支）","您应该会收到类似以下的输出","打开新浏览器并访问 http://localhost:8000。片刻后应能看到 SillyTavern 加载","执行以下 Docker 命令获取 SillyTavern Docker 容器的 IP","按 Ctrl+S 保存文件，然后按 Ctrl+X 退出 nano","按照 Docker 安装后指南 中的「以非 root 用户身份管理 Docker」步骤操作","按照 Docker 安装指南 此处 安装 Docker","请勿 安装 Docker Desktop。","请注意，如果将 Docker 网络配置为网桥模式，也可以像往常一样将外部 IP 地址添加到白名单中。","重启 Docker 容器以应用新配置"]},{"l":"\uD83E\uDE9F Windows 系统","p":["享受吧！:D","以管理员权限运行 Notepad 或您选择的代码编辑器，转到 config 并打开 config.yaml","克隆 SillyTavern 代码库","发布版（稳定分支）","在 127.0.0.1 下方添加新行，并输入从 Docker 复制的 IP。完成后应类似以下内容","在 Docker 文件夹内运行以下命令执行 docker compose","在 Windows 上使用 Docker ** 非常** 复杂。不仅需要在「启用或关闭 Windows 功能」中激活 Windows Subsystem for Linux，还要为虚拟化（Intel VT-d/AMD SVM）配置系统，这因 PC 制造商（或主板制造商）而异。有时此选项在某些系统上不可用。","在您选择的编辑器中，应该看到类似以下内容","复制 Gateway 中看到的 IP，这很重要","安装 Git for Windows","开发版（开发分支）","强烈建议按照我们的 Windows 指南安装 SillyTavern。本节仅是在 Windows 上实现的_粗略_思路。","您应该会收到类似以下的输出","打开新浏览器并访问 http://localhost:8000。片刻后应能看到 SillyTavern 加载","执行以下 Docker 命令获取 SillyTavern Docker 容器的 IP","按 Ctrl+S 保存文件，然后退出编辑器","按照 Docker 安装指南 此处 安装 Docker Desktop","请注意，如果将 Docker 网络配置为网桥模式，也可以像往常一样将外部 IP 地址添加到白名单中。","重启 Docker 容器以应用新配置"]},{"l":"\uD83C\uDF4E macOS 系统","p":["享受吧！:D","使用 Homebrew 安装 git","使用 sudo 打开 nano 并运行以下命令","克隆 SillyTavern 代码库","发布版（稳定分支）","在 127.0.0.1 下方添加新行，并输入从 Docker 复制的 IP。完成后应类似以下内容","在 Docker 文件夹内运行以下命令执行 docker compose","在 nano 中，转到 whitelist。您应该看到类似以下内容","复制 Gateway 中看到的 IP，这很重要","如果无法运行 nano，可通过 Homebrew 安装或使用 TextEdit。","尽管 macOS 与 Linux 类似，但它没有 Docker Engine。您需要像 Windows 一样安装 Docker Desktop。 您还需要安装 Homebrew 才能在 Mac 上安装 Git。本节是在 macOS 上实现的_粗略_思路。","开发版（开发分支）","您应该会收到类似以下的输出","打开新浏览器并访问 http://localhost:8000。片刻后应能看到 SillyTavern 加载","执行以下 Docker 命令获取 SillyTavern Docker 容器的 IP","按 Ctrl+S 保存文件，然后按 Ctrl+X 退出 nano","按照 Docker 安装指南 此处 安装 Docker Desktop","请注意，如果将 Docker 网络配置为网桥模式，也可以像往常一样将外部 IP 地址添加到白名单中。","重启 Docker 容器以应用新配置"]},{"l":"⚙️ 配置 SillyTavern","p":["SillyTavern 的配置文件 (config.yaml) 位于 config 文件夹内。配置该文件与在没有 Docker 的情况下配置应该没有区别，但是您需要以管理员权限运行 nano 或代码编辑器才能保存更改。","不要忘记重启 SillyTavern 的 Docker 容器以应用更改！请确保在 docker 文件夹内执行此命令。"]},{"l":"\uD83D\uDCC1 定位用户数据","p":["SillyTavern 的数据文件夹位于 data 文件夹内。备份文件应该很容易，但是，恢复或向其中添加内容可能需要以管理员权限操作。"]},{"l":"\uD83D\uDD0C 运行服务器插件","p":["在 Docker 中运行像 HoYoWiki-Scraper-TS 或 SillyTavern-Fandom-Scraper 这样的插件与在没有 Docker 的系统上运行没有区别，但是我们需要对 Docker Compose 脚本进行轻微修改才能实现。","如果已在 docker 文件夹内看到 plugins 文件夹，可以跳过步骤 1-2。","使用 nano 或代码编辑器，打开 docker-compose.yml 并在 volumes 下方添加以下行","在 docker 文件夹内创建一个名为 plugins 的新文件夹","按照插件说明安装插件","使用具有管理员权限的 nano 或代码编辑器，打开 config.yaml（在 config 文件夹内）并启用 enableServerPlugins","重启 Docker 容器","完成"]},{"l":"❗ Docker 常见问题"},{"l":"挂载卷的 SELinux 权限问题","p":["启用 SELinux 的 Linux 发行版（如 RHEL、CentOS、Fedora 等）可能会阻止 Docker 容器访问挂载的卷，这是由于安全策略的限制。当容器尝试读取或写入挂载目录时，可能会导致权限被拒绝错误。","可以添加后缀 :z 或 :Z 到卷挂载。这些后缀告诉 Docker 重新标记共享卷上的文件对象。","z 选项用于卷内容将在容器之间共享的情况","Z 选项用于卷内容应仅由当前容器使用的情况","示例："]}],[{"l":"\uD83D\uDD04 如何更新 SillyTavern","p":["请根据您的操作系统选择对应的更新指南。","本指南假设您已至少安装并运行过一次 SillyTavern。"]},{"l":"\uD83D\uDC27 Linux/Termux 或 \uD83C\uDF4E macOS 系统","p":["您肯定是通过 git 安装的，只需在 SillyTavern 目录中执行 'git pull' 即可。","cd SillyTavern 进入正确的文件夹","git pull 获取更新","./start.sh 或 bash start.sh 启动 ST"]},{"l":"\uD83E\uDE9F Windows 系统","p":["首先尝试使用位于 SillyTavern 安装基础文件夹中的 UpdateAndStart.bat","如果失败，请回到此处继续阅读。"]},{"l":"方法 1 - GIT 方式","p":["我们始终推荐用户使用 'git' 安装。原因如下：","当您通过 git clone 安装时，要更新只需在 ST 文件夹的命令行中 输入 git pull。 或者，如果命令提示符出现问题（且您已安装 GitHub Desktop），可以使用 Repository 菜单并选择 Pull。","更新会自动安全地应用。"]},{"l":"\"求助：我最初通过 Zip 安装，现在想转换为 Git 安装\"","p":["您选择了明智的道路。","由于您的安装是通过 Zip 完成的，您需要使用 git 进行全新安装。","幸运的是，我们提供了 操作说明。","一旦您使用 git 将新的 SillyTavern 安装到不同的文件夹中，请回到本页面并继续执行下面「Zip 更新」说明中的 第 4 步。"]},{"l":"方法 2 - ZIP 方式","p":["(*) '根据需要' = \"如果您创建了与这些文件夹相关的任何自定义内容\"","1.12.0 包含自动迁移程序。仅当迁移被中断或出错时才需要执行以下步骤。","下载新的发布版 zip 文件","再次使用适用于您操作系统的方法启动 SillyTavern，并祈祷您做对了","复制这些文件夹/文件后，将它们粘贴到新安装的 /data/default-user 文件夹中（secrets.json 放在文件夹根目录中）","如果一切正常显示，您可以安全地删除旧的 ST 文件夹","如果您坚持通过 zip 安装，以下是繁琐的更新过程：","将 /data 目录和 config.yaml 文件从一个安装复制到另一个安装","将其解压到当前 ST 安装之外的文件夹中","所有文件夹都不是必需的，因此只需复制您需要的内容","按照您操作系统的常规设置程序安装 NodeJS 要求","根据需要(*)从旧的 ST 安装中复制以下文件/文件夹：","根据需要将文件从旧的 /public 转移到新的 /data/default-user","注意：不要复制整个 /PUBLIC/ 文件夹","至少运行一次更新后的服务器安装，以创建 /data/default-user 目录","这样做可能会破坏新安装并阻止新功能的出现"]},{"l":"常见更新问题"},{"l":"\"工作目录中存在未解决的冲突\"","p":["这意味着您修改了远程仓库中已更改的默认文件（例如设置预设）。","要解决此问题，请在终端中运行此命令。请谨慎使用，因为它可能具有破坏性。如果需要，请确保有备份。"]},{"l":"文件更改阻止 git pull","p":["如果您更改了 SillyTavern 系统文件， git pull 可能无法工作","有时更新可能需要我们更改重要文件，这可能导致相同的问题","通常是默认预设文件或 package-lock.json","在这种情况下，您可以尝试将文件移动到其他文件夹（或删除文件），然后执行 git pull","另一种解决方案是使用 git pull --rebase --autostash"]},{"l":"启动服务器时出现错误：Cannot find module \"***\"","p":["这意味着 SillyTavern 添加了新的 npm 包要求","在 SillyTavern 目录中运行 npm install 来修复此问题。提供的 Start.bat 和 start.sh 脚本会自动执行此操作","没有帮助？删除 node_modules 文件夹","Windows 系统","Unix/Linux 系统"]},{"l":"\uD83D\uDC33 Docker 方式","p":["打开终端窗口并导航到您的 docker 目录 cd SillyTavern/docker","使用 docker compose down 删除您的容器","从缓存中删除 SillyTavern docker 镜像 docker rmi ghcr.io/sillytavern/sillytavern:latest（如果您的目标是 staging 分支，请将 sillytavern:latest 替换为 sillytavern:staging）","使用 sudo docker compose up -d 重新构建容器","如果一切顺利，docker 应该开始重新下载镜像，您很快就会启动并运行。如果遇到任何问题，请参阅本指南的下一部分。"]},{"i":"常见更新问题-1","l":"常见更新问题"},{"l":"我使用 Docker，更新后所有数据都消失了！","p":["您必须遵循 Docker 容器的迁移指南 来更新 1.12.0 中引入的新数据模型的卷映射"]},{"l":"运行 docker 命令时权限被拒绝","p":["这是 Linux 问题，意味着您的权限设置不正确。有两种解决方法：","简单方法：如果您的用户具有 sudo 访问权限，只需在命令前加上 sudo（例如： sudo docker compose down）","正确方法：修复您的权限。这取决于您使用的 Linux 版本。网上有很多指南可以帮助您解决此问题"]}],[{"l":"\uD83D\uDE80 1.12.0 迁移指南","p":["SillyTavern 1.12.0（代号「Neo Server」更新）包含多项重要变更，可能影响您的使用体验。","本指南将帮助您做好准备，并提供详细操作说明。"]},{"l":"\uD83D\uDCE6 数据存储更新","p":["1.12.0 版本改变了用户数据的处理方式。","此前，所有持久化数据都与前端文件一同存储在 /public 目录中，这导致了混淆和潜在的故障点，同时也使容器化和系统级应用安装变得复杂。"]},{"l":"变更内容","p":["所有来自 /public 的持久化信息（完整列表见下文）现已移至可配置路径的独立目录，使其可移植且独立于 Web 服务器本身。为兼容性考虑（例如托管扩展、完整角色卡、用户图片上传等），已设置智能重定向，自动从数据目录提供用户文件。"]},{"l":"设置数据根目录","p":["您可以通过 config.yaml 或启动服务器时使用 --dataRoot 控制台参数，指定数据根目录的绝对路径或相对路径（相对于 ST 代码库目录）。","YAML 示例","控制台示例","默认数据根目录路径为 ./data，即 SillyTavern 代码库中的 data 目录。","数据根目录路径应为 完整绝对路径 或 完整相对路径。不能使用 ~ 或 %APP_DATA% 等路径快捷方式，因为这些由 shell 解析，而非操作系统。"]},{"l":"迁移操作"},{"l":"⚠️ 重要！开始前的准备","p":["仅当需要从默认位置移动 dataRoot 时执行此步骤，否则请跳过。 在首次运行更新后的服务器之前设置数据根目录。运行 npm install 以使 config.yaml 填充新值，或传递控制台参数。","所有数据将迁移至 default-user 账户。详见下文 用户管理 部分。"]},{"l":"无容器（裸机）安装","p":["您无需任何操作！当 ST 服务器检测到旧存储格式（通过检查 /public/characters 目录是否存在）时，自动迁移将处理所有事宜。","移动任何文件前，系统会在 /backups/_migration/YYYY-MM-DD（解析为当前日期）目录中创建自动备份，但在运行迁移前手动完整备份仍是良好实践。"]},{"l":"容器化（Docker）安装","p":["迁移 Docker 卷中的数据稍复杂但操作直接。虽然代码库提供的 docker-compose.yml 已更新以反映变更，但您可能需要调整自定义工作流/部署。","步骤 1. 创建新卷，并将其挂载到容器内的 \"/home/node/app/data\" 路径。不要移除 config 卷。","步骤 2. 将 config 卷中除 config.yaml 文件外的所有内容移至 data 卷的 default-user 子目录。","步骤 3. 重新构建容器并启动。","不再需要 /public 目录与 config 卷之间的软链接，Docker 容器中也不再构建此链接！"]},{"l":"需要迁移哪些内容？","p":["/data/default-user/assets","/data/default-user/backgrounds","/data/default-user/characters","/data/default-user/chats","/data/default-user/content.log","/data/default-user/context","/data/default-user/extensions","/data/default-user/group chats","/data/default-user/groups","/data/default-user/instruct","/data/default-user/KoboldAI Settings","/data/default-user/movingUI","/data/default-user/NovelAI Settings","/data/default-user/OpenAI Settings","/data/default-user/QuickReplies","/data/default-user/secrets.json","/data/default-user/settings.json","/data/default-user/stats.json","/data/default-user/TextGen Settings","/data/default-user/themes","/data/default-user/thumbnails","/data/default-user/vectors","/data/default-user/worlds","/default/content/content.log","/public/assets","/public/backgrounds","/public/characters","/public/chats","/public/context","/public/group chats","/public/groups","/public/instruct","/public/KoboldAI Settings","/public/movingUI","/public/NovelAI Settings","/public/OpenAI Settings","/public/QuickReplies","/public/scripts/extensions/third-party","/public/settings.json","/public/stats.json","/public/TextGen Settings","/public/themes","/public/worlds","/secrets.json","/thumbnails","/vectors","以下文件和目录属于数据迁移范围。假设为默认配置，下表中提供了迁移前后的路径对照。","迁移前路径","迁移后路径"]},{"l":"\uD83D\uDC65 用户管理","p":["1.12.0 新增了（完全可选的）在同一服务器上创建多用户设置的功能，允许多个用户使用自己完全隔离的 SillyTavern 实例，甚至可以同时使用。用户账户还可设置密码保护，增加隐私层。","更多信息请参阅 用户管理 文档。"]}],[{"l":"\uD83D\uDE80 1.9.0 迁移指南"},{"l":"如何迁移到新分支（如果您当前使用 main/dev 分支）？","p":["推荐进行全新安装。 但如果您希望使用现有的 SillyTavern 副本，请按照以下说明操作。","重要提示！ 在进行任何操作前，请对您的安装目录进行 完整备份。在此过程中您可能 丢失数据，请勿忽略此警告。","不确定需要备份哪些文件？请参阅： 如何更新 SillyTavern"]},{"l":"Git 安装方式","p":["在您的 SillyTavern 安装文件夹中打开终端（cmd、PowerShell、Termux 等）","输入 git fetch，然后输入 git pull 拉取更新","您可能会丢失设置。是否已进行备份？使用 git switch release 或 git switch staging 可分别切换分支","如果没有错误，请跳至下一步。您可能会遇到类似如下错误：","您将看到受影响的文件列表。如果您不介意这些设置文件被替换，可使用 git switch -f release 或 git switch -f staging 强制设置分支 如果您希望保留这些更改，请从备份中恢复","输入 npm install，然后输入 npm run start 测试一切是否正常运行","完成！如有需要，请从备份恢复数据"]},{"l":"错误提示：fatal: invalid reference: release","p":["如果您之前从旧远程仓库（迁移到组织仓库之前）仅克隆了单个分支，可能会出现此问题。修复方法是从新远程添加并获取分支：","然后从第 5 步继续操作。"]},{"l":"ZIP 压缩包安装方式","p":["对您来说没有任何变化。只需像往常一样下载分支/发布版本的 ZIP 包即可。"]}],[{"l":"\uD83D\uDD04 如何更新 Node.js","p":["为确保安全性和性能，及时更新 Node.js 运行时十分重要。以下是根据操作系统更新 Node.js 的步骤指南。","我们推荐使用最新的长期支持（LTS）版本，您可以在 Node.js 官方网站 上找到相关信息。"]},{"l":"\uD83D\uDD0D 如何检查当前 Node.js 版本","p":["打开终端或命令提示符","输入以下命令并按回车："]},{"l":"\uD83D\uDD04 nvm（Node 版本管理器）- 跨平台方法","p":["如果您使用 nvm：","打开终端","输入以下命令：","Unix/Linux/macOS 系统：","Windows 系统："]},{"l":"\uD83E\uDE9F Windows 系统 - 常规安装方法","p":["访问 Node.js 下载页面","下载 LTS 版本的 Windows 安装程序","运行安装程序并按提示完成安装"]},{"l":"\uD83E\uDE9F Windows 系统 - SillyTavern 启动器","p":["如果您使用 SillyTavern 启动器安装：","打开 SillyTavern 启动器","导航至 工具箱 / 应用安装器 / 核心工具 / 安装 Node.js","或者：","在 PowerShell 中使用 winget 手动安装："]},{"l":"\uD83D\uDCF1 Android 系统 - Termux","p":["打开 Termux 应用","输入以下命令：","更新过程中出现提示时，别忘了按虚拟键盘上的 Y 键确认。"]},{"l":"\uD83C\uDF4E macOS 系统 - 常规安装方法","p":["访问 Node.js 下载页面","下载 LTS 版本的 macOS 安装程序","运行 .pkg 文件并按提示完成安装"]},{"l":"\uD83C\uDF4E macOS 系统 - Homebrew","p":["如果您已安装 Homebrew，可以使用以下命令更新 Node.js："]},{"l":"\uD83D\uDC27 Linux 系统 - 包管理器","p":["Linux 系统更新 Node.js 的方法取决于您的发行版。","但由于官方仓库中的 Node.js 版本可能不是最新的，我们推荐使用 Node 版本管理器 (nvm) 或 NodeSource 仓库。"]},{"l":"\uD83D\uDC33 Docker 容器","p":["无需任何操作。我们提供的预构建 Docker 镜像已使用最新版本的 Node.js 编译。"]}],[{"l":"Usage","p":["Add new features and capabilities to the AI or the interface","API Connections","Automate tasks, let your AI interact with the world, and write your own extensions","Characters and Personas","Chatting","Connect to AI models for generating text, images, and more","Control the requests that you send to the AI and how it responds","Create and use characters to shape the AI's role, and personas to define your identities","Data Bank","Development and Automation","Extensions","FAQ","Frequently asked questions about SillyTavern, AI models, making characters, getting better responses, and more","How to chat with the AI and use the chat interface","Interact with AI, your way. Build your world, your work, or your dreams.","Learn how to set up and use Welcome Page Assistants to greet you with a designated character on the Welcome Screen.","Manage information and when to insert it into the prompt","Quick Start","Response Configuration and Prompts","Send your first message to the AI and get a response","Store and retrieve information for use in the AI's responses","Welcome Page Assistants","World Info"]},{"l":"Control Panels","p":["Add new features and capabilities to the AI or the interface","Advanced Formatting","API Connections","Backgrounds","Change the background image","Change the theme, and the look and feel of messages and chats","Characters","Connect to AI models for generating text, images, and more","Control text generation and sampling. Customize prompt construction for Chat Completion APIs.","Create and manage characters for the AI to use","Create and manage personas to use with the AI","Customize prompt construction for Text Completion APIs","Extensions","Manage information and when to insert it into the prompt","Personas","Response Configuration and Prompt Manager","User Settings","What all the buttons do, from the left to the right:","World Info"]}],[{"l":"\uD83D\uDE80 快速开始","p":["我是小白，请手把手教我最简单快捷使用 SillyTavern 的方法。 -- 匿名用户","只需几分钟即可开始使用 SillyTavern。以下是两种简单的入门方式：","您可以 使用 AI Horde（免费）。AI Horde 是一个社区驱动的 AI 服务，提供多种 AI 模型的访问权限。","如果您拥有 OpenAI 账户或想要注册一个，可以 使用 OpenAI。"]},{"l":"使用 AI Horde 快速开始","p":["按照 安装指南 安装并启动 SillyTavern","在 SillyTavern 的欢迎界面中，输入您的人物名称。此名称将在聊天中使用","可选说明文字","点击顶部工具栏中的 API 连接按钮","输入 AI Horde 的 API 密钥。您暂时可以使用 0000000000，或从 AI Horde 获取免费密钥","选择要使用的 AI 模型。只需从顶部选择几个即可，以后随时可以更改","关闭 API 连接窗口。在底部的聊天框中输入消息并按回车键","您的 AI 将在片刻后回复。您可以继续与它 聊天。成功！"]},{"l":"使用 OpenAI 快速开始"},{"l":"安装 SillyTavern","p":["按照 安装指南 安装并启动 SillyTavern"]},{"l":"获取 OpenAI 访问权限","p":["注册 OpenAI 账户","访问 https://platform.openai.com","点击右上角的账户图标，然后选择 View API Keys","点击 \"Create new secret key\"。立即将其复制到安全的地方。 请勿分享此密钥。任何拥有此密钥的人都可以使用您的账户并以您的费用使用 GPT"]},{"l":"配置 SillyTavern 使用您的 API","p":["在 SillyTavern 的顶部工具栏中，点击 API Connections","在 API 下选择 Chat Completion (OpenAI)","在 Chat Completion Source 下选择 OpenAI","粘贴您在上一步中保存的 API 密钥","点击 Connect 按钮。确认显示 Valid","默认情况下，SillyTavern 将使用 GPT-4 Turbo。您可以选择其他模型，但请先了解定价信息"]},{"l":"测试您的设置","p":["在 SillyTavern 的顶部工具栏中，点击最右侧的 Character Management","选择一个现有角色，例如 Seraphina","在底部的文本框中向 Seraphina 写些内容，然后按 Enter 键或点击 Send 按钮","如果一切设置正确，几秒钟后 Seraphina 应该会回复您。"]}],[{"l":"❓ 常见问题解答"},{"l":"SillyTavern 是什么？","p":["现代 AI 语言模型（如 ChatGPT）已经变得非常强大，其中一些能够逼真地模拟您创建的角色，您可以与之聊天、共同创作小说等。例如，您可以告诉 AI 扮演一位名叫 Jubei 的中世纪日本围棋导师，它会相应地行动和回应。您可以与 Jubei 长时间聊天，一起去酒吧，决定与武士打架，任何您能想象的事情，AI 都会配合并围绕这些内容进行写作/反应，充当您的对手和地下城主。您的想象力是唯一的限制。您可以告诉 AI 假装它是神奇女侠。您还可以指定场景（\"神奇女侠和我在抢劫银行\"）、写作风格（\"神奇女侠说黑人英语\"）或任何您能想到的内容。","SillyTavern 是一个促进这些用途的应用程序：","它是一个处理与 AI 语言模型通信的用户界面","它让您可以创建新的角色卡（提示），并轻松在它们之间切换","它让您可以导入其他人创建的角色","它会保存您与角色的聊天历史，允许您随时恢复、开始新聊天、查看旧聊天等","在后台，它会为您准备 AI 提示所需的内容。具体来说，它会发送系统提示（AI 的指令），使 AI 遵循某些规则以提高响应准确性"]},{"l":"AI 模型选项概述","p":["SillyTavern 可以与两种类型的 AI 交互：","网络服务（基于云端，通常付费、专有、封闭）","自托管（本地、免费、开源）"]},{"l":"付费网络服务 AI","p":["付费网络模型是黑盒子。您支付公司费用以使用他们的 AI 服务。您在 SillyTavern 中输入账户信息，它将连接到您的提供商以代表您使用 AI。","优点：","真正容易上手","最高质量的 AI 写作","缺点：","使用需要付费","所有内容都记录在他们的服务器上。存在隐私问题","它们经常被审查，会拒绝与您讨论某些主题"]},{"l":"自托管 AI","p":["自托管模型是可以在您的 PC 上运行的免费模型，但需要强大的 PC 和更多设置工作。","优点：","一旦设置完成，即使没有互联网访问也可以免费使用","完全隐私。您写的一切都保留在您自己的 PC 上","有各种各样的模型。作为社区驱动的技术，您可以找到适合特定任务或您想要的行为的模型","缺点：","它们不如 SOTA 模型强大（即，对话写作更差，创造性较低等）","运行本地模型需要至少 6GB VRAM 的 GPU","如果您有兴趣使用这些，请参阅专用指南： 如何使用自托管模型"]},{"l":"我可以在手机或平板电脑上使用 SillyTavern 吗？","p":["iPhone 和 iPad 无法运行整个 SillyTavern 应用程序，但由于它只是一个 Web 界面，您可以在家庭 Wi-Fi 上的另一台计算机上运行它，然后在移动浏览器中访问它。有关更多信息，请参阅 远程连接","对于 Android 用户，除了上述方法外，您还可以使用 Termux 应用程序直接在手机上运行整个 SillyTavern，而无需 PC。请参阅 安装（Android）（注意：Termux 安装不受官方支持，我们不能保证它会工作）"]},{"l":"我尝试导入 PNG 角色卡，但收到错误提示说它无效。为什么？","p":["两种可能性：","该卡片没有嵌入定义，只是一个普通的图像文件。某些程序或文件管理器在保存时会从卡片中剥离嵌入的定义。请确保您使用原始 PNG 文件，就像分享它的人发布的那样","PNG 文件实际上是一个带有 .png 文件名的 WEBP 文件。您可以尝试在导入前将卡片重命名为 .webp，或者寻找正确的 PNG 版本图像"]},{"l":"如何制作自己的 AI 角色？","p":["点击角色管理按钮","点击创建新角色","在角色名称下，给一个名字，比如 Amanda","可选地，点击选择头像按钮为此角色选择图像肖像","在描述下，描述角色，并包含您认为与聊天相关的任何信息。例如： Amanda 是一名在间隔年旅行的学生。她身高 6 英尺，是一名排球运动员。她有着运动员的身材。她有长长的棕色头发。她热爱维多利亚时代的英国时期，喜欢观看与该时期相关的电视和阅读小说 例如，如果您希望 Amanda 友好，那么您将添加： Amanda 非常开朗和外向","在第一条消息下，写下开始新聊天时角色的问候语。例如：*Amanda 向您挥手* 嘿！你也是背包客吗？","点击创建角色按钮","您现在有一个可以与之聊天的基础角色。从角色列表中选择 Amanda，将开始一个新的聊天。","请注意，您可以使用描述和/或第一条消息创建更具体的场景，和/或在描述中包含您自己。例如：","您包含的任何相关信息都可以使用。使用效果如何取决于 AI 模型的功率水平。","注意：角色创建后，您可以返回编辑任何这些信息，除了名称。"]},{"l":"我的 API 密钥存储在哪里？为什么我看不到它们？","p":["SillyTavern 将您的 API 密钥保存到用户数据目录中的 secrets.json 文件（默认路径是 /data/default-user/secrets.json）","默认情况下，API 密钥在保存并刷新页面后从界面中不可见。","要启用查看您的密钥：","在 config.yaml 文件中将 allowKeysExposure 的值设置为 true","重新启动 SillyTavern 服务器","点击 API 连接面板右下角的“查看隐藏的 API 密钥”链接"]},{"l":"性能提示"},{"l":"为什么 UI 这么慢/卡顿？","p":["尝试在用户设置面板上启用无模糊效果（快速 UI）模式","在 UI 主题设置中启用减少运动以移除装饰性动画","确保您的浏览器使用硬件加速","如果使用响应流，将流式传输 FPS 设置为较低值（推荐 10-15 FPS）"]},{"l":"我遇到输入延迟。我能做什么？","p":["性能下降，特别是输入延迟，最常归因于浏览器扩展。已知有问题的扩展包括：","iCloud 密码管理器","DeepL 翻译","基于 AI 的语法校正工具","各种广告拦截扩展","如果您遇到性能问题且无法确定原因，或怀疑是 SillyTavern 本身的问题，请：","记录性能配置文件","将配置文件导出为 JSON 文件","将其提交给开发团队进行分析","我们建议首先禁用所有浏览器扩展和第三方 SillyTavern 扩展进行测试，以隔离性能下降的来源"]},{"l":"当我导入大量角色时，应用程序变慢。为什么？","p":["不幸的是，SillyTavern 并非设计用于处理巨大的角色库。您拥有的角色越多，加载角色列表所需的时间就越长。证据数据表明，当您拥有超过 1000 个角色时，性能下降开始变得明显。","但是，您可以采取一些措施来缓解问题：","1. 使用懒加载","在 config.yaml 文件中将 performance.lazyLoadCharacters 的值设置为 true 以启用角色懒加载设置。在下次服务器重启后，角色列表将仅加载您与之交互的角色的完整数据。请注意，如果某些第三方扩展未更新以支持此设置，启用后可能无法正常工作（请联系扩展开发者获取更多信息）","2. 使用内存缓存","如果您有一些空闲 RAM，增加内存缓存容量。这将允许服务器在内存中保留更多角色，减少加载它们所需的时间。您可以通过调整 config.yaml 文件中 performance.memoryCacheCapacity 的值到更高的数字来实现。默认值是 100mb。大致经验法则：每拥有 3000 个角色，将值增加 100mb","限制：","启用懒加载后，高级（模糊）角色搜索将不起作用。仅搜索角色名称","由于可用内存有限，内存缓存在 Android 设备上被禁用"]},{"l":"如何让 AI 写更多？","p":["有时 AI 只会用一句话回应，而您希望它更详细。 这通常是本地运行模型的问题。","如果您只是想讓機器人從它最近回复結束的地方繼續寫作，您可以通過在輸入欄中不輸入任何內容並點擊發送來發送空用戶消息。這將強制機器人繼續故事。","修复策略：","增加“响应长度”设置的值","为角色设计一个良好的“第一条消息”，显示他们说话啰嗦的方式。当给予关于您期望的写作风格的指导时，AI 模型可以大大提高","在角色的描述框中添加短语，如“喜欢说话很多”或“非常啰嗦的说话者”","对您的“作者注记”或“后历史指令提示”做同样的事情","作为最后的手段，您可以尝试打开“自动继续”（在用户设置面板中），但会使响应变慢，因为它使 AI 背靠背地产生小回复，然后将它们全部组合成一个大回复。它也可能与某些 API 选项不兼容"]},{"l":"如何让 AI 写更少？","p":["这主要只是像 ChatGPT 或 Claude 这样的模型的问题。可以应用相同的策略但相反。","降低“响应长度”设置的值","给角色一个短语，如“说话简短”，或“不多说话”的行在他们的描述中","给角色一个简短的第一条消息来设定聊天的基调和期望","确保“自动继续”已关闭"]},{"l":"如何让 AI 停止编写我角色的动作，并完全自行驱动情节？","p":["这应该在“作者注记”中处理，结合如下短语：","{{char}} 的回应应仅对 {{user}} 的动作被动和反应","您的下一个回应应仅从 {{char}} 的视角出发","绝不允许为 {{user}} 规定动作或言语"]}],[{"l":"\uD83D\uDCAC 畅聊互动","p":["连接到 API 后，通过在屏幕底部的聊天栏中输入内容，向 AI 发送消息。然后点击 发送 或按 Enter 键。","聊天栏","AI 将回复一条消息以继续对话。","聊天消息","您现在可以：","发送另一条消息","滑动响应：点击消息上的 滑动 按钮以生成不同的回复。","编辑消息：点击任意消息上的 编辑 按钮以 编辑消息内容。","消息操作：点击消息上的 消息操作 按钮以获取更多 消息选项，如 翻译、图像生成和故事分支。","聊天选项：点击聊天栏旁边的 选项 按钮以获取更多 聊天选项，如作者笔记和聊天文件管理。","如果您希望之前说了不同内容，可以编辑您的消息，然后滑动 AI 的回复以获取新的回复。","您也可以使用 右 箭头键滑动回复，使用 上 箭头键编辑聊天中的最后一条消息。有关更多快捷键，请在聊天中使用 /help hotkeys 斜杠命令 或查看 快捷键 页面。"]},{"l":"\uD83D\uDCCB 消息操作面板","p":["通过消息上的省略号 (•••) 按钮管理单个聊天消息。","要在所有聊天消息中显示这些选项，请在用户设置中启用 展开消息操作 设置。"]},{"l":"核心功能","p":["翻译：将消息转换为不同语言","生成图像：根据消息内容 创建图像","讲述： 文本转语音 转换","提示：查看生成提示和令牌使用情况"]},{"l":"消息可见性","p":["已包含：AI 能看到此消息；点击以排除它","已排除：AI 看不到此消息；点击以包含它"]},{"l":"内容管理","p":["嵌入： 附加文件或图像","检查点：创建故事检查点","检查点导航：点击打开检查点聊天，Shift+点击更新现有检查点","分支：开始替代故事路径","复制：复制消息文本","编辑：编辑消息内容"]},{"l":"✏️ 编辑消息内容","p":["一个紧凑的消息操作工具面板，在您 编辑 聊天消息时出现。"]},{"l":"核心操作","p":["确认：保存消息更改","取消：丢弃消息更改"]},{"l":"消息操作","p":["复制：复制消息内容","删除：移除消息"]},{"l":"消息位置","p":["上移：将消息在聊天中向上移动","下移：将消息在聊天中向下移动","注意：根据消息在聊天历史中的位置，移动控件可能会被禁用。"]},{"l":"⚙️ 聊天选项面板","p":["通过聊天界面左下角的 选项 按钮管理聊天设置和操作。"]},{"l":"显示控制","p":["关闭聊天：退出当前聊天会话","切换面板：显示/隐藏 界面面板"]},{"l":"生成设置","p":["作者笔记：自定义上下文指令","CFG 规模：调整回复创意度","令牌概率：查看令牌生成统计信息"]},{"l":"聊天导航","p":["返回父聊天：返回主对话","保存检查点：创建故事检查点","转换为群组：转换为 群聊"]},{"l":"聊天管理","p":["开始新聊天：开始新的对话","管理聊天文件： 聊天文件操作，如导入、导出和重命名"]},{"l":"消息控制","p":["删除消息：选择并删除多条消息","重新生成：创建新的回复","模拟：AI 以用户身份编写消息","继续：扩展最后一条消息","注意：某些选项可能会根据上下文和聊天状态隐藏。"]},{"l":"\uD83D\uDCCA 令牌概率面板","p":["令牌概率面板让您可以深入了解 AI 生成文本时的采样过程。它不仅显示 AI 写了什么，还显示它在文本每个点考虑的其他选项。","要打开它，请点击 聊天选项 面板中的 令牌概率 按钮。","示例消息","示例消息的令牌概率显示","当您点击生成文本中的任何令牌（单词、标点符号或格式字符）时，面板会显示 AI 在该位置考虑的替代令牌及其概率分数。这让您可以了解 AI 的“思考过程”，并显示回复可能采取的其他方向。查看这些替代选项可以帮助您了解当时是有几个可能的选项还是一个明确的选择。","替代令牌和概率","如果您认为 AI 本应选择不同的令牌，请选择一个替代项，消息将从该点开始重新生成，可能会给您不同的回复。"]},{"l":"重新生成 (Rerolling)","p":["如果您更改特定令牌并重新生成回复，新回复中更改前令牌之前的部分将与原始回复相同。这部分显示为灰色。由于它不是生成的，因此没有这部分信息的概率。","您可能希望看到基于您选择的替代令牌可能生成的其他回复。","您可以点击灰色部分以“重新生成”，为您提供文本的新变体。点击灰色部分的任何部分将保留整个灰色部分，并重新生成整个白色/着色部分。","按住 Ctrl 键并点击灰色部分中的令牌将保留直到所点击令牌的灰色部分，并重新生成其余文本。您选择的替代令牌在这种情况下无法保留。"]},{"l":"控件","p":["令牌显示：","生成的文本被分割成单独的令牌","每个令牌都是交互式的，点击令牌可查看 AI 考虑的替代项","令牌会着色作为视觉辅助，但这并不表示概率","特殊字符（空格、换行符）会被明显标记","令牌选择：","点击令牌以查看替代项","点击替代项以替换令牌并重新生成回复","将鼠标悬停在令牌上可查看其原始对数概率分数","窗口控件：","拖动手柄用于重新定位面板（仅限 MovingUI）","最大化/恢复面板大小","展开/折叠面板内容","关闭面板"]},{"l":"可用性","p":["您必须在 用户设置 中选择 请求令牌概率 才能启用此功能。","令牌概率仅对最新消息可用，并且不会保存到聊天中。如果消息的令牌概率信息不再可用，面板将显示一条指示消息。","使用平滑流式传输时，令牌概率不可用。","并非所有 API 都提供令牌概率。如果您使用的 API 不支持令牌概率，面板将打开但不会显示任何信息。"]},{"l":"文本补全 (Text Completion)","p":["LlamaCPP：可用","Text Generation WebUI(oobabooga)：可用","TabbyAPI：可用","NovelAI：可用","KoboldCPP：可用","Ollama：似乎不可用","OpenRouter Text：似乎不可用"]},{"l":"聊天补全 (Chat Completion)","p":["OpenAI 或 Custom：可用，但不支持重新生成 (rerolling)","Anthropic：似乎不可用","Google AI Studio：似乎不可用","OpenRouter Chat：似乎不可用"]}],[{"l":"\uD83D\uDD27 斜杠命令","p":["此非完整列表，更新频率较低。","要获取您当前实例中最新的可用命令列表，请在任意 SillyTavern 聊天中使用 /help slash 命令。","/help– 显示帮助信息","/api- 切换至其他 API","/sys- 以系统中立旁白身份发送消息","/send- 以用户身份发送消息但不触发内容生成","/sendas– 以指定角色身份发送消息","/comment- 添加对 AI 不可见的聊天注释","/impersonate- 要求 AI 以您的身份进行回复（可提供提示词）","/persona- 设置您的用户角色设定","/imagine- 根据文本提示生成图像","/bg- 通过文件名设置背景图片"]}],[{"l":"\uD83D\uDE80 快捷键指南","p":["✨ 要获取 SillyTavern 实例中最新的快捷键列表，请在任意聊天中输入 /help hotkeys 命令。","\uD83D\uDCF1 移动设备禁用快捷键功能。"]},{"l":"\uD83D\uDCAC 聊天快捷键","p":["↑ 上箭头= 编辑聊天中的上一条消息","Ctrl + ↑= 编辑聊天中上一条用户消息","← 左箭头= 左滑（撤销操作）","→ 右箭头= 右滑（恢复操作）","⚠️ 输入框中有内容时，滑动快捷键禁用","Enter（输入框选中时）= 发送消息至 AI","Ctrl + Enter= 重新生成上一条 AI 回复","Alt + Enter= 继续生成上一条 AI 回复","Esc","（编辑消息且启用了自动保存时）= 关闭编辑框","（AI 正在生成或流式输出消息时）= 立即停止生成"]},{"l":"\uD83D\uDCDD Markdown 快捷键","p":["⚠️ 需在「用户设置」中启用。适用于输入框及带有 M↓ 图标的文本区域：","Ctrl + B= 加粗","Ctrl + I= 斜体","Ctrl + U= 下划线","Ctrl + K= 行内代码","Ctrl + Shift + ~= 删除线"]}],[{"l":"⚙️ 通用设置","p":["此处设置控制使用语言模型生成文本时的采样过程。这些设置的含义对所有支持的 后端 是通用的。"]},{"l":"\uD83D\uDCD6 上下文设置"},{"l":"生成长度（词元数）","p":["API 生成响应所使用的 最大词元数。","生成长度越高，生成响应所需时间越长。","如果 API 支持，可启用 流式传输，以便在响应生成过程中逐段显示。","关闭 流式传输 后，响应将在完成后一次性显示。"]},{"l":"上下文长度（词元数）","p":["SillyTavern 作为提示词发送给 API 的 最大词元数（需减去响应长度）。","上下文包含角色信息、系统提示、聊天历史等。","消息之间的虚线表示聊天的上下文范围，该线上方的消息不会发送给 AI。","生成消息后，点击 提示词分解 消息选项（展开 ... 菜单并点击带线方框图标）可查看上下文的组成。"]},{"l":"\uD83C\uDF9B️ 采样器参数"},{"l":"温度 (Temperature)","p":["控制词元选择的随机性：","低温度(<1.0) 生成更可预测的文本，偏向高概率词元。","高温度(>1.0) 通过增加低概率词元的选择机会，提升输出的创造性和多样性。","设置为 1 可使用原始概率。"]},{"l":"重复惩罚 (Repetition Penalty)","p":["通过根据词元在上下文中出现的频率进行惩罚，以 抑制重复。","设置为 1 可禁用此效果。"]},{"l":"重复惩罚范围 (Repetition Penalty Range)","p":["考虑重复惩罚的、从最后一个生成词元算起的词元数量。设置过高会破坏响应，因为常见词（如 “the”、“a”、“and” 等）将受到最大惩罚。","设置为 0 可禁用此效果。"]},{"l":"重复惩罚斜率 (Repetition Penalty Slope)","p":["如果此项和 重复惩罚范围 均大于 0，则重复惩罚在提示词末尾的效果更强。值越高，效果越强。","设置为 0 可禁用此效果。"]},{"l":"前 K 采样 (Top K)","p":["设置可供选择的最大顶级词元数量。例如，如果 Top K 为 20，则意味着只保留排名最高的 20 个词元（无论其概率分布广泛还是有限）。","设置为 0（或根据后端设置为 -1）可禁用。"]},{"l":"前 P 采样 (Top P)","p":["前 P 采样（又称核采样）累加顶级词元，直至达到目标百分比。如果前 2 个词元概率均为 25%，且 Top P 为 0.50，则仅考虑前 2 个词元。","设置为 1 可禁用此效果。"]},{"l":"典型 P 采样 (Typical P)","p":["根据词元与集合平均熵的偏差来优先选择词元。它保留累积概率接近预定义阈值（例如 0.5）的词元，强调那些具有平均信息量的词元。","设置为 1 可禁用此效果。"]},{"l":"最小 P 采样 (Min P)","p":["通过剔除与顶级词元相比概率较低的词元来限制词元池。可生成更连贯的响应，但设置过高也可能加剧重复。","在较低值（如 0.1-0.01）下效果最佳，但也可与高 温度 配合设置更高值。例如： 温度: 5, 最小 P: 0.5","设置为 0 可禁用此效果。"]},{"l":"前 A 采样 (Top A)","p":["根据最高词元概率的平方设置词元选择阈值。例如，如果 Top-A 值为 0.2，且顶级词元概率为 50%，则概率低于 5% (0.2 * 0.5^ 2) 的词元将被排除。","设置为 0 可禁用此效果。"]},{"l":"无尾采样 (Tail Free Sampling, TFS)","p":["通过使用导数分析词元概率的变化率，搜索分布中的低概率词元尾。它根据归一化二阶导数保留达到阈值（例如 0.3）的词元。越接近 0，丢弃的词元越多。","设置为 1 可禁用此效果。"]},{"l":"平滑因子 (Smoothing Factor)","p":["使用二次变换增加高概率词元的可能性，同时降低低概率词元的可能性。旨在无论 温度 如何，都能产生更具创造性的响应。","不与截断采样器（如 Top K、 Top P、 Min P 等）一起使用时效果最佳。","设置为 0 可禁用此效果。"]},{"l":"动态温度 (Dynamic Temperature)","p":["根据顶级词元的可能性动态调整温度。旨在不牺牲连贯性的前提下产生更具创造性的输出。","接受从最小到最大的温度范围。例如： 最小温度: 0.75 和 最大温度: 1.25","指数 根据顶级词元应用指数曲线。","取消勾选可禁用此效果。"]},{"l":"Epsilon 截断 (Epsilon Cutoff)","p":["设置一个概率下限，低于该值的词元将被排除在采样之外。单位为 1e-4；合理值为 3。","设置为 0 可禁用。"]},{"l":"Eta 截断 (Eta Cutoff)","p":["特殊 Eta 采样技术的主要参数。单位为 1e-4；合理值为 3。详情参见论文 Truncation Sampling as Language Model Desmoothing by Hewitt et al. (2022)。","设置为 0 可禁用。"]},{"l":"DRY 重复惩罚 (DRY Repetition Penalty)","p":["DRY 会惩罚那些将输入末尾扩展为输入中先前出现过的序列的词元。如果您想允许逐字重复某些序列（例如名称），可以将其添加到序列中断器列表中。参见 Pull Request 此处。","将乘数设置为 0 可禁用。"]},{"l":"排除顶级选择 (Exclude Top Choices, XTC)","p":["XTC 采样算法移除最可能的词元而非修剪最不可能的词元。它以给定概率移除除符合给定阈值的最不可能词元之外的所有词元。这确保了至少有一个“可行”选择保留，从而保持连贯性。参见 Pull Request 此处。","将概率设置为 0 可禁用。"]},{"l":"Mirostat","p":["Mirostat 将输出复杂度与输入匹配，从而避免重复陷阱（自回归推理生成文本时，输出复杂度趋于零）和混淆陷阱（复杂度发散）。详情参见论文 Mirostat: A Neural Text Decoding Algorithm that Directly Controls Perplexity by Basu et al. (2020)。","模式选择 Mirostat 版本。","0 = 禁用，","1 = Mirostat 1.0（仅限 llama.cpp），","2 = Mirostat 2.0。"]},{"l":"束搜索 (Beam Search)","p":["一种用于 LLM 采样的贪婪暴力算法，用于查找最可能的单词或词元序列。它同时扩展多个候选序列，并在每一步保留固定数量（束宽）的顶级序列。"]},{"l":"Top nsigma","p":["一种基于统计特性过滤逻辑值的采样方法。它保留最大逻辑值 n 个标准偏差范围内的词元，提供了一种更简单的 top-p/top-k 采样替代方案，同时在不同温度下保持采样稳定性。"]}],[{"l":"API Connections","p":["SillyTavern can connect to a wide range of LLM APIs. Below is a description of their respective strengths, weaknesses, and use cases."]},{"l":"ELI5: Chat Completions vs Text Completions","p":["When you first navigate to the \"API Connections\" page in ST, you will notice a drop-down option to select between options using nomenclature such as \"Chat Completion\" and \"Text Completion\". It's helpful to understand what this means.","What it's not: It's easy to think of \"Text Completion\" as local models and \"Chat Completion\" as cloud-based LLMs, but that's not the case. Neither is e.g. \"Novel AI\" or \"Kobold\" actually a separate type of model altogether, even though they are separate options in the API dropdown in ST. You can force models into different API structures with the appropriate backend, but that's not the point of this section.","When you send a message using ST, your chat, character description, and other prompts such as lorebooks or author's notes are constructed into a single \"prompt\" to be sent to the model. The API \"type\" for the model you are using decides how exactly this prompt will be constructed (something that ST takes care of for you automatically in the background - you can open your ST terminal and see exactly what the prompt being sent to the AI looks like)."]},{"l":"Chat Completions","p":["A Chat Completion model, as its name suggests, will structure your prompt into a series of messages between the User (you) and the Assistant (the AI) or System (neutral). Models that are trained for Chat Completion help create the feeling of a \"Chat\", with the AI \"responding\" to the last message. When you're using the ChatGPT website, you're dealing with a Chat Completions API in the background."]},{"l":"Text Completions (a.k.a just \"Completions\")","p":["A Text Completion on the other hand, and again as its name suggests, will convert your prompt into one long string, and the model will simply try to continue this (like, literally imagine all your text, your hundreds of messages, all your formatting, newlines, etc. squashed into one very long sentence).","If your messages in ST happen to be formatted as a series of messages between YourPersona: and Character:, the Text Completion model will try to continue this pattern and ST will render it as a new chat message for you, but really the model is just trying to continue the text. If you offered an input of \"The Sun rises in the\", a text completion model is likely to finish that message for you with \"East\".","Most Text Completion models have a recommended \"Instruct Template\" (usually mentioned in the model's documentation or download page) that helps them \"respond\" to messages and instructions, just like a Chat Completion model. ST usually has most (if not all) Instruct Templates available for you to choose from in the \"Advanced Formatting\" page."]},{"l":"Local APIs","p":["These LLM APIs can be run on your PC.","They are free to use and have no content filter.","Installation process can be complex ( The SillyTavern dev team does not provide support for this).","Requires separate download of LLM models from HuggingFace which can be 5-50GB each.","Most models are not as powerful as cloud LLM APIs."]},{"l":"KoboldCpp","p":["Easy-to-use API with CPU offloading (helpful for low VRAM users) and streaming","Runs from a single binary file on Windows, Mac, and Linux","Supports GGUF models","Slower than GPU-only loaders such as AutoGPTQ and Exllama/v2","GitHub, Setup Instructions"]},{"l":"llama.cpp","p":["The original source from which KoboldCpp and Ollama were forked","Provides pre-compiled binaries and an option to compile from source","Supports GGUF models","Lightweight CLI interface for llama-server","GitHub"]},{"l":"Ollama","p":["Easiest to set up and use of all llama.cpp-based APIs","A nifty catalog of models available for one-click download","Supports GGUF models wrapped in Ollama's own format","GitHub, Website"]},{"l":"Oobabooga TextGeneration WebUI","p":["All-in-one Gradio UI with streaming","Broadest support for quantized (AWQ, Exl2, GGML, GGUF, GPTQ) and FP16 models","One-click installers available","Regular updates, which can sometimes break compatibility with SillyTavern","GitHub","Correct Way to Connect SillyTavern to Ooba's new OpenAI API:","Make sure you're on the latest update of Oobabooga's TextGen (as of Nov 14th, 2023).","Edit the CMD_FLAGS.txt file, and add the --api flag there. Then restart Ooba's server.","Connect ST to http://localhost:5000/(by default) without checking the 'Legacy API' box. You may remove the /v1 postfix from the URL Ooba's console provides you.","You can change the API hosting port with the --api-port 5001 flag, where 5001 is your custom port."]},{"l":"TabbyAPI","p":["Lightweight Exllamav2-based API with streaming","Supports Exl2, GPTQ, and FP16 models","Official extension allows loading/unloading models directly from SillyTavern","Not recommended for users with low VRAM (no CPU offloading)","GitHub, Setup Instructions"]},{"l":"KoboldAI Classic (deprecated, abandoned)","p":["Runs on your PC, 100% private, wide range of models available","Gives the most direct control of the AI's generation settings","Requires large amounts of VRAM in your GPU (6-24GB, depending on the LLM model)","Models limited to 2k context","No streaming","Popular KoboldAI versions:","Henky's United","0cc4m's 4bit-supporting United"]},{"l":"Cloud LLM APIs","p":["These LLM APIs are run as cloud services and require no resources on your PC","They are stronger/smarter than most local LLMs","However, they all have content filtering of varying degrees, and most require payment"]},{"l":"AI Horde","p":["SillyTavern can access this API out of the box with no additional settings required","Uses the GPU of individual volunteers (Horde Workers) to process responses for your chat inputs","At the mercy of the Worker in terms of generation wait times, AI settings, and available models","Website, Setup Instructions"]},{"l":"OpenAI (ChatGPT)","p":["Easy to set up and acquire an API key","Requires prepayment for credits and charges per prompt","Very logical. Creative style can be repetitive and predictable","Most of the newer models (gpt-4-turbo, gpt-4o) support multimodality","Website, Setup Instructions"]},{"l":"Claude (by Anthropic)","p":["Recommended for users who want their AI chats to have a creative, unique writing style","Requires prepayment for credits and charges per prompt","The newest models (Claude 3) support multimodality","Requires a specific prompting style and utilization of prefills for reply steering","Website, Setup Instructions"]},{"l":"Google AI Studio and Vertex AI","p":["Has a free tier with rate limits (Gemini Flash), may require billing information","AI Studio usually has the latest models and features","Vertex AI is trickier to set up, but more stable","Setup Instructions"]},{"l":"Mistral (by Mistral AI)","p":["Efficient models of various sizes and use cases. You can create an account and API key on their platform.","From 32k to 128k context sizes for general use, and 32k to 256k context sizes for coding.","Free Tier with rate limits.","Reasonable moderation, with Mistral's main principles being to be neutral and empower users, more information here.","Website, Setup Instructions"]},{"l":"OpenRouter","p":["Provides a unified API to access all the major LLMs on the market","Pay-per-token credit system, as well as free models with limited daily requests","No enforced moderation, unless required by the LLM vendor","Website, Setup Instructions"]},{"l":"DeepSeek","p":["Provides access to the latest versions of very popular DeepSeek V3 ( deepseek-chat) and DeepSeek R1 ( deepseek-reasoner) models","Requires a payment for credits ($2 minimum), but the models are fairly cheap for their quality","No moderation on the API, but the models may refuse certain prompts","Website, Setup Instructions"]},{"l":"AI21","p":["Provides access to Jamba Family open models","Has a free trial ($10 for three months), then requires to pay monthly per token","Website, Setup Instructions"]},{"l":"Cohere","p":["Provides access to the latest models from Cohere (command-r, command-a, c4ai-aya, etc.)","Has a free tier (Trial Keys) with enough rate limits for casual use","Website, Setup Instructions"]},{"l":"Perplexity","p":["Provides access to unique Perplexity Sonar online-enabled models via their API","Requires to have billing configured and credits purchased","Website, Setup Instructions"]},{"l":"Mancer AI","p":["Service that hosts unconstrained models of various families","Uses 'credits' to pay for tokens on various models","Does not log prompts by default, but you can enable it to get credit discounts on tokens.","Uses an API similar to Oobabooga TextGeneration WebUI, see Mancer docs for details.","Website, Setup Instructions"]},{"l":"DreamGen","p":["Uncensored models tuned for steerable creative writing","Free monthly credits, as well as a paid subscription","Models ranging from 7B to 70B","Setup Instructions"]},{"l":"Pollinations","p":["Requires no setup, can be used out of the box","Provides access to a wide range of models free of charge","Outputs may occasionally include ads with links to third-party services"]},{"l":"NovelAI","p":["No content filter, the latest model is based on Llama 3","Paid subscription required, the tier determines the max context length","Website, Setup Instructions"]},{"l":"AI/ML API","p":["Unified API for 300+ models including Claude, GPT-4o, Gemini, LLaMA 3, Mistral and others","Has a free tier with rate limits, subscription plans, and pay-as-you-go options","Website, Docs, Models"]}],[{"l":"Connection Profiles","p":["Save Connection Profiles to quickly switch between different APIs, models and formatting templates. This is useful when you actively use multiple API connections or need to switch between different configurations without surfing through the menus."]},{"l":"Accessing Connection Profiles","p":["This feature is enabled by default starting from SillyTavern 1.12.6 or later as a built-in extension, and available in the API Connections menu. If you wish to disable it, open the Extensions panel, click on \"Manager extensions\", locate Connection Profiles in the list, uncheck the \"Enabled\" checkbox, and then click \"Close\"."]},{"l":"What is Saved","p":["Connection Profiles store the following selections."]},{"l":"Common","p":["API type, model and the server URL","Secret Key","Settings preset","Start Reply With(can be explicitly empty)","Custom Stopping Strings(can be explicitly empty)","Reasoning Formatting"]},{"l":"Text Completion APIs","p":["System Prompt and its state","Instruct Mode state and template","Context Template","Tokenizer"]},{"l":"Chat Completion APIs","p":["Prompt Post-Processing","Proxy preset"]},{"l":"Managing Connection Profiles","p":["Profiles only save the selection in dropdown fields, without knowing anything about the underlying settings. This means that you will lose unsaved changes by switching to a different profile. To prevent this, make sure to update all presets and templates if you don't want to lose ephemeral changes.","To save a profile, set all the required settings and click the \"Create\" button. Then review the settings and provide a name for the profile. A name should be unique.","To view the detailed information about a chosen profile, click on the \"Information\" button. Click again to hide the details.","Connection Profile settings are saved into settings.json without altering the associated profile save file until you press the \"Update\" button. This means that if you setup a profile, but then switch to a different one without updating, you will lose all of your previous changes.","To restore the changed selections from a saved profile, click the \"Reload\" button.","To delete a profile, click the \"Delete\" button and confirm the deletion. This action is irreversible."]},{"l":"Slash Commands","p":["Connection profiles can be managed using the following slash commands.","/profile [name]- switch to a profile if the argument is provided, or get the name of the current profile if not.","/profile-create [name]- saves the current settings as a new profile with the provided name.","/profile-list- returns a JSON-serialized array of available profile names.","/profile-get [name]- gets the details of the profile with the provided name as a JSON-serialized object.","/profile-update- updates the selected profile with the current settings."]}],[{"l":"Self-hosted AI models","p":["This guide is based on the author's personal experience and knowledge and is not an absolute truth. All statements should be taken with a grain of salt. If you have any corrections or suggestions, please contact us on Discord or send a PR to the SillyTavern documentation repository."]},{"l":"Intro","p":["This guide aims to help you get set up using SillyTavern with a local AI running on your PC (we'll start using the proper terminology from now on and call it an LLM). Read it before bothering people with tech support questions."]},{"l":"What are the best Large Language Models?","p":["It is impossible to answer this question as there's no standardized scale of \"Best\". The community has enough resources and discussions going on Reddit and Discord to form at least some opinion on what is the preferred / go-to model. Your mileage may vary."]},{"l":"What is the best configuration?","p":["If there was a best or no-brainer setup, would there even have to be a need for configuration? The best configuration is the one that works for you. It's a trial-and-error process."]},{"l":"Hardware requirements and orientation","p":["This is a complex subject, so I'll stick to the essentials and generalize.","There are thousands of free LLMs you can download from the Internet, similar to how Stable Diffusion has tons of models you can get to generate images.","Running an unmodified LLM requires a monster GPU with a ton of VRAM (GPU memory). More than you will ever have.","It is possible to reduce VRAM requirements by compressing the model using quantization techniques, such as GPTQ or AWQ. This makes the model somewhat less capable, but greatly reduces the VRAM requirements to run it. Suddenly, this allowed people with gaming GPUs like a 3080 to run a 13B model. Even though it's not as good as the unquantized model, it's still good.","It gets better: there also exists a model format and quantization called GGUF (previously GGML) which has become the format of choice for normal people without monster GPUs. This allows you to use an LLM without a GPU at all. It will only use CPU and RAM. This is much slower (probably 15 times) than running the LLM on a GPU using GPTQ/AWQ, especially during the prompt processing, but the model's ability is just as good. The GGUF creator then optimized GGUF further by adding a configuration option that allows people with a gaming-grade GPU to offload parts of the model to the GPU, allowing them to run part of the model at GPU speed (note that this doesn't reduce RAM requirements, it only improves your generation speed).","There are different sizes of models, named based on the number of parameters they were trained with. You will see names like 7B, 13B, 30B, 70B, etc. You can think of these as the brain size of the model. A 13B model will be more capable than the 7B from the same family of models: they were trained on the same data, but the bigger brain can retain the knowledge better and think more coherently. Bigger models also require more VRAM/RAM.","There are several degrees of quantization (8-bit, 5-bit, 4-bit, etc). The lower you go, the more the model degrades, but the lower the hardware requirements. So even on bad hardware, you might be able to run a 4-bit version of your desired model. There's even 3-bit and 2-bit quantization but at this point, you're beating a dead horse. There's also a further quantization subtypes named k_s, k_m, k_l, etc. k_m is better than k_s but requires more resources.","The context size (how long your conversation can become without the model dropping parts of it) also affects VRAM/RAM requirements. Thankfully, this is a configurable setting, allowing you to use a smaller context to reduce VRAM/RAM requirements. (Note: the context size of Llama2-based models is 4k. Mistral is advertised as 8k, but it's 4k in practice.)","Sometime in 2023, NVIDIA changed their GPU driver so that if you need more VRAM than your GPU has, instead of the task crashing, it will begin using regular RAM as a fallback. This will ruin the writing speed of the LLM, but the model will still work and give the same quality of output. Thankfully, this behavior can be disabled.","Given all of the above, the hardware requirements and performance vary completely depending on the family of model, the type of model, the size of the model, the quantization method, etc."]},{"l":"Model size calculator","p":["You can use Nyx's Model Size Calculator to determine how much RAM/VRAM you need.","Remember, you want to run the largest, least quantized model that can fit in your memory, i.e. without causing disk swapping."]},{"l":"Downloading an LLM","p":["To get started, you will need to download an LLM. The most common place to find and download LLMs is on HuggingFace. There are thousands of models available. A good way to find GGUF models is to check bartowski's account page: https://huggingface.co/bartowski. If you don't want GGUF, he links the original model page where you might find other formats for that same model.","On a given model's page, you will find a whole bunch of files.","You might not need all of them! For GGUF, you just need the .gguf model file (usually 4-11GB). If you find multiple large files, it's usually all different quantizations of the same model, you only need to pick one.","For .safetensors files (which can be GPTQ or AWQ or HF quantized or unquantized), if you see a number sequence in the filename like model-00001-of-00003.safetensors, then you need all 3 of those .safetensors files + all the other files in the repository (tokenizer, configs, etc.) to get the full model.","As of January 2024, Mixtral MOE 8x7B is widely considered the state of the art for local LLMs. If you have the 32GB of RAM to run it, definitely try it. If you have less than 32GB of RAM, then use Kunoichi-DPO-v2-7B, which despite its size is stellar out of the gate."]},{"l":"Walkthrough for downloading Kunoichi-DPO-v2-7B","p":["We will use the Kunoichi-DPO-v2-7B model for the rest of this guide. It's an excellent model based on Mistral 7B, that only requires 7GB RAM, and punches far above its weight. Note: Kunoichi uses Alpaca prompting.","Go to https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF","Click 'Files and versions'. You will see a listing of several files. These are all the same model but offered in different quantization options. Click the file 'kunoichi-dpo-v2-7b.Q6_K.gguf', which gives us a 6-bit quantization.","Click the 'download' button. Your download should start."]},{"l":"How to identify the type of model","p":["Good model uploaders like TheBloke give descriptive names. But if they don't:","Filename ends in .gguf: GGUF CPU model (duh)","Filename ends in .safetensors: can be unquantized, or HF quantized, or GPTQ, or AWQ","Filename is pytorch-***.bin: same as above, but this is an older model file format that allows the model to execute arbitrary Python script when the model is loaded, and is considered unsafe. You can still use it if you trust the model creator, or are desperate, but pick .safetensors if you have the option.","config.json exists? Look if it has a quant_method.","q4 means 4-bit quantization, q5 is 5-bit quantization, etc","You see a number like -16k? That's an increased context size (i.e. how long your conversation can get before the model forgets the beginning of your chat)! Note that higher context sizes require more VRAM."]},{"l":"Installing an LLM server: Oobabooga or KoboldAI","p":["With the LLM now on your PC, we need to download a tool that will act as a middle-man between SillyTavern and the model: it will load the model, and expose its functionality as a local HTTP web API that SillyTavern can talk to, the same way that SillyTavern talks with paid webservices like OpenAI GPT or Claude. The tool you use should be either KoboldAI or Oobabooga (or other compatible tools).","This guide covers both options, you only need one.","If you are hosting SillyTavern on Docker, use http://host.docker.internal:\\<port> instead of http://127.0.0.1:\\<port>. This is because SillyTavern connects to the API endpoint from the server running in the Docker container. Docker's network stack is separate from the host's, and so the loopback interfaces are not shared."]},{"l":"Downloading and using KoboldCpp (No installation required, GGUF models)","p":["Visit https://koboldai.org/cpp where you will see the latest version with various files you can download. At the time of writing the newest CUDA version they list is cu12 which will work best on modern Nvidia GPU's, if you have an older GPU or a different brand you can use the regular koboldcpp.exe. If you have an old CPU its possible that KoboldCpp will crash when you try to load models, in that case try the _ oldcpu version to see if it resolves your issue.","KoboldCpp does not need to be installed, once you start KoboldCpp you will immediately be able to select your GGUF model such as the one linked above using the Browse button next to the Model field.","By default KoboldCpp runs at a maximum of 4K context even if you set this higher in SillyTavern, if you wish to run a model at higher context make sure to adjust the context slider on this screen before launching the model. Keep in mind that more context size means higher (video) memory requirements, if you set this to high or load a model that is to big for your system KoboldCpp will automatically begin using your CPU for the layers it can not fit on your GPU, this will be much slower.","Click Launch, if everything goes well a new webpage will open with KoboldAI Lite where you can test if everything works correctly.","Open SillyTavern and click API Connections (2nd button in the top bar)","Set API to Text Completion and the API Type to KoboldCpp.","Set server URL to http://127.0.0.1:5001/ or the link that KoboldCpp gave you in case it is not running on the same system (You can activate KoboldCpp's Remote Tunnel mode to obtain a link that can be accessed from anywhere).","Click Connect. It should connect successfully and detect kunoichi-dpo-v2-7b.Q6_K.gguf as the model.","Chat with a character to test that it works."]},{"l":"Tips for Optimizing KoboldCpp's speed","p":["Flash Attention will help reduce the memory requirements, it can be faster or slowing depending on your system and will allow you to fit more layers on your GPU than the default.","KoboldCpp will leave some space for other software when it guesses layers to prevent issues, if you have few programs open and are unable to fit the model entirely in the GPU you may be able to add a few extra layers.","If the model uses up to much memory for the context size you can decrease this by Quantizing the KV. This will reduce the quality of the output but can help you put more layers on the GPU. To do this you go to the Tokens tab in KoboldCpp and then disable Context Shifting and enable Flash Attention. This will unlock the Quantized KV Cache slider, a lower number means less memory / intelligence of the model.","Running KoboldCpp on a slower system where it takes long to process the prompt? Context Shifting works best when you avoid using Lorebooks, randomization or other features that dynamically change the input. Leaving context shifting enabled KoboldCpp will help you avoid long reprocessing times."]},{"l":"Installing Oobabooga","p":["Here's a more correct/dummy proof installation procedure:","git clone https://github.com/oobabooga/text-generation-webui(or download their repo as a .zip in your browser, then extract it)","Run start_windows.bat or whatever your OS is","When asked, select your GPU type. Even if you intend to use GGUF/CPU, if your GPU is in the list, select it now, because it will give you the option to use a speed optimization later called GPU sharding (without having to reinstall from scratch). If you have no gaming-grade dGPU (NVIDIA, AMD), select None.","Wait for the installation to finish","Place kunoichi-dpo-v2-7b.Q6_K.gguf in text-generation-webui/models","Open text-generation-webui/CMD_FLAGS.txt, delete everything inside and write: --api","Restart Oobabooga","Visit http://127.0.0.1:5000/docs. Does it load a FastAPI page? If not, you messed up somewhere."]},{"l":"Loading our model in Oobabooga","p":["Open http://127.0.0.1:7860/ in your browser","Click the Model tab","In the dropdown, select our Kunoichi DPO v2 model. It should have automatically selected the llama.cpp loader.","(Optional) We mentioned 'GPU offload' several times earlier: that's the n-gpu-layers setting on this page. If you want to use it, set a value before loading the model. As a basic reference, setting it to 30 uses just under 6GB VRAM for 13B and lower models. (it varies with model architecture and size)","Click Load"]},{"l":"Configuring SillyTavern to talk to Oobabooga","p":["Click API Connections (2nd button in the top bar)","Set API to Text Completion","Set API Type to Default (Oobabooga)","Set server URL to http://127.0.0.1:5000/","Click Connect. It should connect successfully and detect kunoichi-dpo-v2-7b.Q6_K.gguf as the model.","Chat with a character to test that it works"]},{"l":"Conclusion","p":["Congrats, you should now have a working local LLM."]}],[{"l":"Chat Completions"},{"l":"Source-specific instructions","p":["Most API platforms allow to view the generated API key only once, at the time of its creation. If you lose it, you will need to generate a new one. Make sure to keep it safe!"]},{"l":"OpenAI","p":["Use OpenAI's developer platform to access various OpenAI models, including gpt-4o, gpt-4.1, o3, etc.","How to get an API key:","Go to OpenAI and sign in.","Use \" View API keys\" option to create a new API key."]},{"l":"Claude","p":["Claude is a family of AI models developed by Anthropic. You can access Claude models through the Anthropic console.","How to get an API key:","Go to Anthropic Console and sign in.","Use the \" Get API Key\" section to create a new API key."]},{"l":"Mistral AI","p":["Mistral AI is a team developing both open and proprietary models with high scientific standards and a focus on openness. You can run their models locally or through their API service, La Plateforme.","How to get an API key:","The first step is to create an account on La Plateforme.","Once that's done, you can choose a plan and set up your payment information or opt for the Free Tier.","Next, you can create your API key. You may need to wait a couple of minutes before the key becomes valid!"]},{"l":"DeepSeek","p":["DeepSeek Platform provides access to the latest DeepSeek models through an API. They offer a range of models, including DeepSeek V3 and DeepSeek R1.","How to get an API key:","Sign up on the DeepSeek Platform.","After signing up and topping up your account, you can create an API key in the \" API keys\" section."]},{"l":"AI21","p":["AI21 Labs offers a range of AI models, including their flagship Jamba series. You can access their models through the AI21 Studio API.","How to get an API key:","Go to AI21 Studio and sign in.","Navigate to the \"Settings => API Keys\" section to create a new API key."]},{"l":"Cohere","p":["Cohere provides a suite of AI models for various tasks, including text generation and embeddings. You can access their models through the Cohere API.","How to get an API key:","Go to Cohere and sign in.","Navigate to the \" API Keys\" section in your account settings to create a new API key."]},{"l":"Perplexity","p":["Perplexity AI offers access to online-enabled Sonar models through their API for real-time research and information retrieval.","Official Getting Started guide: Perplexity Quickstart","How to get an API key:","Go to Perplexity and sign in.","Go to the \" API billing\" section to purchase credits for API usage.","Navigate to the \" API keys\" section in the settings to create a new API key."]},{"l":"Fireworks AI","p":["Fireworks AI is a high-performance platform that provides fast, cost-effective access to state-of-the-art open-source language models. The platform offers serverless deployment with OpenAI-compatible APIs and supports context windows up to 256,000 tokens.","How to get an API key:","Go to Fireworks AI and create an account or sign in.","Navigate to the API Keys page in your account settings.","Click \"Create API key\" and provide a descriptive name (e.g., \"SillyTavern\")."]},{"l":"Custom OpenAI-compatible endpoint","p":["It is important to note that we do not provide support for possible issues that you may have! We do not guarantee compatibility with every possible API endpoint!","If you intend to use this feature to use a local endpoint, like TabbyAPI, Oobabooga, Aphrodite, or any like those, you might want to check out the built-in compatibility for those instead. The custom endpoint feature is mainly intended for use with other services and programs that expose an OpenAI-compatible API Chat Completion endpoint.","Most Text Completion APIs support far greater customization options than OpenAI's standards allow for. These greater customization options, such as the Min-P sampler, may be worthwhile for SillyTavern users to check out, which can greatly improve the quality of generations.","You can configure an alternative endpoint for the Chat Completions backend. This custom endpoint can connect to any server that supports the generic OpenAI API schema.","Examples of compatible backends include:","LM Studio","LiteLLM","LocalAI"]},{"l":"Connecting","p":["To access this feature:","Switch to the 'Chat Completion' API type","Select 'Custom (OpenAI-compatible)' for 'Chat Completion Source'","Enter the custom endpoint URL and an API key if required. For example, TabbyAPI requires an API key for authentication.","Hint: If you experience connection issues, try adding /v1 to the end of the endpoint URL. Do NOT add the /chat/completions suffix."]},{"l":"Selecting a Model","p":["If the custom API implements the /v1/models endpoint to provide a list of available models, you can choose from a dropdown list. Otherwise, use the text field to manually input a model ID.","Check 'Bypass API status check' to prevent SillyTavern from alerting you about a non-functioning API endpoint. Enable this option if your API endpoint works properly but SillyTavern continues to display warnings.","Click \"Test Message\" to verify connectivity by sending a simple prompt to the model."]},{"l":"Prompt Post-Processing","p":["Note: Tool Calling is not supported when Post-Processing option with \"no tools\" is used!","Some endpoints may impose specific restrictions on the format of incoming prompts, such as requiring only one system message or strictly alternating roles.","SillyTavern provides built-in prompt converters to help meet these requirements (from least to most restrictive):","None - no explicit processing applied unless strictly required by the API","Merge consecutive messages from the same role","Semi-strict - merge roles and allow only one optional system message","Strict - merge roles, allow only one optional system message, and require a user message to be first","Single user message - merge all messages from all roles into a single user message","Merge, semi-strict, and strict additionally remove any tool calls from the prompt, unless the \"with tools\" variant is selected. This is useful for APIs that do not support tool calling and your existing prompts contain tool calls.","Less restrictive options have no effect on more restrictive endpoints implemented in SillyTavern other than \"Custom OpenAI-compatible\"; Custom may error upon invalid request.","In strict mode, if no user message exists before the first assistant message, then promptPlaceholder from config.yaml will be inserted, which by default is \"[Start a new chat]\"."]}],[{"l":"OpenRouter","p":["OpenRouter is available as both a Text Completion and Chat Completion source. All models are available through either API, but their features may differ depending on the API type you choose. For example, image inlining and tool calling are only available with the Chat Completion API.","Don't want to sign up for a dozen API services, but still want access to all the latest models? Use OpenRouter.","OpenRouter works by letting you use a single endpoint to access models like DeepSeek, Claude, and Gemini, all in one service with a shared credit pool.","It has a free trial (about $1) and paid access afterward. No subscription or monthly bill - you pay for what you actually use. Some models have free access with a limited number of daily requests.","To get permanent access to free models with a generous daily limit, you need to buy at least $10 in credits once.","See more details on the OpenRouter FAQ page.","Create an OpenRouter account: openrouter.ai","OpenRouter Models List","OpenRouter-ConnectionPanel","From top to bottom (see image above):","Select the 'Chat Completion' API.","Select OpenRouter as the source.","Click \"Authorize\" to get a key using the OAuth flow. Alternatively, generate an API key here and paste it into the box.","Click \"Connect\" and select a model.","(Optional) Use the \"Test Message\" button to verify your connection."]}],[{"l":"AI Horde"},{"l":"Disclaimer","p":["AI Horde is a crowdsourced, distributed GPU cluster run entirely by volunteers.","By default, your inputs are anonymously sent and responses can not be seen by the person running the Horde Worker.","However, since it is an open-sourced program, Malicious Workers could modify the code to:","log your activity (input prompts, AI responses).","produce bad or offensive responses.","When using Horde never send any personal information such as names, email addresses, etc.","Switching on the \"Trusted Workers Only\" checkbox will limit the selection of available workers to only those who have been hosting on Horde for a while and are generally considered trusted. But they could still be seeing prompts, for example by hosting using unaccounted software.","To help reduce this problem, SillyTavern has built in the following feature:","When a chat response is generated by a Horde Worker, SillyTavern records the Worker's ID and what model they were using.","This information can be seen by hovering your mouse cursor over the chat item (see image below).","If you believe you received a malicious response, you can pass this information to the Horde admin on the AI Horde Discord for review and possible disciplinary action against that Worker.","Horde Worker Info Popup"]},{"l":"Setup","p":["SillyTavern is able to connect with Horde out of the box with no additional setup required.","Select 'AI Horde' from the API Dropdown Selector in the ST API Panel.","Select one or more Models ('AI brains' for the characters) from the Model Selector at the bottom of the panel.","Select a character and begin chatting.","ST Kobold Horde API Connection Panel","By default, your SillyTavern instance connects to the Horde's low priority 'guest account'. This means you may have to wait a long time for a reply. To reduce wait times, follow the tips down below."]},{"l":"Tips","p":["Register an account on the Horde website then add your Horde key into the SillyTavern Horde API Key box.","Set up a Horde Worker to provide your GPU for others.","Letting others use your GPU earns you 'Kudos', a kind of Horde-only currency.","The more kudos your account has, the faster you will get chat responses from other Horde Workers.","Kudos can also be used to create AI images on Stable Horde.","SillyTavern supports Stable Horde image generation out of the box.","If your GPU isn't powerful enough to run an AI, or you don't have a computer, you can still participate in the Horde community to earn Kudos in various ways."]}],[{"l":"DreamGen","p":["DreamGen is an app and an API for AI-powered creative writing. They have a free tier, as well as a paid subscription that allows unlimited monthly access to their high-quality in-house text generation models made specifically for the purpose of steerable AI-assisted writing. Create an account to get started: https://dreamgen.com/.","The (free) credits reset at the start of each calendar month. See pricing to see the credit cost for each model and usage to see your remaining credits."]},{"l":"Connecting to DreamGen"},{"l":"Get API Key","p":["Go to the DreamGen API keys page and click the \"New API Key\" button. Make sure the API Key is copied into your clipboard.","Create New DreamGen API key Copy DreamGen API key"]},{"l":"Connect","p":["Go to the SillyTavern connection settings.","Select API: Text Completion","Select API Type: DreamGen","Enter the API key","(optional) Pick a model","Connecting to DreamGen"]},{"l":"Models","p":["DreamGen offers opus-v1-sm, opus-v1-lg, and opus-v1-xl. The larger the model, the better it will be at following instructions and writing good stories."]},{"l":"Formatting Settings","p":["The DreamGen models expect a specific input format, which is documented here.","SillyTavern comes with built-in presets made for DreamGen. Make sure to use these settings as your baseline. These settings try to stick to the DreamGen format as closely as possible but due to the irregular formatting of character cards, it is not always perfect.","Go to the \"Advanced Formatting\" page.","Under \"Context Template\" pick DreamGen Role-Play V1 Llama3 / ChatML depending on the model (*).","Enable \"Instruct Mode\".","Under \"Instruct Mode Presets\" pick DreamGen Role-Play V1 Llama3 / ChatML.","DreamGen context settings DreamGen instruct settings","(*) When to use Llama 3 and when to use ChatML? As of 2024/06/17, opus-v1-sm is ChatML and all other models are Llama3 based. When running local models, the template will be indicated in the model's HuggingFace card."]},{"l":"Completion Settings","p":["DreamGen supports:","\"Temperature\", \"Top P\", \"Top K\" and \"Min P\"","\"Presence Penalty\", \"Frequency Penalty\" and \"Repetition Penalty\" (without range)","\"Min Length\" -- lets you force the model to generate at least min(min_length, max_tokens) tokens","Good starting values might be:","Min P: 0.05","Temperature: 0.8","Repetition Penalty: 1.1"]},{"l":"Tips for Formatting","p":["The DreamGen models differ from the regular instruction-following models like OpenAI's ChatGPT.","The models were fine-tuned for the task of writing a story based on the provided description which typically consists of plot description, style description, characters, locations, lore, etc. The models can also be steered in the middle of the story, making you the director, telling the characters what they should do or how the plot should unfold.","A well-formatted system prompt message would look like this:","Note that the prompt should be a description of the story, rather than instructions or directives on how the story should be written. Avoid using phrases like:","\"Write the story as if...\"","\"Make sure to...\"","etc.","See more examples of what the plot, style and character descriptions should look like.","The default \"DreamGen Role-Play V1\" template substitutes the different sections as follows:","## Plot description: will consist of {{scenario}} and {{wiBefore}}.","## Style description: is not provided, you should either add it to the system prompt under Advanced Settings, or to the character cards, at the end of {{scenario}}. This section is useful to influence the narrative style (first, second, third person), the tense (past, present), the level of detail and verbosity, etc.","## Characters: will have a {{char}} character with description consisting of {{description}} and {{personality}} and a {{user}} character with description consisting of {{persona}}."]},{"l":"Message Examples and Initial Message","p":["The DreamGen models are very responsive to the context -- they will largely stick to the writing style (and facts) presented in the previous conversation turns. This makes the message examples and the initial message very important."]},{"l":"Formatting Message Examples","p":["The {{mesExamples}} are appended at the end of the system prompt. To take full advantage of the instruct formatting, make sure that your examples are separated with the START separator. For example:"]},{"l":"Examples","p":["Here are a couple of example cards, adapted for DreamGen, that take into account the unique prompting. These cards also leverage the {{mesExamples}} as described above."]},{"l":"Seraphina","p":["This is an edit of the popular Seraphina card that's built into SillyTavern by default."]},{"l":"Lara Lightland","p":["This is an edit of the Lara Lightland card by Deffcolony."]},{"l":"FAQ"},{"l":"What sampler settings should I use?","p":["You can start with these:","Temperature: 1.0","MinP: 0.05","Presence Penalty: 0.1","Frequency Penalty: 0.1"]},{"l":"How can I make the responses longer or shorter?","p":["You have several options:","Change or add the ## Style description: in the system prompt or model card. You can try adding something like \"Sentences are generally long, and the narrative describes the setting in painstaking detail.\"","Change the Min Length in the Completion Settings.","Add Last Output Sequence similar to the following in the Advanced Formatting settings under Instruct Mode:","Here's an example of the Last Output Sequence that might help make the model respond in a more verbose way, using the Llama 3 template:","The same expressed using the ChatML template:","You can change the text within to something more suitable for your scenario or context."]},{"l":"How can I stop the model from repeating itself?","p":["If the model repeats what's in the context, you can try increasing \"Repetition Penalty\" in the Completion Settings or you can try rephrasing the part of the context that's getting repeated. If the model repeats itself within one message, you can try increasing \"Presence Penalty\" or \"Frequency Penalty\"."]},{"l":"How can I steer the story?","p":["If you want to direct the characters to do something, or to steer the plot in certain direction, you can use the user role (that is the |im_start|user preamble).","At this point, this functionality is not neatly integrated into SillyTavern natively, but you can use the Last Output Sequence as described above to insert the user(instruction) turn. See examples of what the instructions should look here."]}],[{"l":"Google Gemini","p":["Gemini is Google's cutting-edge multimodal LLM, which is available though several APIs, including Google Vertex AI and Google AI Studio (formerly MakerSuite). This guide will help you set up the Gemini API connections in SillyTavern."]},{"l":"Google AI Studio","p":["AI Studio is the fastest and the most user-friendly way to try out the latest Google AI models without needing to set up a Google Cloud Platform (GCP) project. It provides a simple API key that you can use to access the Gemini models."]},{"l":"Step 1: Create a Google AI Studio Key","p":["Go to the Google AI Studio page and sign in with your Google account.","Click on \"Get API Key\", accept the terms and conditions.","Click \"Create API Key\" to generate your API key.","Copy the API key to your clipboard."]},{"l":"Step 2: Put the API Key into SillyTavern","p":["In SillyTavern, go to the \"API Connections\" page.","Select \"Chat Completion\" as the API type.","Select \"Google AI Studio\" from the dropdown menu.","Enter the API key you copied earlier into the \"API Key\" text box.","Click the \"Connect\" button to save the key.","You should now be able to use the Google AI Studio API with SillyTavern."]},{"l":"Google Vertex AI","p":["Vertex AI is a service provided by Google Cloud Platform (GCP). It provides access to various AI models, including the Gemini series.","There are several ways a Vertex AI API can be set up, and the available models may vary depending on the method used."]},{"l":"Service Account","p":["Google Cloud Platform (GCP) requires a service account to access Vertex AI, simple API keys will not work. A token will be generated from the service account JSON file, which will then be used to authenticate requests to the Vertex AI API.","You can create a service account by following these steps:","Prerequisites:","You must have a Google Cloud Platform (GCP) account.","You must have a project created within your GCP account.","You must have billing enabled for that project."]},{"l":"Step 1: Enable the Vertex AI API","p":["Before your key can work, the API must be enabled for your project.","Go to the Google Cloud Console: https://console.cloud.google.com/","Make sure the correct project is selected in the top bar.","Navigate to the Vertex AI API page: https://console.cloud.google.com/apis/library/aiplatform.googleapis.com","If it's not already enabled, click the \"Enable\" button."]},{"l":"Step 2: Create the Service Account","p":["This is the identity that will be used to access the Vertex AI API.","In the Google Cloud Console, navigate to the \"Service Accounts\" page. You can search for it in the top search bar or use this direct link: https://console.cloud.google.com/iam-admin/serviceaccounts","Select your GCP project and click \"+ CREATE SERVICE ACCOUNT\".","Service account name: Give it a descriptive name, like my-vertex-ai-client.","Click \"CREATE AND CONTINUE\".","Grant this service account access to project: In the \"Role\" dropdown, search for and select Vertex AI User. This role grants the necessary permissions to run models without giving away too much access.","Click \"CONTINUE\", and then click \"DONE\"."]},{"l":"Step 3: Generate the JSON Key","p":["This is the \"password\" file you need. It contains sensitive information, so don't share it or upload it anywhere public.","You should now be back on the Service Accounts list. Find the account you just created (e.g., sillytavern-vertex-ai).","Click the three-dot menu (⋮) on the far right of that row and select \"Manage keys\".","Click \"ADD KEY\" -> \"Create new key\".","Ensure the Key type is set to JSON.","Click \"CREATE\".","A .json file will immediately be downloaded to your computer. Keep it safe, because this key can't be recovered if lost."]},{"l":"Step 4: Put the JSON Content into SillyTavern","p":["The JSON file you downloaded contains all the information needed to authenticate with the Vertex AI API. It will look something like this:","Open the .json file you just downloaded with a simple text editor (like Notepad on Windows, TextEdit on Mac, or VS Code).","Select all the text in the file (Ctrl+A or Cmd+A).","Copy the text to your clipboard (Ctrl+C or Cmd+C).","In SillyTavern, go to the \"API Connections\" page, select \"Chat Completion\" as the API type, and then select \"Google Vertex AI\" from the dropdown menu. Switch the authentication method to \"Service Account\".","Paste the entire copied content into the \"Service Account JSON Content\" text box.","Click the \"Validate JSON\" button to make sure you copied it correctly.","Finally, scroll down and click \"Connect\" at the bottom of the API settings page.","You should now be able to use the Google Vertex AI API with SillyTavern."]},{"l":"Express Mode","p":["Express mode is the quickest way to get started with using Generative AI on Google Cloud. It allows you to use the Gemini API without needing to set up a service account. Instead, you can use an API key directly.","See the official documentation for more details: Vertex AI in express mode overview."]},{"l":"Step 1: Ensure your account is eligible for Express Mode","p":["You must have a Google account that was not previously used to create a Google Cloud project. If you have an existing Google Cloud project (including free trials), you can create a new one for this purpose."]},{"l":"Step 2: Active the Vertex AI Express Mode","p":["Go to the following web page: Vertex AI Studio.","Click on \"Try it free\".","Accept the terms and conditions and sign in with your Google account.","Choose your country and click \"Agree & start free\". Wait for the setup to complete."]},{"l":"Step 3: Create an API Key","p":["Verify that your Google Cloud console is running in Express Mode. You should see a banner at the top left corner of the page.","Click on the \"API Keys\" link in the left sidebar.","Click on the \"Create API Key\" button.","A new API key will be generated. Copy this key to your clipboard."]},{"l":"Step 4: Put the API Key into SillyTavern","p":["In SillyTavern, go to the \"API Connections\" page.","Select \"Chat Completion\" as the API type.","Select \"Google Vertex AI\" from the dropdown menu.","Switch the authentication method to \"Express Mode (API Key)\".","Paste the API key you copied earlier into the \"API Key\" text box.","Click the \"Connect\" button to save the key.","You should now be able to use the Google Vertex AI API in Express Mode with SillyTavern."]}],[{"l":"KoboldCpp","p":["KoboldCpp is a self-contained API for GGML and GGUF models.","This VRAM Calculator by Nyx will tell you approximately how much RAM/VRAM your model requires."]},{"l":"Nvidia GPU Quickstart","p":["As of version 1.58, KoboldCpp should look like this:","Click Launch and wait for the model to load.","Click Save so you don't have to configure KoboldCpp on every launch.","Congratulations! You're done!","Do not tick Low VRAM, even if you have low VRAM.","Download the latest release: https://github.com/LostRuins/koboldcpp/releases","GPU Layers should have been populated when you loaded your model. Leave it there for now.","Kind of.","KoboldCpp 1.58","Launch KoboldCpp. You may see a pop-up from Microsoft Defender, click Run Anyway.","Select Use CuBLAS and make sure the yellow text next to GPU ID matches your GPU.","This guide assumes you're using Windows.","Under the Hardware tab, tick High Priority.","Under the Quick Launch tab, select the model and your preferred Context Size.","Unless you have an Nvidia 10-series or older GPU, untick Use QuantMatMul (mmq).","You can now connect to KoboldCpp within SillyTavern with http://localhost:5001 as the API URL and start chatting.","You should see something like this:"]},{"l":"GPU Layers","p":["KoboldCpp is working, but you can improve performance by ensuring that as many layers as possible are offloaded to the GPU. You should see something like this in the terminal:","Don't be afraid of numbers; this part is easier than it looks. CPU buffer size refers to how much system RAM is being used. Ignore that. CUDA0 buffer size refers to how much GPU VRAM is being used. CUDA_Host KV buffer size and CUDA0 KV buffer size refer to how much GPU VRAM is being dedicated to your model's context. In this case, KoboldCpp is using about 9 GB of VRAM.","I have 12 GB of VRAM, and only 2 GB of VRAM is being used for context, so I have about 10 GB of VRAM left over to load the model. Because 9 layers used about 7 GB of VRAM and 7000 / 9 = 777.77 we can assume each layer uses approximately 777.77 MIB of VRAM. 10,000 MIB / 777.77 = 12.8, so I'll round down and load 12 layers with this model from now on.","Now do your own math using the model, context size, and VRAM for your system, and restart KoboldCpp:","If you're smart, you clicked Save before, and now you can load your previous configuration with Load. Otherwise, select the same settings you chose before.","Change the GPU Layers to your new, VRAM-optimized number (12 layers in my case).","Click Save to save your updated configuration.","You should now see something like this:","KoboldCpp is using about 11.5 GB of my 12 GB VRAM. This should perform a lot better than the settings generated automatically by KoboldCpp.","Congratulations! You're (actually) done!","For a more in-depth look at KoboldCpp settings, check out Kalomaze's Simple Llama + SillyTavern Setup Guide."]}],[{"l":"Mancer","p":["Mancer is a large language model inferencing service that lets you run whatever prompts you want and doesn't censor responses. Most of the models require a preloaded balance to start chatting, but there is a free model as of writing (2024-11-28).","Models","Pricing"]},{"l":"How to Get Started","p":["Sign up for an account at mancer.tech.","Click on Dashboard and copy your API Key.","Mancer dashboard as of 2/27/2024","In SillyTavern, select the Text Completion API, and then select Mancer under API Type.","Enter your Mancer API Key and click Connect.","API Key","You should now be able to chat with any Mancer model of your choice."]},{"l":"Anonymous Logging","p":["If you don't mind your chats potentially being used to train models, improve Mancer's service, publish datasets, or whatever else they may decide to do with it, you can opt-in to anonymous logging for a 25% token discount on select models. Simply go to your Mancer dashboard and tick Enable Anon. Logging."]},{"l":"Support","p":["Still need help? Head over to the #mancer support channel on the SillyTavern Discord."]}],[{"l":"NovelAI","p":["NovelAI is a paid subscription service that allows unlimited monthly access to their high-quality in-house text generation, image generation, and text-to-speech models. Register an account here to get started: https://novelai.net/","You will get only 50 generations for free to evaluate the model. When the \"Not eligible for this model\" error appears, this means that you've exhausted your trial period and need to subscribe to a paid plan."]},{"l":"API Key","p":["To get your NovelAI API key, follow these steps:","Select the gear icon at the top of the left sidebar. Left Sidebar","Select \"Account\" under \"User Settings\". User Settings","Select \"Get Persistent API Token\". Account","Select the copy icon to copy your NovelAI API token to the clipboard. Persistent API Token"]},{"l":"Models","p":["If you have Opus, then Erato is the model to use. If you don't have Opus, then Kayra is the best available model.","Clio has a larger context size on Tablet/scroll tiers, but the strength of Kayra usually makes up for that difference."]},{"l":"Settings","p":["The files with the settings are here ( SillyTavern/data/user-handle/NovelAI Settings). You can also manually add your own settings files."]},{"l":"Response Length","p":["How much text you want to generate per message. Note that NovelAI has a limit of 150 tokens per response."]},{"l":"Context Size","p":["How many tokens of the chat are kept in the context at any given time. How large the maximum context size you can use depends on the model and your subscription tier:","Kayra (Tablet) - 3072 tokens","Kayra (Scroll) - 6144 tokens","Erato (Opus exclusive), Kayra (Opus) and Clio (all tiers) - 8192 tokens"]},{"l":"Preamble","p":["Text that is inserted right above the chat to modify the writing style. The recommended format is a list of short tags, like \"[Style: chat, detailed, sensory ]\"."]},{"l":"Preset Descriptions","p":["This is, according to Novel AI, what the default presets are good for."]},{"l":"Erato","p":["Golden Arrow - A good all-rounder.","Wilder - Higher variety of word choice, more differences between rerolls, more prone to mistakes.","Zany Scribe - Avoids mistakes and repetition. Prioritizes more complex words.","Dragonfruit - Varied and complex language with little repetition. More frequent mistakes and contradictions.","Shosetsu - Designed for writing in Japanese. Works fine for English too."]},{"l":"Kayra","p":["Asper - For creative writing. Expect unexpected twists.","Carefree - A good All-rounder","Fresh-Coffee - Keeps things on track. Handles instruct well.","Pro_Writer - Mimic the pacing and feel of best-selling fiction","Stelenes - More likely to choose reasonable alternatives. Variety on retries.","Tea_Time - It gets good when it gets going.","Writers-Daemon - Extremely imaginative, sometimes too much."]},{"l":"Clio","p":["Edgewise - Handles a variety of generation styles well","Fresh Coffee - Keeps things on track.","Long-Press - Intended for creative prose.","Talker Chat - Designed for chat style generation.","Vingt-Un - A good all-around default with a bent towards prose."]},{"l":"Tips and FAQs for using NovelAI with SillyTavern","p":["There are a lot of common problems and questions that come up when switching to NovelAI from another ST backend API. The difference comes down to what the models are trained for. Most likely, you've used an OpenAI or Anthropic model (or a local model made to resemble those), which is built around following the user's instructions. NovelAI's models are built purely around text completion: instead of taking your input as a message and formulating a response, NAI's models attempt to continue the incoming prompt. Due to this difference, a lot of tips and common knowledge that work for other APIs won't work for NAI."]},{"l":"Tweaking settings for NovelAI","p":["Under Advanced Formatting (the A icon):","Set \"Context Template\" to \"NovelAI\"","Set \"Tokenizer\" to \"Best match\"","Check \"Always add character's name to prompt\"","Check \"Collapse Consecutive Newlines\"","Uncheck the \"Enabled\" box under \"Instruct Mode\"","Under User Settings (the person with a gear)","Turn on \"Swipes\" (Not NAI specific, but it's so useful you should just do it)"]},{"l":"Building/Adapting character cards for NovelAI","p":["To optimize your character cards for NovelAI, there are a couple of recommended methods for writing your character's description: prose, and attributes.","Prose is so simple it doesn't feel like it should work: \"Sylpheed is a young-looking but actually 900 year old nymph. She's short and petite, with long white hair that fades into a green gradient in her braided side ponytail, and emerald green eyes shaped like crosses.[...]\" No, really, that's it. Just write out, in normal sentences, what the character looks like, acts like, etc., and the AI will pick up on it.","If you don't trust your writing abilities or want a more structured way to go about it, you can use the attributes method, which is present in the NovelAI training data. This works as a simple list of character traits of different types. Here's a list of possible attributes that have been tested to be effective with NovelAI's models:","\"Type: character\" is there to tell the AI that this is describing a character (as opposed to a location, object, or other type of thing). The rest of the attributes are optional, and some are redundant (for example, Personality, Mind, and Mental all mean basically the same thing), but these have been tested and work well with NovelAI's models. Fill in whichever ones are relevant to your character. The attributes should be written in lower case and separated by commas, no need for quotes around the words. For example:","These methods are recommended because they're present in NovelAI's training data, so they specifically work well with the model."]},{"l":"Example cards","p":["Here are a couple of example cards, made for NovelAI, that show off different ways of creating cards specifically for NovelAI. The first card, Valka, uses the attributes method for the character description, while Eris, the second card, uses prose descriptions, along with a large amount of example dialogue.","Valka","Eris"]},{"l":"What not to do","p":["Most of the existing character card formats are a poor fit for NovelAI. They'll give you some results, even some good ones, but they have a lot of problems. W++ is one of the biggest offenders, where it doesn't resemble anything that NovelAI's models were trained on, and its constant use of brackets/braces/quotes eats up a ton of tokens, bloating the size of the cards with no real benefit.","Of the existing formats that aren't baked into NovelAI, AliChat is the one most likely to work, as it relies on using example messages to get across both information about the character and their voice at the same time, in the format of the type of message that you want the AI to output.","For most other formats, since they are usually ways of listing out different characteristics of a particular character, they can be converted to the attributes method rather straightforwardly."]},{"l":"Which module should I use?","p":["Probably No Module. Prose Augmenter is useful if you want a character to speak in a more flowery manner, but be careful not to overdo it. Text Adventure might be useful for a text adventure-style card/story."]},{"l":"Not the instruct module?","p":["You can invoke the Instruct module when you need it. Create a newline in your message, and put your instructions in curly brackets like this: { CharName is offended by that seemingly innocuous statement }(the spaces are required between the text and the brackets). Doing that will automatically switch the AI into the Instruct module for a short time. You don't want to use the Instruct module all the time because it tends to produce less creative output than the other modules, just when you need to guide the AI strongly in a particular direction."]},{"l":"Why do my responses keep getting cut off?","p":["NovelAI limits response length to ~ 150 tokens total, even if you set the slider higher than that. When it reaches the number of tokens in the slider or 150, whichever is lower, it will generate up to 20 more tokens, looking for a stop sequence or the end of a sentence, so there's an effective limit of 170 tokens for a response, at which point it will just stop, causing it to cut off.","If it cuts off, you can select the continue option (in the three-line menu to the left of the text box) to get the character to continue their response.","If you regularly want responses longer than 170 tokens, you can work around the limit like this:","Keep the response length at 150 tokens.","Under Advanced Formatting, enable Auto-continue.","Set the \"Target length\" to the desired length.","This will chain together multiple generations to give you longer messages but doesn't guarantee that the reply will be 100% of the desired length if the model decides to stop."]},{"l":"How do I get the bot to write longer responses?","p":["Read the above about responses getting cut off. That will help to make sure that responses aren't cut off prematurely by running into the limit of generation length.","If your responses aren't getting cut off but are still too short, it's likely you're dealing with \"garbage in, garbage out\" - if you give the model bad examples, it will produce bad output. If the character card has no example dialogue or short example dialogue and the messages you send to the bot are short, the model will pick up on that, take it as the accepted way to do things and the responses will be short. So, write longer example dialogue and longer messages to the bot. (You can always use NovelAI to write some example dialogue for you rather than doing it yourself.)"]},{"l":"How do I get the bot to stop talking for me?","p":["Check that the character card's first message and example dialogue don't include the character taking actions for you - if they do, then rewrite them to get rid of it acting for you","Make sure that \"Always add character's name to prompt\" is checked","Make sure that you're currently using the same user persona as the rest of the chat. If you changed user personas and didn't change back (or don't have a persona locked to that chat), the usual rules to stop generating for you will fail","Add [\"\\n{{user}}:\"] to Custom Stopping Strings (shouldn't be necessary, but sometimes helps)"]},{"l":"Why isn't my character responding?","p":["A lot of things can cause this, so we need to look in a few places:","Make sure that \"Always add character's name to prompt\" is checked in Advanced Formatting","Check to make sure there aren't any errors coming from the API. While you can use SillyTavern with the NAI free trial, once it runs out, you'll just get errors","Check what you have in \"Custom Stopping Strings\" - if those are being generated at the start of the response, it might be cut off prematurely"]},{"l":"How should I use the Author's Note?","p":["In general, you probably shouldn't. It's inserted very close to the end of the context, and with NAI's models, it frequently overpowers everything else in the context. It's mostly an artifact from older, weaker models where it was more necessary."]},{"l":"How do I do a scene break/time jump?","p":["Put the following as a system message or on newlines at the start of your next message:","Then put the rest of your message on the next line. The bracketed text can be a time jump, a new location, or anything else. The \"***\" (hilariously named a \"dinkus\") tells the AI that the scene has changed, and the bracketed text gives that more context."]},{"l":"The AI keeps repeating specific words/phrases, what do I do?","p":["As mentioned above, you can push the repetition penalty slider up a bit more, though pushing it too far can make the output incoherent. To more thoroughly fix the problem, go back through the context, especially recent messages, and delete the repeated word/phrase. Removing it from the context gives the AI less reason to start saying it in the first place."]}],[{"l":"TabbyAPI","p":["A FastAPI based application that allows for generating text using an LLM using the Exllamav2 backend, with support for Exl2, GPTQ, and FP16 models.","GitHub"]},{"l":"Quickstart","p":["Follow the installation instructions on the official TabbyAPI GitHub.","Create your config.yml to set your model path, default model, sequence length, etc. You can ignore most (if not all) of these settings if you want.","Launch TabbyAPI. If it worked, you should see something like this:","TabbyAPI terminal","Under the Text Completion API in SillyTavern, select TabbyAPI.","Copy your API key from the TabbyAPI terminal into Tabby API key and make sure your API URL is correct (it should be http://127.0.0.1:5000 by default).","If you did everything correctly, you should see something like this in SillyTavern:","TabbyAPI SillyTavern","You can now chat using TabbyAPI!"]},{"l":"TabbyAPI Loader","p":["The developers of TabbyAPI created an official extension to load/unload models directly from SillyTavern. Installation is simple:","In SillyTavern, click on the Extensions tab and navigate to Download Extensions & Assets.","Copy https://raw.githubusercontent.com/theroyallab/ST-repo/main/index.json into Assets URL and click the plug button to the right.","You should see something like this. Click the download button next to Tabby Loader.","Tabby Loader","If the installation was successful, you should see a green pop-up message at the top of your screen. Under the extensions tab, navigate to TabbyAPI Loader and copy your admin key from the TabbyAPI terminal into Admin Key.","Click the refresh button next to Model Select. When you click on the textbox just below it, you should see all of the models in your model directory.","Tabby Loader Extension","You can now load and unload your models directly from SillyTavern!"]},{"l":"Support","p":["Still need help? Visit the TabbyAPI GitHub for a link to the developer's official Discord server and read the wiki."]}],[{"l":"Prompts","p":["When you send a message to your AI, the text you write is combined with other text to form a single request that's sent to the AI. This combined text is called a \"prompt\" or sometimes the \"request\" or \"context.\"","The prompt can include a variety of different types of text, including:","Main instructions to the AI about how to generate a response","Definitions of the roles that the AI should take on","Definitions of the role that you are taking on","Information about the \"world\" that the AI is interacting with","Relevant documents or information from Data Bank","Summaries of the past conversation","Results of web searches or other external data sources","Previous messages in the conversation","Your message to the AI","Final instructions for the AI about how to generate a response","This can be a lot to manage! To help you understand how to structure and modify the request that's sent to the AI, SillyTavern identifies different elements that you might want to include in your prompt. You can then structure your prompt to include the things that make sense for the way you want to interact with the AI.","Many of these elements are explained in the sections where you will change them. For example, to describe the role that you would like the AI to take on, you could use the Description field in Character Design."]},{"l":"Viewing the Prompt","p":["Reading the final prompt that's sent to the AI is very helpful for understanding what the AI was told, and why it generated the response that it did. You can view the prompt in several ways:","Using the Prompt Itemization icon on the reply message from the AI","Using the Prompt Inspector extension","Checking the logs in the terminal window that you're running SillyTavern in","Checking the console in your browser's developer tools"]},{"l":"Changing how the Prompt is Built","p":["Presenting all the parts of your prompt to the AI in the right way is crucial for getting the best responses. You can control how the prompt is built.","Use the Advanced Formatting panel to customize prompt construction for Text Completion APIs.","Use the Prompt Manager to customize prompt construction for Chat Completion APIs."]},{"l":"Main Prompt (System Prompt)","p":["The Main Prompt (or System Prompt) defines the general instructions for the model to follow. It sets the tone and context for the conversation. For example, it tells the model to act as an AI assistant, a writing partner, or a fictional character.","The System Prompt is a part of the Story String and usually the first part of the prompt that the model receives.","The Main Prompt is one of the default prompts in Prompt Manager. It is usually the first message in the context that the model receives, attributed to (\"sent by\") the system role.","The default Main Prompt is:","Write {{char}}'s next reply in a fictional chat between {{char}} and {{user}}.","The {{char}} and {{user}} placeholders are replaced with the names of the character and persona that you've defined in the conversation.","You can use any of the supported {{macro}} tags in the Main Prompt to include information that might vary between conversations or changes as the conversation progresses."]},{"l":"Adjusting the Main Prompt","p":["The default main prompt helps the model understand what it's expected to do with the character and persona information that follows, how to interpret the past conversation, and what kind of response to generate. It's a flexible general-purpose prompt that works well for many situations, because it establishes that the AI is writing as a character in a conversation with your persona.","However, you can adjust the main prompt to better suit your needs. Here are some common reasons to adjust the main prompt:","Provide additional instructions: for example, you want the AI to explain its reasoning, follow specific rules, or avoid certain topics","Clarify the role of the AI: for example, you want the AI to act as a narrator, a storyteller, or a guide","Change the context of the conversation: for example, you want the AI to respond as if it were an AI assistant, text adventure game, or a writing partner","All the examples in this guide have worked well for other users, but the prompt that works for your needs and the model you're using might be different. Experiment with different instructions and prompting styles to see what works best for you. If you're not sure what to try, you can always ask for help in the SillyTavern Discord.","Giving the AI additional instructions in the Main Prompt can help it understand what you want from the conversation.","Write one reply only. Write at least one paragraph, up to four.","Markdown is enabled. Use it to format your response. Enclose code snippets in triple backticks.","Write character dialogue in quotation marks. Write {{char}}'s thoughts in parentheses.","You are an anime roleplay generation model for users aged 13 to 17. You always generate fun, age-appropriate responses.","Answer truthfully and write out your thinking step by step to be sure you get the right answer.","The AI will more easily follow instructions about what it should do than what it should not do. For example, if you want the AI to avoid writing in a certain way, it's better to tell it how you want it to write instead. And while \"Do not decide what {{user}} says or does\" is commonly included in prompts to prevent the AI from controlling your persona, some users find \"Write {{char}}'s responses in a way that respects {{user}}'s autonomy\" is more effective.","There is often a better place than the Main Prompt to include information about the user or characters, modify a character's writing and speaking style, or give other specific instructions. The Main Prompt is best used for general instructions about the conversation as a whole, or about a type of conversation that you want to have."]},{"l":"Effect of Message History","p":["When adjusting the main prompt to improve the AI's responses, consder that the AI picks up a lot from the message history. The history is its memory of past events, character interactions and relationships, and its style guide for word choice and writing style.","Use this to your advantage by also providing example messages showing how you want the AI to respond. Showing what you want is often easier than trying to explain it!","When your conversation already has history, changing the main prompt has a limited effect on the AI's responses. In terms of events and relationships, the AI assumes that the main prompt occurred in the distant past, and the message history updates it. In terms of writing style and word choice, the AI assumes that all the messages in history were generated according to the rules in the current main prompt, and that it should continue to generate messages in the same way. Some suggestions for dealing with this are:","insert current instructions close to or after the end of message history, for example by using an Author's Note","test your changes to the main prompt by starting a new conversation","edit the message history to remove or correct examples of unwanted behaviour","use the Post-History Instructions to provide final instructions to the AI","Never let the AI \"get away\" with something you don't want it to do. If you don't like the AI's response, don't continue the conversation as if it was correct. Instead, modify the prompts, regenerate the message, and continue from there. This will help the AI learn what you want."]},{"l":"Removing the \"Fictional Chat\" Context","p":["There are situations where \"fictional chat\" might not be the right context for your conversation.","You can remove the \"fictional\" context from the Main Prompt:","Write {{char}}'s next reply in a conversation with {{user}}.","You may not want the AI to think of itself as role-playing at all. Instead of removing the idea of a character, you can remove the idea of an AI:","You are {{char}}, a helpful assistant. You provide useful information and help {{user}} with their questions."]},{"l":"AI as Narrator or Storyteller","p":["What if you want the AI to act as a narrator, describing events from an omniscient perspective, inventing its own characters and settings?","One approach is to create a named character for the AI to use as a narrator. This character could be called \"Narrator\" or \"AI\", suggesting that the AI is a general-purpose storyteller, or it could be named after a specific scenario or setting, giving the AI the task of narrating a story in that setting. The details of the setting can then be defined in the Character or in World Info.","You will need to adjust the default main prompt to reflect the AI's role. For a general-purpose narrator, you might use:","You are {{char}}, a skilled and versatile storyteller. Narrate the story.","or for a specific setting:","You are the narrator of a fantasy scenario. Play as the characters that visit {{char}}.","It helps to clarify the role of the user in the conversation. Are your messages part of the story, or are they instructions to the narrator about what your character does or says? An example that includes the user in the story:","The story should progress by responding to the actions and dialogue of {{user}}. Narrate the story in third person.","An example that keeps the user out of the story:","Enter Adventure Mode. Narrate the story based on {{user}}'s dialogue and actions after \">\". Describe the surroundings in vivid detail. Be detailed, creative, verbose, and proactive. Move the story forward by introducing fantasy elements and interesting characters.","Defining the role of the user not only helps the AI understand how to respond to your messages, but also to what extent it is allowed to control your persona. This avoids situations where the AI makes decisions for your persona that you would rather make yourself."]},{"l":"Post-History Instructions","p":["Post-History Instructions (PHI) are additional instructions sent to the AI after the main prompt and the user message. They can be used to provide additional context or instructions to the AI based on the message history.","Since the Post-History Instructions are sent after the user message, they are the final instructions that the AI receives before generating a response. The AI usually gives them a higher priority than the main prompt, and they can override the main prompt's instructions.","To use per-character Post-History Instructions, add them to the character's Post-History Instructions and enable Prefer Char. Instructions. To preserve the globally defined PHI while using character-specific instructions, you can use the {{original}} macro in the character's Post-History Instructions field.","Post-History Instructions are defined in the Advanced Formatting panel under the System Prompt category. The Post-History Instructions is added as an invisible user role injection that precedes the last line of the prompt (usually containing a response message \"header\"). Note that the \"Enable System Prompt\" toggle must be enabled for the Post-History Instructions to be applied (even if the System Prompt itself is empty).","Post-History Instructions is one of the default prompts in Prompt Manager. It is usually the last message in the context that the model receives, attributed to (\"sent by\") the system role. If your Chat Completion API does not support the system role, it will usually be attributed to the user role instead."]},{"l":"Adding to the Prompt (World Info)","p":["You can insert additional information anywhere in the prompt using the World Info feature. By setting the conditions for when the information should be inserted, you can guide the AI to include specific details, change how it responds, or add new elements to the conversation.","Some common uses of World Info include:","a \"lorebook\" or \"encyclopedia\" with information about the world or setting","a way to manage different system prompts for various characters and situations","a place to store memories that the AI should \"recall\" in the conversation","a more modular system for creating, editing, and sharing character details","a source of random events and surprises for the AI to react to, or to make you react to!"]}],[{"l":"Advanced Formatting","p":["A supported backend must be chosen as a Text Completion source. Currently only llama.cpp and KoboldCpp support deriving templates.","A tokenizer is a tool that breaks down a piece of text into smaller units called tokens. These tokens can be individual words or even parts of words, such as prefixes, suffixes, or punctuation. A rule of thumb is that one token generally corresponds to 3~ 4 characters of text.","Accepts a JSON-serialized array of stopping strings. Example: [\\n, \\nUser:, \\nChar:]. If you're unsure about the formatting, use an online JSON validator. If the model output ends with any of the stop strings, they will be removed from the output.","Adds an assistant role message to the end of the prompt. For some backend models, this is equivalent to prefilling the model response, but some may not support that at all and will fail with a validation error. If you're unsure, leave this field empty.","AI Horde","Backend-defined templates","By default, the Start Reply With prefix won't be shown in the resulting message. Enable \"Show reply prefix in chat\" to display it.","Chat Completion APIs","Claude","Click the Restore current template button.","Confirm the action when prompted.","Context Template","Custom Stopping Strings","Delete the content.log file from the root of your user data directory. This file tracks the default files copied for your user.","Delete the template JSON files from the relevant subdirectories ( context, instruct, sysprompt, etc.).","Derive templates option must be enabled in the Advanced Formatting menu. This can be applied to Context, Instruct, or both.","For equivalent settings in Chat Completion APIs, use Prompt Manager.","For equivalent settings in Chat Completion APIs, use Prompt Manager. The Main Prompt is the equivalent of the System Prompt in Chat Completion APIs.","Google AI Studio","If the hash matches, the template will be automatically selected if it exists in the templates list (i.e., not renamed or deleted).","KoboldAI Classic (versions 1.2.2 and higher) or KoboldCpp","Make sure the skipContentCheck setting is set to false in config.yaml, otherwise the content check will not be triggered.","Manual Reset","MistralAI","Most of the settings in this panel do not apply to Chat Completions APIs as they are governed by the prompt manager system instead.","Navigate to your user data directory (see Data paths for details).","Not applicable to Chat Completion APIs as they use a different prompt builder.","NovelAI","Open the Advanced Formatting menu.","OpenAI (max 4 strings) and compatible APIs","OpenRouter (both Text and Chat Completion)","Pick the template you want to reset.","Prefills the last line of the prompt, forcing the model to continue from that point. This is useful for enforcing content, such as nudging toward the Model Reasoning with the defined prefix:","Resetting Templates","Restart the SillyTavern server. The application will repopulate the default content, restoring any deleted default templates.","See the prompting guide to learn more about the System Prompt.","Some Text Completion sources provide an ability to automatically choose templates recommended by the model author. This works by comparing a hash of the chat template defined in the model's tokenizer_config.json file with one of the default SillyTavern templates.","Start Reply With","Supported APIs:","System Prompt","Text Completion APIs","Text Completion APIs: Text Generation WebUI (ooba), Tabby, Aphrodite, Mancer, TogetherAI, Ollama, etc.","The model must correctly report its metadata when the connection to the API is established. If this didn't work, try updating the backend to the latest version.","The options for this section are explained in Context Template.","The options for this section are explained in Tokenizer.","The reported chat template hash must match the one of the known SillyTavern templates. This only covers default templates, such as Llama 3, Gemma 2, Mistral V7, etc.","The settings provided in this section allow for more control over the prompt-building strategy, primarily for Text Completion APIs.","The System Prompt defines the general instructions for the model to follow. It sets the tone and context for the conversation. For example, it tells the model to act as an AI assistant, a writing partner, or a fictional character.","The System Prompt is a part of the Story String and usually the first part of the prompt that the model receives.","Tokenizer","UI Reset","Usually, AI models require you to provide the character data to them in some specific way. SillyTavern includes a list of pre-made conversion rules for different models, but you may customize them however you like.","You can restore the default templates to their original state. This can be done either through the UI or by manually deleting the relevant data files."]}],[{"l":"Context Template","p":["For equivalent settings in Chat Completion APIs, use Prompt Manager.","Usually, AI models require you to provide the character data to them in some specific way. SillyTavern includes a list of pre-made conversion rules for different models, but you may customize them however you like.","Edit these settings in the \" Advanced Formatting\" panel."]},{"l":"Story String","p":["{{anchorAfter}}: Prompts set to use the \"After Story String\" position.","{{anchorBefore}}: Prompts set to use the \"Before Story String\" position.","{{char}}: The character's name.","{{description}}: The character's Description.","{{mesExamples}}: (Optional) The character's Example Dialogues, instruct-formatted with a separator.","{{mesExamplesRaw}}: The character's Example Dialogues in raw format, without any formatting.","{{persona}}: The selected persona's description.","{{personality}}: The character's Personality.","{{scenario}}: The character's Scenario.","{{system}}: The system prompt OR the character's main prompt override (if it exists and \"Prefer Char. Prompt\" is enabled in User Settings).","{{user}}: The selected persona's name.","{{wiAfter}} or {{loreAfter}}: Combined activated World Info entries with Position set to \"After Char Defs\".","{{wiBefore}} or {{loreBefore}}: Combined activated World Info entries with Position set to \"Before Char Defs\".","A special {{trim}} macro is supported to remove any newlines that surround it. Use it if you want a part of the text to not be separated from the previous line by a newline ( spaces are not trimmed).","The template supports Handlebars syntax, custom text injections or formatting, and any other macros. See the language reference here: https://handlebarsjs.com/guide/","This field is a template for the prompt preamble (known internally as a story string). This is the main way to add the information defined in Character Cards for text completion and instruct models.","WARNING: If any of the above parameters are missing from the story string template, they will not be sent in the prompt at all.","We provide the following parameters to the Handlebars evaluator (wrapped in double curly braces):","When using {{mesExamples}} in the Story String, set \"Example Messages Behavior\" in the User Settings panel to \"Never include examples\" to avoid duplicating example messages in the prompt."]},{"l":"Prompt Anchors","p":["The {{anchorBefore}} and {{anchorAfter}} are generic placeholders for prompts added by various extensions and miscellaneous features in a chosen static position, for example:","Author's Note","Summaries","Chat Vectorization/ Data Bank","STscript injections","Web Search"]},{"l":"Story String position","p":["By default, the rendered story string (with all placeholders replaced) is placed at the very beginning of the prompt, followed by example messages and the visible chat history.","Alternatively, you can move it to a dynamic position by choosing the \"In-chat @ Depth\" option, which places the story string at a specific depth in the chat context.","If the template contains static prompt elements (model-specific prefixes or suffixes) for wrapping the story string, using the \"In-Chat @ Depth\" position will cause it to be incorrectly double-wrapped with duplicate sequences, which may lead to unexpected results.","In this case, you can fix the issue in one of the following ways:","Built-in templates: Reset the templates to their defaults using the steps described in Advanced Formatting.","Custom templates: Move the static elements from the story string template to Story String Sequences."]},{"l":"Story String wrapping","p":["The following section only applies when Instruct Mode is ON.","Default position: The rendered Story String will be wrapped using the sequences defined in Story String Sequences.","In-chat @ Depth position: The rendered Story String will be wrapped using the sequences defined in Chat Messages Sequences for a chosen role (default: System)."]},{"l":"Example Separator","p":["Used as a block header and a separator between the example dialogue blocks. Any instance of START tags in the example dialogues will be replaced with the contents of this field."]},{"l":"Chat Start","p":["Inserted as a separator after the rendered story string and after the example dialogues blocks, but before the first message in context."]},{"l":"Separators as Stop Strings","p":["Adds \"Example Separator\" and \"Chat Start\" to the list of stop strings.","Helpful if the model tends to hallucinate or leak whole blocks of example dialogue preceded by the separator."]},{"l":"Names as Stop Strings","p":["Adds Character and User Persona names to the list of stop strings.","Recommended to keep it on to prevent model impersonation."]},{"l":"Always add character's name to prompt","p":["This setting has no effect when Instruct Mode is ON. The name behavior is instead defined by the selected Include Names option.","Appends the character's name to the prompt to force the model to complete the message as the character:"]}],[{"l":"Instruct Mode","p":["Instruct Mode allows you to adjust the prompting for instruction-following models trained on various prompt formats, such as Alpaca, ChatML, Llama2, etc.","For equivalent settings in Chat Completion APIs, use Prompt Manager."]},{"l":"API support"},{"l":"Text Completion API","p":["Fully supported. This includes:","All of the sources under Text Completion","KoboldAI Classic","AI Horde"]},{"l":"Choosing a formatting","p":["A chosen instruct template must match the expectations of an actual model that is running on a backend.","This is usually reflected in a model card on HuggingFace, and some even provide SillyTavern-compatible JSON files.","Example: NeverSleep/Noromaid-13b-v0.1.1"]},{"l":"Chat Completion API (OpenAI, Claude, etc)","p":["This is not supported (and not needed) for Chat Completion APIs. They use an entirely different prompt builder."]},{"l":"NovelAI","p":["While technically supported for NovelAI, none of their models were trained to understand instruct formatting. NovelAI models can use a special instruct module that is activated automatically when an instruction wrapped in curly braces is encountered in chat messages, so using Instruct Mode for the entire prompt will lead to degraded quality of the outputs.","Here's an example that auto-activates the instruct module for NovelAI:"]},{"l":"Instruct Mode Settings"},{"l":"System Prompt","p":["The System Prompt is now a separate entity. See the Advanced Formatting page for more details."]},{"l":"Templates","p":["Provides ready-made templates with sequences for some well-known instruct models.","Changing a template resets the unsaved settings to the last saved state! Don't forget to save your template if you made any changes you don't want to lose."]},{"l":"Activation Regex","p":["If defined as a valid regular expression, when connected to a model and its name matches this regex, will automatically select this template.","Instruct mode needs to be enabled prior. Only the first regex match across templates will be selected (evaluated in alphabetical order)."]},{"l":"Wrap Sequences with Newline","p":["Each sequence text will be wrapped with newline characters when inserted into the prompt. Required for Alpaca and its derivatives.","Disable if you want to have full control over line terminators."]},{"l":"Replace Macro in Sequences","p":["If enabled, known {{macro}} substitutions will be replaced if defined in message wrapping sequences.","Also, a special {{name}} macro can be used in message prefixes to reference the actual name attached to a message (rather than a currently active {{char}} or {{user}}), which can be helpful when using group chats or /sendas command. If the name can't be determined, \"System\" is used as a fallback placeholder."]},{"l":"Include Names","p":["If enabled, prepend characters and user names to chat history logs after the prefix sequence.","The following options are available:","Never: Do not add name prefixes before the message contents.","Groups and Past Personas: Only add name prefixes to messages from group characters and past personas.","Always: Always add name prefixes before the message contents."]},{"l":"Sequences: Story String Wrapping","p":["System Prompt wrapping has been removed and replaced with Story String wrapping.","Define how the Story String will be wrapped when the Position is set to \"Default (top of context)\""]},{"l":"Story String Prefix","p":["Inserted before a Story String."]},{"l":"Story String Suffix","p":["Inserted after a Story String."]},{"l":"Sequences: Chat Messages Wrapping","p":["These settings define how messages belonging to different roles will be wrapped upon building a prompt.","All prefix sequences will also be automatically used as stopping strings."]},{"l":"User Message Prefix","p":["Inserted before a User message and as a last prompt line when impersonating."]},{"l":"User Message Suffix","p":["Inserted after a User message."]},{"l":"Assistant Message Prefix","p":["Inserted before an Assistant message and as a last prompt line when generating an AI reply."]},{"l":"Assistant Message Suffix","p":["Inserted after an Assistant message"]},{"l":"System Message Prefix","p":["Inserted before a System (added by slash commands or extensions) message."]},{"l":"System Message Suffix","p":["Inserted after a System message."]},{"l":"System same as User","p":["If checked true, System messages will be using User role message sequences.","Otherwise, System messages use their own sequences (if not empty) or will not do any wrapping at all (if empty)."]},{"l":"Misc. Sequences","p":["Various advanced configurations for finer tuning of the prompt building"]},{"l":"First Assistant Prefix","p":["Inserted before the first Assistant's message.","Only the first message of the chat history counts, not the message that actually goes into the prompt first!"]},{"l":"Last Assistant Prefix","p":["Inserted before the last Assistant's message or as a last prompt line when generating an AI reply.","Not used when generating text in a background (e.g. Stable Diffusion prompts or Summaries). System Instruction Prefix or Regular Assistant Prefix will be used instead."]},{"l":"System Instruction Prefix","p":["Inserted as a last prompt line when generating neutral/system text in a background (e.g. Stable Diffusion prompts or Summaries)."]},{"l":"User Filler Message","p":["Will be inserted at the start of the chat history if it doesn't start with a User message.","Use case: when an instruct format strictly requires prompts to be user-first and have messages with alternating roles only, examples: Llama 2 Chat, Mistral Instruct."]},{"l":"Stop Sequence","p":["Text that denotes the end of the reply. Also sent as a stopping string to the backend API.","If a stop sequence is generated, everything past it will be removed from the output (including the sequence itself)."]}],[{"l":"Tokenizer","p":["A tokenizer is a tool that breaks down a piece of text into smaller units called tokens. These tokens can be individual words or even parts of words, such as prefixes, suffixes, or punctuation. A rule of thumb is that one token generally corresponds to 3~ 4 characters of text.","AI21 API: Jamba tokenizer (requires a one-time download).","API tokenizer. Queries the generation API to get the token count directly from the model. Known backends to support: Text Generation WebUI (ooba), koboldcpp, TabbyAPI, Aphrodite API. Pick if you use a supported backend.","Chat Completion APIs (non-overridable):","Claude: model-dependant tokenizer via WebTokenizers.","Cohere API: Command-R or Command-A tokenizer (requires a one-time download).","DeepSeek API: DeepSeek tokenizer (requires a one-time download).","DeepSeek tokenizer. Used by DeepSeek models (such as R1). Pick if you use a DeepSeek model.","Fallback tokenizer: GPT-3.5 turbo tokenizer.","Gemma tokenizer. Used by Gemini/Gemma models. Pick if you use a Gemma model.","Google AI Studio: Gemma tokenizer.","If you get inaccurate results or wish to experiment, you can set an override tokenizer for SillyTavern to use while forming a request to the AI backend:","KoboldAI Classic / AI Horde: Llama tokenizer.","KoboldCpp: model API tokenizer.","Llama 3 tokenizer. Used by Llama 3/3.1 models. Pick if you use a Llama 3/3.1 model.","Llama tokenizer. Used by Llama 1/2 models family: Vicuna, Hermes, Airoboros, etc. Pick if you use a Llama 1/2 model.","Mistral Nemo tokenizer. Used by Mistral Nemo models family and their finetunes. Pick if you use a Mistral Nemo/Pixtral model.","Mistral V1 tokenizer. Used by older Mistral models family and their finetunes. Pick if you use an older Mistral model.","MistralAI API: Mistral V1 or V3 tokenizer (requires a one-time download).","NerdStash tokenizer. Used by NovelAI's Clio model. Pick if you use the Clio model.","NerdStash v2 tokenizer. Used by NovelAI's Kayra model. Pick if you use the Kayra model.","None. Each token is estimated to be ~ 3.3 characters, rounded up to the nearest integer. Try this if your prompts get cut off on high context lengths. This approach is used by KoboldAI Lite.","NovelAI Clio: NerdStash tokenizer.","NovelAI Kayra: NerdStash v2 tokenizer.","OpenAI: model-dependant tokenizer via tiktoken.","OpenRouter: Llama, Mistral, Gemma, Yi tokenizers for their respective models.","SillyTavern provides a \"Best match\" option that tries to match the tokenizer using the following rules depending on the API provider used.","Text Completion APIs (overridable):","Text Completion: API tokenizer (if supported) or Llama tokenizer.","Yi tokenizer. Used by Yi models. Pick if you use a Yi model."]},{"l":"Additional Tokenizers","p":["These tokenizers are not included in the default installation due to their size A one-time download is required when they're used for the first time.","Qwen2 tokenizer.","Command-R / Command-A tokenizers. Used by Cohere source in Chat Completion.","Mistral V3 (Nemo) tokenizer. Used by MistralAI source in Chat Completion (Nemo and Pixtral models).","DeepSeek (deepseek-chat) tokenizer. Used by DeepSeek source in Chat Completion.","If you don't want to use internet downloads, the opt-out option exists in config.yaml: enableDownloadableTokenizers. Set to false to disable downloads.","You can also download tokenizers manually from the SillyTavern-Tokenizers repository. Download the JSON files and put them in the _cache subdirectory of your data root, the path is ./data/_cache by default. Create the _cache directory if it doesn't exist. After that, restart the SillyTavern server to re-initialize tokenizers.","If the required tokenizer model is not cached and downloads are disabled, a fallback tokenizer (Llama 3) will be used for counting."]},{"l":"Token Padding","p":["SillyTavern will always use the matching tokenizer for Chat Completion models, so there is no need for token padding.","Unless SillyTavern uses a tokenizer provided by the remote backend API that runs the model, all token counts assumed during prompt generation are estimated based on the selected tokenizer type.","Since the results of tokenization can be inaccurate on context sizes close to the model-defined maximum, some parts of the prompt may be trimmed or dropped, which may negatively affect the coherence of character definitions.","To prevent this, SillyTavern allocates a portion of the context size as padding to avoid adding more chat items than the model can accommodate. If you find that some part of the prompt is trimmed even with the most-matching tokenizer selected, adjust the padding so the description is not truncated.","You can input negative values for reverse padding, which allows allocating more than the set maximum amount of tokens."]}],[{"l":"CFG","p":["Page written by: kingbri","Contributors: kingbri, Guillaume \"Vermeille\" Sanchez, AliCat"]},{"l":"What is it?","p":["CFG, or classifier-free guidance is a method that's used to help make parts of a prompt less or more prominent."]},{"l":"Supported Backend APIs","p":["Currently, the supported backends are oobabooga's textgen WebUI, NovelAI, and TabbyAPI. NovelAI had its own documentation for CFG.","WARNING: CFG increases vram usage due to ingesting more than 1 prompt! If your GPU memory runs out while generating a prompt with CFG on, consider reducing your context size, using a lesser parameter model, or turning off CFG entirely."]},{"l":"Configuration","p":["Accessing CFG settings are the same as accessing Author's note:","CFGhamburgermenupng","And here's what the CFG panel looks like:","CFGchatpanelpng","There are four dropdowns in the CFG panel:","Chat CFG","Scopes the CFG scale and prompts to only this chat","Character CFG","Scopes the CFG scale and prompts to the specified character","Global CFG","Globally overrides the CFG scale and prompts (also overrides the model preset!)","CFG Advanced Settings (formerly called CFG Prompt Cascading)","A place to combine prompts from the previous 3 dropdowns and set insertion depth.","NOTE: If the guidance scale is set to 1, nothing will be sent since that's when CFG is in an \"off\" state."]},{"l":"Group Chats","p":["In group chats, the CFG scale panel looks like this:","CFGpanelgcpng","The main change is that character CFG is removed and a checkbox called Use Character CFG Scales is present in the chat CFG dropdown. This allows for the current character's guidance scale to be used instead of whatever the chat CFG scale is set to.","The main utility of this feature is to alter the scale based on each character's individual needs.","In addition, checking the Character Negatives box in prompt cascading will append the independent character negative prompts along with the chat ones (if enabled)."]},{"l":"Concepts"},{"l":"Isn't this in Stable Diffusion?","p":["Yes and no. CFG with LLMs works in a different way than what one might be used to in Stable Diffusion. LLM-based CFG works on the principle of \"prompt mixing\". The CFG formula takes a positive and negative prompt, then mixes the differences between them. From there, a combined prompt is sent and a response is generated!","Here's an illustration to help visualize this concept. The red represents the negative prompt, the blue represents the neutral prompt, and the purple represents the mixed result that's interpreted. All the white space is the same across all 3 prompts, so those are not used for CFG mixing.","stcfgdiagrampng","If you want to know more about CFG and LLMs, Vermifuge's original paper is located here. I'd suggest giving it a read/listen:","Paper - [2306.17806] Stay on topic with Classifier-Free Guidance (arxiv.org)","Audio version - https://www.youtube.com/watch?v=MGY00YFcyco"]},{"l":"Do I need CFG prompts?","p":["No! CFG prompts are completely optional. Just adjusting the guidance scale above 1 will also help produce an effect on responses, which can accentuate chats and character interaction."]},{"l":"What makes a good CFG prompt?","p":["So, we established that CFG prompting is not the same as Stable Diffusion's negative tags and embeddings. How do we make a prompt?","Warning: This assumes that you have created a character using PLists and Ali:Chat. If you have not, feel free to experiment with various prompting techniques.","Let's say I have a character named \"John\". John is supposed to feel happy and excited all the time from his example dialogues. However, when chatting with John, he's sometimes sad and depressed.","To remove this, CFG comes to the rescue! Just make the negative prompt [John's feelings: sad, depressed] to help remove the sadness portions. You can optionally make the positive prompt [John's feelings: happy, joyful] to further bring out John's happy parts."]},{"l":"Positive Prompts","p":["I went over this in the previous section, but I'd like to touch on this a bit more. Positive prompts are used to further accentuate parts of a character. Let's use John again as our example. By making him happier with a positive prompt of [John's feelings: happy, joyful], John should start outputting dialogue with a more happy feeling than if the positive prompt was not included."]},{"l":"But...","p":["These are just loose guidelines from experience with one specific character format. There are many other ways to create prompts that you should experiment with. Feel free to share your thoughts with other users!"]},{"l":"Guidance Scale","p":["Here's a rule of thumb. A guidance scale of 1 means that CFG is disabled. In fact, SillyTavern won't send anything to your backend if the guidance scale is 1. A guidance scale 1 will give the results shown in the other sections at varying degrees.","However, a guidance scale of 1 will give the opposite effect since the negative prompt is used as the primary prompt here.","Let's use the example with John again. The negative prompt is [John's feelings: sad, depressed] and the positive prompt is [John's feelings: happy, joyful] with a guidance scale of 0.8.","This will in turn accentuate the negative prompt more and you'll see John start to act sadder than normal rather than happier.","tldr; Use a guidance scale of 1.5 and work up and down from there based on your outputs."]},{"l":"Prompt Cascading","p":["Negatives and positives can be cascaded between CFG types (the types being per-chat, per-character, and global overrides). See the Configuration header for more information."]},{"l":"Insertion Depth","p":["Follow the basic rule: The lower something is located in the prompt, the more influential it is to the response. For chatting, I recommend using the default depth of 1 since it's very flexible with other components of SillyTavern.","However, if you want to experiment, an insertion depth of 0 is open. However, these can dramatically alter how your response will look and it's NOT recommended to use prompt cascading here!"]}],[{"l":"Prompt Manager","p":["The Prompt Manager is a system that provides more control over the prompt-building strategy for Chat Completion APIs.","For equivalent settings in Text Completion APIs, use Advanced Formatting.","If a preset shares a name with one of your character cards, it will be automatically selected when starting a chat with that character. Name presets something unique to avoid this behavior.","Access the Prompt Manager by clicking on the \"AI Response Configuration\" button in the navigation bar. The Prompt Manager is located below the common settings panel."]},{"l":"Quick Prompts Edit","p":["Provides space to quickly edit common prompt sections, such as Main Prompt, Auxiliary Prompt, and Post-History Instructions. More information on these prompts can be found on the prompt-building page."]},{"l":"Utility Prompts","p":["These prompts are sent to the Chat Completion model to help it understand the information being sent to it, or to instruct it to act in specific ways during certain types of interactions."]},{"l":"Format Templates","p":["If the format template is not set, the information will be sent as-is, without any wrapping.","These are string templates used to wrap the information pulled from World Info and Character Cards.","A special marker is used to indicate where the information should be inserted:","{0} for the World Info format template.","{{scenario}} for the Scenario format template.","{{personality}} for the Personality format template."]},{"l":"Group Nudge Prompt Template","p":["Used only in group chats. Placed at the end of the prompt to force a reply from a specific character.","Leave this empty to disable Group Nudge functionality."]},{"l":"New Chat, New Group Chat, New Example Chat","p":["These are sent before the chat history and before each Example Dialogue block to inform the model where background information ends and chat history begins.","New Chat: Used for individual chats.","New Group Chat: Used for group chats.","New Example Chat: Used for example dialogue blocks.","Leave these empty to disable this functionality."]},{"l":"Continue Nudge","p":["Sent at the end of the prompt to instruct the model on what to do when Continue is triggered, such as when the Continue button is pressed or when triggered by STScript.","Keep in mind that Chat Completion models handle Continues differently than Text Completion models, and may not always deliver seamless results regardless of your Continue Nudge."]},{"l":"Replace Empty Message","p":["Sends the contents of this field instead of a blank message when the text box is empty and Send a message is pressed."]},{"l":"Character Names Behavior","p":["Provides different strategies for instructing the model on how to associate messages with characters. If a Chat Completion model is having trouble determining which messages belong to which character, it may need a different strategy selected."]},{"l":"Continue Postfix","p":["When Continue is triggered, the 'continued' message returned by the model will have the selected Continue Postfix prepended to the beginning. For example, it can add a space before the continued text."]},{"l":"Additional Settings"},{"l":"Wrap in Quotes","p":["Deprecated option. Prefer Regex scripts instead.","Wraps the entire user message in hidden quotation marks before sending. This is useful for sessions where characters do not use quotes to indicate speech. If your session uses quotation marks to indicate speech, leave this unchecked."]},{"l":"Continue Prefill","p":["May not work with all Chat Completion sources.","Sends the Continue Nudge as an Assistant role message instead of a System message. If this is enabled, the Continue Nudge prompt will not be used."]},{"l":"Squash system messages","p":["Deprecated option. Prefer Prompt Post-Processing instead.","Combines consecutive System messages into a single combined message (excluding Example Dialogue)."]},{"l":"Enable web search","p":["Not to be confused with the Web Search extension.","Enables web search capabilities provided by the Chat Completion backend. The prompt is usually enriched with search results by the model provider and may incur additional costs."]},{"l":"Enable function calling","p":["See Function Calling"]},{"l":"Send inline images, Send inline videos","p":["Not to be confused with the Image Captioning extension.","If the Chat Completion model has multimodal capabilities to process submitted images and videos, this toggles its ability to do so. To append media to the prompt, use the Attach A File option in the \"Magic Wand\" menu."]},{"l":"Request inline images","p":["Not to be confused with the Image Generation extension.","Allows the model to return image attachments."]},{"l":"Use system prompt","p":["Only supported by Google Gemini and Anthropic Claude backends.","Despite having very similar settings for these two, they are technically separate options, so they can be configured separately.","Merges all system messages up until the first message with a non-system role (User/Assistant) and sends them as a separate system instruction field."]},{"l":"Reasoning Settings","p":["If the Chat Completion model uses reasoning, these settings affect its visibility and functionality."]},{"l":"Request model reasoning","p":["See Adding Reasoning: By Backend."]},{"l":"Reasoning Effort","p":["See Reasoning Effort."]},{"l":"\"Prompts\"","p":["The Prompt Manager forms the backbone of the prompt sent to the Chat Completion model. It controls what is sent as well as the order in which it is sent."]},{"l":"The 'Prompts' Dropdown","p":["Contains a dropdown list of all (non-default) prompts that the current Chat Completion preset includes. For one of these prompts to be added to the outgoing message, it needs to be selected from the dropdown list and then added to the Prompt Manager by pressing the Insert prompt button. To create a new prompt to add to this dropdown list, press the New prompt button. Once the new prompt is written and saved, it is added to the dropdown and can then be inserted."]},{"l":"Prompts List","p":["This is a drag-and-drop interface that lists the prompts selected to potentially be sent to the Chat Completion model. Prompts placed closer to the top of the interface are sent earlier. The bottom of the list is the last thing sent to the model (typically, this would be your Post-History Instructions).","The default prompts cannot be removed from the list of selected prompts. This includes Main Prompt, World Info (before/after), Persona Description, Character Description, Character Personality, Scenario, Enhance Definitions, Auxiliary Prompt, Chat Examples, Chat History, and Post-History Instructions. If these are not desired, they can be toggled 'OFF', but not removed or deleted outright."]},{"l":"Editing a Prompt","p":["Clicking the pencil button on a prompt will bring you to the Edit interface. Here, you can edit the prompt directly.","To permanently save changes to these prompts in your Chat Completion preset, you must click the Save button in the bottom right of the Edit interface, as well as save the preset itself by using the Save button located at the top of the AI Response Configuration section! Otherwise, changes made will be lost when the Chat Completion preset is switched to a different one."]},{"l":"Name","p":["The name of the prompt. This is not sent to the Chat Completion model; it is for your reference within the Prompt Manager only."]},{"l":"Role","p":["Which role sends the prompt. You can choose between System, AI Assistant, or User."]},{"l":"Triggers","p":["The generation types for which this prompt is sent. If nothing is selected, the prompt will be sent for all generation types. If one or more are selected, the prompt will only be sent for those specific generation types:","Normal: Regular message generation request.","Continue: When the Continue button is pressed.","Impersonate: When the Impersonate button is pressed.","Swipe: When the generation is triggered by swiping.","Regenerate: When the Regenerate button is pressed in solo chats.","Quiet: Background generation requests, usually triggered by extensions or STscript commands.","The \"Regenerate\" trigger is not available in group chats as it uses different regeneration logic: all messages from the last reply are deleted, and messages are queued using the \"Normal\" generation type according to the chosen Group reply strategy."]},{"l":"Position","p":["When Position is set to Relative, this prompt is sent where it's located in the drag-and-drop interface with all other prompts. When it is set to In-Chat and given a Depth, it is instead sent within the Chat History as the selected Role, and ignores the order of the drag-and-drop interface."]},{"l":"Depth","p":["When Position is set to In-Chat, this defines how deep the prompt is sent within the chat history. The higher the number, the deeper it is sent. For example, a Depth of 0 will be sent after the last chat message, a Depth of 1 will be sent before the last chat message, and a Depth of 2 will be sent before the second-to-last chat message, and so on."]},{"l":"Order","p":["Prompts that have the same Role and Depth will be grouped together and ordered by their Order value. The order is as follows (from top to bottom): User, AI Assistant, System.","When Position is set to In-Chat, this defines the order in which the prompt is sent within the chat history. The lower the number, the earlier it is sent."]},{"l":"Building Your Prompt: Tips and Tricks","p":["Visit the prompt-building section of the SillyTavern documentation for more information on how to write effective prompts. The information can largely be applied to Chat Completion presets."]}],[{"l":"Reasoning","p":["In language models, reasoning (also known as model thinking) refers to a chain-of-thought (CoT) technique that mirrors human problem-solving through step-by-step analysis. SillyTavern provides several features that make the use of reasoning models more efficient and consistent across supported backends."]},{"l":"Common issues","p":["When using reasoning models, the model's internal reasoning process consumes part of your response token allowance, even if this reasoning isn't shown in the final output (e.g. o3-mini or Gemini Thinking). If you notice your responses are coming back incomplete or empty, you should try adjusting the Max Response Length setting found in the AI Response Configuration panel. For reasoning models, it's typical to use significantly higher token limits - anywhere from 1024 to 4096 tokens - compared to standard conversational models."]},{"l":"Configuration","p":["Most reasoning-related settings can be configured in the \"Reasoning\" section of Advanced Formatting panel.","Reasoning blocks appear in the chat as collapsible message sections. They can be added manually, automatically by the backend, or through response parsing (see below).","By default, reasoning blocks are collapsed to save space. Click a block to expand and view its contents. You can set blocks to expand automatically by enabling Auto-Expand in the reasoning settings.","When a reasoning block is expanded, you can copy or edit its contents using the Copy and Edit buttons.","Some models models support reasoning, but will not send their thoughts back. It is possible to still show the reasoning block with reasoning time for those by toggling the Show Hidden setting."]},{"l":"Adding Reasoning"},{"l":"Manually","p":["Add a reasoning block to any message through the Message Edit menu. Click while editing to add a reasoning section. Third-party extensions can also add reasoning by writing to the extra.reasoning field of the message object before adding it to the chat."]},{"l":"With a Command","p":["Use the /reasoning-set STscript command to add reasoning to a message. The command takes at(message ID, defaults to the last message) and reasoning text as arguments."]},{"l":"By Backend","p":["If your chosen LLM backend and model support reasoning output, enabling \"Request model reasoning\" in the AI Response Configuration panel will add a reasoning block containing the model's thinking process.","Supported sources:","Claude","DeepSeek","Google AI Studio","Google Vertex AI","OpenRouter","xAI (Grok)","AI/ML API","\"Request model reasoning\" does not determine whether a model does reasoning. Claude and Google (2.5 Flash) allow thinking mode to be toggled; see Reasoning Effort."]},{"l":"By Parsing","p":["Enable \"Auto-Parse\" in the Advanced Formatting panel to automatically parse reasoning from the model's output.","The response must contain a reasoning section wrapped in configured Prefix and Suffix sequences. The sequences provided by default correspond to the DeepSeek R1 reasoning format.","Example with prefix think and suffix /think:"]},{"l":"Prompting with Reasoning","p":["By default, recognized reasoning block contents are not sent back to the model. To include reasoning in prompts, enable \"Add to Prompts\" in the Advanced Formatting panel. Reasoning content will be wrapped in configured Prefix and Suffix sequences and separated by a Separator from the main context. The Max Additions numeric setting controls how many reasoning blocks can be included, counting from the end of the prompt.","Most model providers do not recommend sending CoT back to the model in multi-turn conversations."]},{"l":"Continuing from Reasoning","p":["A special case when the reasoning can be sent back to the model without having the \"Add to Prompts\" toggle enabled is when the generation is continued (e.g. by pressing \"Continue\" from the Options menu), but the message being continued contains only the reasoning without an actual content. This gives the model an opportunity to finish an incomplete reasoning and start generating the main content. The prompt will be sent as follows:"]},{"l":"Regex Scripts","p":["Regular expression scripts from the Regex extension can be applied to the contents of reasoning blocks. Check \"Reasoning\" in the \"Affects\" section of the script editor to target reasoning blocks specifically.","Different ephemerality options affect reasoning blocks in the following ways:","No ephemerality: reasoning content is permanently changed.","Run on edit: regex script will be re-evaluated when the reasoning block is edited.","Alter chat display: regex is applied to the reasoning block's display text, not the underlying content.","Alter outgoing prompts: regex is only applied to reasoning blocks before they are sent to the model."]},{"l":"Reasoning Effort","p":["\"high\"","\"high\", or 80% of max response","\"low\"","\"low\", or 20% of max response","\"medium\"","\"medium\", or 50% of max response","0, no thinking","128","15% of max response","15% of max response, min 1024","15% of max response, min 128","15% of max response, min 512","2.5 Flash","2.5 Flash Lite","2.5 Pro","25% of max","25% of max response, min 1024","50% of max","50% of max response, min 1024","95% of max response, min 1024","applicable models","Auto","Auto (dynamic thinking)","budgets 1024 tokens","Claude (≤ 21333 if no streaming)","For Claude, budget is capped to 21333 if streaming is disabled. If the calculated budget would be less than 1024, then max response is changed to 2048.","For Gemini 2.5 Pro and 2.5 Flash/Lite, budget is capped to 32768 or 24576 tokens respectively, regardless of the streaming setting.","For OpenRouter, Perplexity and AI/ML API, only an OpenAI-style keyword is sent.","Google AI Studio and Vertex AI are as follows:","grok-3-mini","High","Low","lower of max or 24576","lower of max or 32768","Maximum","Medium","Minimum","Model","Models","not specified","not specified, effect depends","not specified, no thinking","o4-mini, o3*, o1*","OpenAI (keyword)","OpenRouter (keyword)","Option","Opus 4, Sonnet 4/3.7","Perplexity (keyword)","Reasoning Effort is a Chat Completion setting in the AI Response Configuration panel that influences how many tokens may potentially be used on reasoning. The effect of each option depends on the source connected to. For the sources below, Auto simply means the relevant parameter is not included in the request.","sonar-deep-research","thinkingBudget = -1","xAI (Grok) (keyword)"]}],[{"l":"World Info","p":["World Info (also known as Lorebooks or Memory Books) is a powerful tool available in ST to insert prompts dynamically into your chat to help guide the AI replies.","Commonly, World Info (WI for short) is used to enhance the AI's understanding of the details in your fictional world, however you could use a World Info entry to insert ANYTHING that you would like to insert into the prompt.","It functions like a dynamic dictionary that only inserts relevant information from World Info entries when keywords associated with the entries are present in the message text.","The SillyTavern engine activates and seamlessly integrates the appropriate lore into the prompt, providing background information to the AI.","It is important to note that while World Info helps guide the AI toward the desired content, it does not guarantee its appearance in the generated output messages. That depends on how good your model is at making use of additional information!"]},{"l":"Pro Tips","p":["The World Info engine is a very powerful prompt management tool. Don't fixate on adding character lore alone, feel free to experiment.","Activation keywords, titles, and other information that is not in the Content field is not inserted into context, so each World Info entry should have a comprehensive, standalone description.","To create rich and detailed world lore, entries can be interlinked and reference one another by using recursive activation. See more on Recursion below.","SillyTavern offers flexible context budgeting for inserted background information. To conserve prompt tokens, it is advisable to keep entry contents concise."]},{"l":"Further reading","p":["World Info Encyclopedia: Exhaustive in-depth guide to World Info and Lorebooks. By kingbri, Alicat, Trappu."]},{"l":"Character Lore","p":["Optionally, one World Info file could be assigned to a character to serve as a dedicated lore source across all chats with that character (including groups).","To do that, navigate to a Character Management panel and click a globe button, then pick World Info from a dropdown list and click \"Ok\".","To unbind or change character lore, Shift-click the globe button. If on mobile, click \"More...\" and then \"Link World Info\"."]},{"l":"Character Lore Insertion Strategy","p":["When generating an AI reply, entries from the character World Info will be combined with the entries from a global World Info selector using one of the following strategies:"]},{"l":"Sorted Evenly (default)","p":["All entries will be sorted according to their Insertion Order as if they a part of one big file, ignoring the source."]},{"l":"Character Lore First","p":["Entries from the Character World Info would be included first by their Insertion Order, then entries from the Global World Info."]},{"l":"Global Lore First","p":["Entries from the Global World Info Info would be included first by their Insertion Order, then entries from the Character World Info."]},{"l":"World Info Entry"},{"l":"Key","p":["A list of keywords that trigger the activation of a World Info entry. Keys are not case-sensitive by default (this is configurable)."]},{"l":"Regular Expression (Regex) as Keys","p":["Keys allow a more flexible approach to matching by supporting regex. This makes it possible to match more dynamic content with optional words or characters, spacing, and all the other utilities that regex provides. If a defined key is a valid regex (Javascript regex style, with / as delimiters. All flags are allowed), it will be treated as such when checking whether an entry should be triggered. Multiple regexes can be entered as separate keys and will work alongside each other. Inside a regex, commas are possible. Plaintext keys do not support commas, as they are treated as key separators.","An example of a use-case for advanced regex matching: An entry/instruction that should be inserted, when char is doing a weather-related action","For more information on Regex syntax and possibilities: Regular expressions - JavaScript | MDN"]},{"l":"Advanced Regex Per-Message Matching","p":["ST prefixes every chat message in the WI scan buffer with character name: and after v1.12.6, concatenates prepends them using the character value 1 (\\x01). This means you can match specific input or output from a certain character using a regex tied to that separation character.","For example, to match only the user saying \"hello\", you could use the following regex:"]},{"l":"Key Input","p":["There are two modes to enter keywords, each with a slightly different UI. In ⌨️ plaintext mode(default), keys can be entered as a comma-separated list in a single text field. Regexes can be included too, but they don't have any special highlighting. In ✨ fancy mode, the keys appear as separate elements and regexes will be highlighted as such. The control supports editing and deleting keys. The mode can be switched via the inline button inside the input control."]},{"l":"Optional Filter","p":["Comma-separated list of additional keywords in conjunction with the primary key. If no arguments are provided, this flag is ignored. Supports logic for AND ANY, NOT ANY, or NOT ALL","AND ANY = Activates the entry only if the primary key and Any one of the optional filter keys are in scanned context.","AND ALL = Activates the entry only if the primary key and ALL of the optional filter keys are present.","NOT ANY = Activates the entry only if the primary key and None of the optional filter keys are in scanned context.","NOT ALL = Prevents activation of the entry despite primary key trigger, if all of the optional filters are in scanned context.","These keys also support regex."]},{"l":"Entry Content","p":["The text that is inserted into the prompt upon entry activation."]},{"l":"Insertion Order","p":["Numeric value. Defines a priority of the entry if multiple were activated at once. Entries with higher order numbers will be inserted closer to the end of the context as they will have more impact on the output."]},{"l":"Insertion Position","p":["Before Char Defs: World Info entry is inserted before the character's description and scenario. Has a moderate impact on the conversation.","After Char Defs: World Info entry is inserted after the character's description and scenario. Has a greater impact on the conversation.","Before Example Messages: The World Info entry is parsed as an example dialogue block and inserted before the examples provided by the character card.","After Example Messages: The World Info entry is parsed as an example dialogue block and inserted after the examples provided by the character card.","Top of AN: World Info entry is inserted at the top of Author's Note content. Has a variable impact depending on the Author's Note position.","Bottom of AN: World Info entry is inserted at the bottom of Author's Note content. Has a variable impact depending on the Author's Note position.","@ D: World Info entry is inserted at a specific depth in the chat (Depth 0 being the bottom of the prompt).","⚙️ - as a system role message","\uD83D\uDC64 - as a user role message","\uD83E\uDD16 - as an assistant role message","Example Message entries will be formatted according to the prompt-building settings: Instruct Mode or Chat Completion prompt manager. They also follow the Example Messages Behavior rules: being gradually pushed out on full context, always kept, or disabled altogether.","If your Author's Note is disabled (Insertion Frequency = 0), World Info entries in A/N positions will be ignored!"]},{"l":"Entry Title / Memo","p":["A text field for your convenience to label your entries, which is not utilized by the AI or any of the trigger logics.","If empty, can be backfilled using the entries' first key by clicking on the \"Fill empty memos\" button."]},{"l":"Strategy","p":["\uD83D\uDD35 (Blue Circle) = The entry would always be present in the prompt.","\uD83D\uDFE2 (Green Circle) = The entry will be triggered only in the presence of the keyword.","\uD83D\uDD17 (Chain Link) = The entry is allowed to be inserted by embedding similarity.","Each Entry also has a toggle that allows you to enable or disable the entry."]},{"l":"Probability (Trigger %)","p":["This value acts like an additional filter that adds a chance for the entry NOT to be inserted when it is activated by any means (constant, primary key, recursion).","Probability = 100 means that the entry will be inserted on every activation.","Probability = 50 means that the entry will be inserted with a 1:1 chance.","Probability = 0 means that the entry will NOT be inserted (essentially disabling it).","Use this to create random events in your chats. For example, every message could have a 1% chance of waking up an Elder God if its name is mentioned in the message."]},{"l":"Inclusion Group","p":["Inclusion groups control how entries are selected when multiple entries with the same group label are triggered simultaneously. If multiple entries having the same group label were activated, only one will be inserted into the prompt.","By default, the chosen entry is selected randomly based on their Group Weight (default is 100 points) — the higher the number, the higher the probability of selection. This allows for a random selection among the triggered entries, adding an element of surprise and variety to interactions.","A single entry can be part of multiple inclusion groups if they are defined as a comma-separated list. The same logic as explained above will apply. If that entry is triggered, it will disable all other entries that are part of any of its groups. Therefore, if any of the groups are activated, this entry will not be activated."]},{"l":"Prioritize Inclusion","p":["To provide more control over which entries are activated via Inclusion Group, you can use the 'Prioritize Inclusion' setting. This option allows you to specify deterministically which entry to choose instead of randomly rolling Group Weight chances.","If multiple entries having the same group label and this setting turned on were activated, the one with the highest 'Order' value will be selected. This is useful for creating fallback sequences via inclusion groups. For example to prioritize low-depth entries with more emphasis, or to choose a specific instruction on setting the scene over another if both are valid."]},{"l":"Use Group Scoring","p":["When this setting is enabled globally or per entry, the number of activated entry keys determines the group winner selection. Only the subset of a group with the highest number of key matches will be left to be activated by Group Weight or Inclusion Priority - the rest will be deactivated and removed from the group.","Use this to give more specificity for individual entries in large groups. For example, they can have a common key and a specific key. A random entry will be inserted when a specific key is not provided, and vice versa.","The score calculation logic for primary keys is 1 match = 1 point.","For secondary keys, the interaction depends on the chosen Selective Logic:","AND ANY: 1 secondary match = 1 point.","AND ALL: 1 point for every secondary key if they all match.","NOT ANY and NOT ALL: no change.","Example:","Entry 1. Keys: song, sing, Black Cat. Group: songs","Entry 2. Keys: song, sing, Ghosts. Group: songs","The input sing me a song can activate either entry (both activated 2 keys), but sing me a song about Ghosts will activate only Entry 2 (activated 3 keys)."]},{"l":"Automation ID","p":["Allows to integrate World Info entries with STscripts from Quick Replies extension. If both the quick reply command and the WI entry have the same Automation ID, the command will be executed automatically when the entry with a matching ID is activated.","Automations are executed in the order they are triggered, adhering to your designated sorting strategy, combining the Character Lore Insertion Strategy with the 'Priority' sorting. Which leads to Blue Circle entries processed first, followed by others in their specified 'Order'. Recursively triggered entries will be processed after in the same order.","The script command will run only once if multiple entries with the same Automation ID are activated."]},{"l":"Character Filter","p":["A list of character names for which this entry can be activated. If this list is not empty, the entry will only be activated for characters whose names are on the list. When a tag is selected, the entry will only be activated for characters that have that specific tag.","\"Exclude\" mode inverts the filter, meaning that the entry will be activated for all characters except those that are added to the list or that have the selected tag(s)."]},{"l":"Triggers","p":["The generation types for which this World Info entry can be activated. If nothing is selected, the entry can be activated for all generation types. If one or more are selected, the entry will only be activated for those specific generation types:","Normal: Regular message generation request.","Continue: When the Continue button is pressed.","Impersonate: When the Impersonate button is pressed.","Swipe: When the generation is triggered by swiping.","Regenerate: When the Regenerate button is pressed in solo chats.","Quiet: Background generation requests, usually triggered by extensions or STscript commands.","The \"Regenerate\" trigger is not available in group chats as it uses different regeneration logic: all messages from the last reply are deleted, and messages are queued using the \"Normal\" generation type according to the chosen Group reply strategy."]},{"l":"Additional matching sources","p":["By default World Info Entries are matched only against content from the current conversation. These options allow you to match the entry against different character information that does not show up in the chat, or even persona information. This is useful when you want to have a wide range of entries that are to be used between several characters but don't want to have to manage large lists of tags, or don't want to have to update character filter lists every time you create a new one. This also allows you to match entries based on the persona you have active.","Character Description: Matches against the character description.","Character Personality: Matches against the character personality summary, found under Advanced Definitions.","Scenario: Matches against the character specified scenario, found under Advanced Definitions.","Persona Description: Matches against the current selected persona's description.","Character's Note: Matches against the character's note, which can be found under Advanced Definitions.","Creator's Notes: Matches against the character creator's notes, which can be found under Advanced Definitions. The creator's notes are usually not included in the prompt."]},{"l":"Vector Storage Matching","p":["The Vector Storage extension provides an alternative to keyword matching by using the similarity between the recent chat messages and World Info entry contents.","To enable and use this, the following prerequisites need to be met:","Vector Storage extension is enabled and is configured to use one of the available embedding sources.","The \"Enable for World Info\" checkbox is ticked in the Vector Storage extension settings.","Either the World Info entries that are allowed for keyless matching have the \"Vectorized\" (\uD83D\uDD17) status or the \"Enabled for all entries\" option is checked in the Vector Storage settings.","The choice of the vectorization model in the extension and the theoretical meaning behind the term \"embeddings\" won't be covered here. Check out the Data Bank guide if you require more info on this topic.","Vector Storage matching adheres to this set of rules:","The maximum number of entries that are allowed to be matched with the Vector Storage can be adjusted with the \"Max Entries\" setting. This number only sets the limit and does not influence the token budget set in the activation settings for World Info. All of the budgeting rules still apply.","This feature only replaces the check for keywords. All additional checks must be met for the entry to be inserted: trigger%, character filters, inclusion groups, etc.","The \"Scan Depth\" setting from Activation Settings or entry overrides is not used. The Vector Storage \"Query messages\" value is utilized instead to get the text to match against. This allows for a configuration like \"Scan Depth\" set to 0, so no regular keyword matches will be made, but entries still can be activated by vectors.","A \"Vectorized\" status is only an additional marker. The entry would still behave like a normal, enabled, non-constant record that will be activated by keywords if they are set. Remove the keywords if you want them to be activated only by vectors.","Since the retrieval quality depends entirely on the outputs of the embedding model, it's impossible to predict exactly what entries will be inserted. If you want deterministic and predictable results, stick to keyword matching."]},{"l":"Timed Effects","p":["Usually, World Info evaluation is stateless, meaning that the result of the evaluation is the same, only depending on the current chat context. However, with the introduction of Timed Effects, you can create entries that have an activation delay, stay active after being triggered, or can't be triggered after the activation."]},{"l":"Timed Effects Rules","p":["The time frames for the effects are measured in messages (not pairs of messages/exchanges), with 0 meaning there is no effect.","Effects only apply in the chat where the entry was activated. Branches inherit the state of the parent chat.","Active timed effects are removed if the chat doesn't advance, e.g. if the last message was swiped or deleted.","Making any changes to the entry that is currently on timed effect will cause the effect to be forcibly removed.","Consequent triggering of keywords does not refresh the effect duration if it's already active."]},{"l":"Types of Timed Effects","p":["Sticky - the entry stays active for N messages after being activated. Stickied entries ignore probability checks on consequent scans until they expire.","Cooldown - the entry can't be activated for N messages after being activated. Can be used together with sticky: the entry goes on cooldown when the sticky duration ends.","Delay - the entry can't be activated unless there are at least N messages in the chat at the moment of evaluation.","Delay = 0 -> The entry can be activated at any time.","Delay = 1 -> The entry can't be activated if the chat is empty (no greeting).","Delay = 2 -> The entry can't be activated if there is zero or only one message in the chat, etc."]},{"l":"Timed Effects Example","p":["Entry configuration: sticky = 3, cooldown = 2, delay = 2."]},{"l":"Activation Settings","p":["Collapsible menu at the top of the World Info screen."]},{"l":"Scan Depth","p":["Can be overridden on an entry level.","Defines how many messages in the chat history should be scanned for World Info keys.","If set to 0, then only recursed entries and Author's Note are evaluated.","If set to 1, then SillyTavern only scans the last message.","2 = two last messages, etc."]},{"l":"Include Names","p":["Defines if the names of the chat participants should be included in the scanned text buffer as message prefixes. This allows activating entries that use names as keywords without directly mentioning the names in messages.","See an example of the text to be scanned below, assuming the chat participants are named Alice and Bob.","Enabled (default):","Disabled:"]},{"l":"Context % / Budget","p":["Defines how many tokens could be used by World Info entries at once. You can define a threshold relative to your API's max-context settings (Context %) or an objective token threshold (Budget)","If the budget is exhausted, then no more entries are activated even if the keys are present in the prompt.","Constant entries will be inserted first. Then entries with higher order numbers.","Entries inserted by directly mentioning their keys have higher priority than those that were mentioned in other entries' contents."]},{"l":"Min Activations","p":["This setting is mutually exclusive with Max Recursion Steps.","Minimum Activations: If set to a non-zero value, this will disregard the limitation of \"scan-depth\", seeking all of the chat log backward from the latest message for keywords until as many entries as specified in min activations have been triggered. This will still be limited by the Max Depth setting or your overall Budget cap.","Additional scan sweeps triggered by Min Activations will not check entries added by recursion on previous steps. Only chat messages and extension prompts can trigger these additional activations. However, the entries activated by Min Activations can trigger other entries as usual."]},{"l":"Max Depth","p":["Maximum Depth to scan for when using the Min Activations setting."]},{"l":"Recursive scanning","p":["Recursive scanning allows for entries to activate other entries or be activated by others, enabling complex interactions and dependencies between different World Info entries. This feature can significantly enhance the dynamic nature of your creative scenarios. Whether recursive scanning is enabled can be controlled with the global setting Recursive Scan. There are three options available to control recursion for each entry:","8 Non-recursable: When this checkbox is selected, the entry will not be activated by other entries. This is useful for static information that should not change or be influenced by other world info entries.","Prevent further recursion: Selecting this option ensures that once this entry is activated, it will not trigger any other entries. This is helpful to avoid unintended chains of activations.","Delay until recursion: This entry will only be activated during recursive checks, meaning it won't be triggered in the initial pass but can be activated by other entries that have recursion enabled. Now, with the added Recursion Level for those delays, entries are grouped by levels. Initially, only the first level (smallest number) will match. Once no matches are found, the next level becomes eligible for matching, repeating the process until all levels are checked. This allows for more control over how and when deeper layers of information are revealed during recursion, especially in combination with criteria as NOT ANY or NOT ALL combination of key matches.","Entries can activate other entries by mentioning their keywords in the content text.","For example, if your World Info contains two entries:","Both of them will be pulled into the context if the message text mentions just Bessie."]},{"l":"Max Recursion Steps","p":["This setting is mutually exclusive with Min Activations.","When set to zero, recursion nesting is only limited by your prompt budget. When set to a non-zero value, limits the total number of scan sweeps to desired maximum \"nesting level\".","Example values:","1 effectively disables recursion as the check stops after the first step.","2 can only activate recursive entries once.","3 can trigger recursion twice..."]},{"l":"Case-sensitive keys","p":["Can be overridden on an entry level.","To get pulled into the context, entry keys need to match the case as they are defined in the World Info entry.","This is useful when your keys are common words or parts of common words.","For example, when this setting is active, keys 'rose' and 'Rose' will be treated differently, depending on the inputs."]},{"l":"Match whole words","p":["Can be overridden on an entry level.","Entries with keys containing only one word will be matched only if the entire word is present in the search text. Enabled by default.","For example, if the setting is enabled and the entry key is \"king\", then text such as \"long live the king\" would be matched, but \"it's not to my liking\" wouldn't.","Important: this setting can have a detrimental effect when used with languages that don't use whitespace to separate words (e.g. Japanese or Chinese). If you write entries in these languages, it is advised to keep it off."]},{"l":"Alert on overflow","p":["Shows an alert if the activated World Info exceeds the allocated token budget."]}],[{"l":"User Settings","p":["UI Customization","Change the theme, look and feel of the chat interface to suit your preferences.","Visual Novel mode","Chat to characters with sprites, like in visual novels such as Doki Doki Literature Club and other famous VN games."]},{"l":"General Settings","p":["These are the core settings that affect your overall SillyTavern experience."]},{"l":"UI Language","p":["SillyTavern's user interface is available in multiple languages. The language selector provides these options:","Default: Uses your system language if available","English: Forces English UI regardless of system settings","Other languages available through the dropdown","Note: This setting only affects the user interface text. For AI conversation translation, please use the Chat Translation extension."]},{"l":"Software Version","p":["Your current version of SillyTavern is displayed in the top-right corner. This information is essential for:","Troubleshooting problems","Ensuring compatibility with extensions","Determining if updates are available","To update SillyTavern to the latest version, please refer to the Updating documentation."]},{"l":"Account Management","p":["Control your SillyTavern user account, back up your settings and user data, and manage user roles and permissions in multi-user mode."]},{"l":"Account","p":["Account Actions","Account creation date","Account handle","Change Password: Update your account security credentials","Critical account operations that should be used with caution:","Danger Zone","Display name (editable via pencil icon)","Download Backup: Export a complete backup of all your user data","In the Account dialog, you can view and edit your profile information, change your password, and manage account settings.","Password status (locked/unlocked icon indicates protection)","Profile Information","Reset Everything: Complete account wipe and factory reset","Reset Settings: Restore all settings to factory defaults","Settings Snapshots: Create, manage, and restore backups of your user settings","User avatar (can also be changed using Personas)","User role"]},{"l":"Admin Panel","p":["Multi-account features require enableUserAccounts to be set to true in config.yaml.","Select Manage Users to view and manage existing user accounts."]},{"l":"User Profile","p":["Custom avatar management (upload/remove)","Display name and handle","Role and status information","Account creation date","Password protection status"]},{"l":"Account Controls","p":["Edit display name","Enable account","Disable account","Promote to admin","Demote to regular user"]},{"l":"Management Actions","p":["Download user data backup","Change user password","Delete account"]},{"l":"New User","p":["Select New User to create a new user account.","Display Name*(e.g., \"John Snow\")","User Handle*(lowercase letters, numbers, and dashes only)","Password (optional)","Password Confirmation","Creating a new user automatically generates a subfolder in the /data/ directory using the user's handle as the folder name."]},{"l":"Logout","p":["Sign out of your current session."]},{"l":"Settings Search","p":["A convenient search bar that helps you quickly find specific settings:","Type any keyword to filter and highlight settings anywhere in User Settings","Searches through setting names and descriptions","Helps navigate complex settings more efficiently"]},{"l":"UI Theme","p":["Change the appearance of the chat interface to suit your preferences.","For more information on the settings in this section of User Settings, see UI Customization."]},{"l":"Character Handling","p":["Char List Subheader: Choose what additional information to display under character names in the Characters list:","Character Version","Created by","Import Card Tags: Controls how tags are handled when importing character cards:","Ask - Show dialog for each import","None - Don't import any tags","All - Import all tags","Existing - Only import tags that already exist","Advanced Character Search: When enabled, uses fuzzy matching and searches all character data fields, not just names.","Prefer Char. Prompt: If enabled, uses the character card's System Prompt override when available.","Prefer Char. Instructions: If enabled, uses the character card's Post-History Instructions override when available.","Never resize avatars: Prevents cropping/resizing of imported character images. When disabled, images are resized to 512x768.","Show avatar filenames: Displays actual filenames of character avatars in the character list.","Spoiler Free Mode: Hides character definitions behind a spoiler button in the editor panel."]},{"l":"Miscellaneous","p":["Reload Chat: Reloads and redraws the current chat.","Debug Menu: Access debugging options.","Smooth Streaming: Experimental feature for smoother text generation. Includes speed control slider.","Message Sound: Plays a sound when message generation completes.","Background Sound Only: Only plays sounds when browser tab is unfocused.","Relaxed API URLs: Reduces formatting requirements for API URLs.","Lorebook Import Dialog: Shows import dialog for World Info/Lorebook when importing characters with embedded lore.","Auto-select Input Text: Automatically selects text in certain input fields when clicked.","Markdown Hotkeys: Enables keyboard shortcuts for markdown formatting.","Restore User Input: Preserves unsaved user input when page is refreshed.","MovingUI: Allows repositioning UI elements by dragging (PC only).","Reset button to restore default positions","Preset system for saving/loading UI layouts"]},{"l":"Chat/Message Handling"},{"l":"Message Display Settings","p":["Controls how messages are loaded and displayed in the chat interface. These settings affect the overall chat experience and performance.","# Messages to Load: Number of chat history messages to load before pagination (0 = All)","Streaming FPS: Update speed of streamed text (5-100 FPS)","Example Messages Behavior:","Gradual push-out","Always include examples","Never include examples"]},{"l":"Input & Response Controls","p":["Settings that determine how messages are sent and how the AI continues its responses.","Enter to Send: Choose between Disabled, Automatic (PC), or Enabled","\"Send\" to Continue: Use Send button to continue AI responses","Quick \"Continue\" button: Show button to extend AI's last message","Quick \"Impersonate\" button: Show button for single-message character impersonation","Swipes: Show arrow buttons for alternative AI responses (PC and mobile)","Gestures: Enable swipe gestures for generation (Mobile only)"]},{"l":"Auto-Management","p":["Automated features that help manage chat flow and content.","Auto-load Last Chat: Automatically load the most recent chat on startup","Auto-scroll Chat: Automatically scroll to newest messages","Auto-save Message Edits: Save message edits without confirmation","Confirm message deletion: Prompt before deleting messages","Auto-fix Markdown: Automatically correct markdown formatting"]},{"l":"Auto-swipe","p":["Automatically reject and regenerate AI messages based on configurable criteria.","Enable Auto-swipe: Master toggle for the auto-swipe function","Minimum generated message length: Triggers an auto-swipe if the message is shorter than this value","Blacklisted words: List of words that can trigger auto-swipe, separated by commas","Blacklisted word count to swipe: Minimum number of blacklisted words that must be detected to trigger an auto-swipe"]},{"l":"Auto-Continue","p":["Automatically continues a response if the model stopped before reaching a certain length.","This lets your AI write a long response in multiple parts, so that you can have a short response length setting while still getting long replies.","It will not make the AI write more than it would have otherwise. Asking the AI to continue a message that it considers \"finished\" does not usually work. See How to make the AI write more? for other ideas.","Enable Auto-continue: Master toggle for automatic continuation","Allow for Chat Completion APIs: Enables auto-continue functionality for Chat Completion API endpoints","Target length (tokens): The desired message length in tokens - will trigger continue if message is shorter than this value (0-1024)"]},{"l":"Message Formatting & Display","p":["Controls how messages are formatted and what content is displayed.","Forbid External Media: Block embedded media from external domains","Show {{char}}: in responses: Retain character name prefix in responses if generated","Show {{user}}: in responses: Retain user name prefix in responses if generated","Show tags in responses: Allow (some) HTML tags in responses to be displayed as HTML","Relax message trim in Groups: Allow AI to speak for other characters in group chats, rather than stopping the response generation","Show group chat queue: Display response order in the character list for group chats","Pin greeting message styles: Always render style tags from greetings, even if the message is unloaded due to lazy loading."]},{"l":"Prompt Inspection and Debugging","p":["Log prompts to console: Output prompts to browser console","Request token probabilities: Request token probabilities for AI responses from the API. Where available, these can be viewed in Token Probabilities."]},{"l":"AutoComplete","p":["Auto-hide details","Matching style (Starts with/Includes/Fuzzy)","Visual style (Theme/Dark/Light)","Keyboard selection options","Font scaling","Width controls"]},{"l":"STscript Settings","p":["Configuration options for the STscript parser."]},{"l":"STRICT_ESCAPING","p":["Pipes don't need to be escaped in quoted values.","A backslash in front of a symbol can be escaped to provide the literal backslash followed by the functional symbol.","See Strict Escaping for more information."]},{"l":"REPLACE_GETVAR","p":["Helps to avoid double-substitutions when the variable values contain text that could be interpreted as macros.","See Replace Variable Macros for more information."]},{"l":"Clean-Up Menu","p":["The Clean-Up menu provides a data maintenance tool that helps you identify and remove unnecessary files from your SillyTavern installation. This feature helps keep your data directory organized and can free up significant disk space.","The Clean-up tool will permanently delete files. This action cannot be undone!","Manual uploads to the /data/user/files/ and /data/user/images/ directories will be deleted if they are not associated with chat messages or Data Bank entries.","If unsure, make a backup of your data before using the Clean-up menu."]},{"l":"How to Use Clean-Up","p":["Click the Clean-Up button under the Miscellaneous section","Click Scan to analyze your installation. This may take some time depending on the size of your data directory","Review the categories of files found","Use View to preview file contents before deletion","Use Download to save files before deletion","Delete individual files or entire categories as needed"]},{"l":"Clean-Up Categories","p":["The Clean-Up tool scans for loose files into the following categories:"]},{"l":"Files","p":["What it finds: Files that are not associated with chat messages or Data Bank entries","Location: /data/user-handle/user/files/","Risk: ⚠️ WILL DELETE MANUAL UPLOADS that aren't referenced in chats","When to clean: Safe to delete if you don't need unreferenced files"]},{"l":"Images","p":["What it finds: Images that are not associated with chat messages","Location: /data/user-handle/user/images/","Risk: ⚠️ WILL DELETE MANUAL UPLOADS that aren't referenced in chats","When to clean: Safe to delete if you don't need unreferenced images"]},{"l":"Chats","p":["What it finds: Chat files associated with deleted characters","Location: data/user-handle/chats/","Risk: ⚠️ Orphaned chats will be permanently lost","When to clean: Safe to delete if you've intentionally deleted characters and no longer need their chat histories"]},{"l":"Group Chats","p":["What it finds: Chat files associated with deleted groups","Location: data/user-handle/group chats/","Risk: ⚠️ Orphaned group chats will be permanently lost","When to clean: Safe to delete if you've intentionally deleted groups and no longer need their chat histories"]},{"l":"Avatar Thumbnails","p":["What it finds: Thumbnails for avatars of missing or deleted characters","Location: data/user-handle/thumbnails/avatar","Risk: ✅ Safe to delete- thumbnails are automatically regenerated when needed","When to clean: Always safe to clean, helps free up space"]},{"l":"Background Thumbnails","p":["What it finds: Thumbnails for missing or deleted backgrounds","Location: data/user-handle/thumbnails/bg","Risk: ✅ Safe to delete- thumbnails are automatically regenerated when needed","When to clean: Always safe to clean, helps free up space"]},{"l":"Chat Backups","p":["What it finds: Automatically generated chat backups","Location: data/user-handle/backups/chat_*","Risk: ⚠️ Backup files will be permanently lost","When to clean: Consider keeping recent backups, but older ones can be safely deleted"]},{"l":"Settings Backups","p":["What it finds: Automatically generated settings backups","Location: data/user-handle/backups/settings_*","Risk: ⚠️ Settings backup files will be permanently lost","When to clean: Consider keeping recent backups, but older ones can be safely deleted"]},{"l":"Debug menu","p":["Do not use them unless you fully understand their consequences.","The Debug Menu provides functionality for troubleshooting, maintenance, and development purposes. These functions should be used with caution as they can significantly impact your SillyTavern installation.","Because extensions can add debug functions, the available options will vary depending on the extensions you have installed."]},{"l":"Translation & Locale Functions","p":["Get missing translations: Analyzes the current locale (or all locales if English is selected) for missing translations and outputs results to browser console","Apply locale: Forces a refresh of the current language settings by reapplying the selected locale"]},{"l":"Cache & Storage Management","p":["Clear WebSearch cache: Removes all stored search results from local cache","Purge all vector indices: Completely removes all stored vectors across all sources","Reset token cache: Clears stored token counts, forcing complete re-tokenization of all chats","Delete itemized prompts: Removes all itemized prompts from local storage"]},{"l":"Data & Statistics","p":["Refresh Stat File: Rebuilds the statistics file using existing chat data","Backfill token counters: Recalculates token counts for all messages in current chat","Useful when switching between models with different tokenizers","Triggers chat reload after completion","Visual changes only, does not modify chat content"]},{"l":"API & Extension Testing","p":["Change Mancer base URL: Modify the base URL for Mancer API server","Test WebSearch extension: Performs a test search using current settings","Send a generation request: Tests text generation using the currently selected API"]},{"l":"System & Debug Tools","p":["Force onboarding: Restarts the onboarding process","Toggle event tracing: Enables/disables event tracking for debugging","Copy ST setup: [Work in Progress] Copies system configuration data to clipboard for bug reports","Each function can be executed using the \"Execute\" button beneath its description. Consider backing up your data before using these tools, as some operations cannot be undone."]}],[{"l":"UI Customization"},{"l":"UI Theme"},{"l":"Theme Management","p":["Theme files allow you to save, share, and reuse your UI customizations. You can maintain multiple themes for different moods or purposes, and switch between them instantly.","Import/Export theme files","Delete existing themes","Save changes to current theme","Save as new theme","All the settings in this section are saved to the current theme. If you switch themes, the settings will be replaced by the settings of the new theme."]},{"l":"Display Settings","p":["These display options affect how characters and messages are presented in the chat interface."]},{"l":"Avatar Style","p":["Choose between Circle, Square, Rectangle, or Rounded Square. This setting applies to both user and AI avatars."]},{"l":"Chat Style","p":["Style","Description","Slash command","Flat","Clean and continuous \"chat log\" style, a flat canvas for your AI interactions to come to life.","/flat/default","Bubbles","\"Instant messenger\" style with distinct bubbles for each message, delightful rounded corners, and a subtle 3D effect.","/bubble/bubbles","Document","Compact, document-like appearance with a text-focused layout. Hides avatars, timestamps, and message control buttons for past messages.","/single/story"]},{"l":"Notifications","p":["Set a position where the notification popups (toast messages) will appear on the screen.","Top Left","Top Center (default)","Top Right","Bottom Left","Bottom Center","Bottom Right"]},{"l":"Theme Colors","p":["Customize the color scheme of every UI element to create your perfect theme. Colors can be selected using a color picker, and include transparency options where applicable.","Main Text","Italics Text","Underlined Text","Quote Text","Text Shadow","Chat Background","UI Background","UI Border","User Message","AI Message"]},{"l":"Layout & Visual Settings","p":["Fine-tune the visual presentation of the interface with these sliders.","Chat Width: Adjust chat window width (25-100% of screen)","Font Scale: Customize text size (0.5-1.5x)","Blur Strength: Control UI panel blur (0-30)","Shadow Width: Adjust text shadow intensity (0-5)"]},{"l":"Theme Toggles","p":["Avatar Hover Magnification: Zoom effect on avatar hover","Characters Hotswap: Quick-select buttons for favorite characters","Chat Timestamps: Display message timestamps","Click to Edit: Click on messages to quickly open a message editor","Compact Input Area: Single-row input (Mobile only)","Expand Message Actions: Always show full message context menu","Hide Chat Avatars: Remove avatars from chat","Mad Lab Mode: Unrestricted parameter ranges","Message IDs: Display sequential message numbers","Message Timer: Show AI response generation time","Message Token Count: Show token counts per message","Model Icons: Show AI model icons for messages","No Blur Effect: Remove background blur for better performance","No Text Shadows: Disable text shadow effects","Reduced Motion: Disable animations and transitions","Swipe # for All Messages: Show swipe numbers on all messages","Tags as Folders: Organize characters using tags as folders","These switches control various UI features and behaviors. Some options can improve performance on lower-end devices, while others add useful information or functionality to the chat interface.","Visual Novel mode: Compact chat with background sprite","Zen Sliders: Simplified parameter controls"]},{"l":"Custom CSS","p":["Allows you to apply custom CSS styles to further customize the appearance of the chat interface.","Use Expand to expand the editor window for better visibility and editing.","If you switch themes, your custom CSS will be replaced by the custom CSS of the new theme. Ensure you save your custom CSS to a theme if you want to keep it when switching themes.","If you use a lot of custom CSS, or want to use the same custom CSS with several themes, the unofficial CSS Snippets extension can help you manage and organize your custom CSS."]},{"l":"Message Sound","p":["To play your own custom sound on receiving a new message from bot, replace the following MP3 file in your SillyTavern folder:","public/sounds/message.mp3","Plays at 80% volume.","If the \" Background Sound Only\" option is enabled, the sound plays only if SillyTavern window is unfocused."]},{"l":"Formulas Rendering","p":["To enable math formulas rendering, use the LaTeX extension. To get the extension, you need to install it via the \"Download Extensions & Assets\" menu in SillyTavern.","Type your formulas in code blocks with latex or asciimath language identifiers for LaTeX and AsciiMath respectively. The extension uses KaTeX for rendering.","The legacy $ and $$ wrapper syntax is no longer supported. Please use the following regex scripts to polyfill the old syntax:","$$ - LaTeX","$ - AsciiMath"]}],[{"l":"Visual Novel (VN) Mode","p":["Visual Novel Mode is a special screen layout in SillyTavern that allows you to chat to characters with sprites (or their character card image) that resembles that of a visual novel like Doki Doki Literature Club, The Fruits of Grisaia, Fate: Stay/night and other famous VN games."]},{"l":"Toggling Visual Novel Mode"},{"l":"Enabling Visual Novel Mode","p":["Visual Novel Mode comes built in with SillyTavern and can be toggle by going to User Settings(User Settings Icon) and checking Visual Novel Mode below No Text Shadows.","User Settings"]},{"l":"Disabling Visual Novel Mode","p":["Disabling Visual Novel Mode is the same steps as enabling it. Untoggle Visual Novel Mode and you should be back to the normal chat screen itself.","Some extensions (like the Prome VN Extension) will toggle 'Visual Novel Mode' on if you use their own respective VN modes. Enabling/Disabling VN Mode from the User Settings menu will also affect these extensions as well."]},{"l":"The Visual Novel UI","p":["VN Display","In Visual Novel Mode, the UI is altered slightly in order to accommodate character sprites (or the character card image) which is shown in the center. In a group chat with multiple characters however, the character sprites will spread themselves out, accommodating for each other as shown below.","Group VN Display"]},{"l":"VN Mode with MovingUI","p":["To toggle MovingUI, go to User Settings and check on MovingUI. Do note that this feature only works on Desktops.","If MovingUI is enabled in User Settings, the sprites (or character card image) can be moved around if you wish to move them around or place them in a more specific area on the screen.","If the size of your character sprites are relatively big it will be a challenge to try and move certain sprites around with MovingUI as the button to drag sprites around might be covered underneath a existing sprite. You will probably have to move them around a bit more than normal, especially if there is more characters on the screen for better placement.","Group VN Display (MovingUI)"]},{"l":"Obtaining Character Sprites","p":["Obtaining character sprites can be done by browsing the internet for existing sprites, for say, a existing character from a Visual Novel or a game that uses a Visual Novel feature such as DDLC or CounterSide. If the character you desire sprites form does not come with sprites already, you have several options remaining.","Search the character post for any sprite ZIP package or link to a sprite pack.","Some bot creators may release their bots with a sprite pack (either within the same post or in a sprites channel). Search those posts if someone hasn't made sprites of the character you want already.","Create your own using LoRAs and Stable Diffusion.","Generating sprites from scratch is time-consuming (especially if no LoRAs exist for your character and/or for the Stable Diffusion model you want to use) and will require decent hardware in order to generate them, more so if you plan on making 28 sprite expression than 6 and if you are using SDXL and/or upscaling sprites to a more higher resolution.","Use the character card image. It might not be like a sprite, but at least you have something to look at on-screen. However, multiple character cards cannot be used in VN mode.","With the Prome Visual Novel Extension 1.0.6+, there is a feature called Emulate Character Card as Sprite that allows you to have a group chat with both sprite and non-sprite characters by using their character card as a sprite in chat.","Character Card Group Chat"]},{"l":"VN Extensions"},{"l":"Prome Visual Novel Extension","p":["The Prome Visual Novel Extension is an endorsed third-party extension from Bronya Rand and Prometheus that enhances the visual novel experience in SillyTavern even further with features such as Letterbox Mode which makes the visual novel UI more \"cinematic\", Focus Mode with Darken Character Sprites, Traditional VN Mode where only the last message in chat appears in chat and more planned to come!","Letterbox Mode","Traditional VN Mode","Horizontal Letterbox Mode","Hide Sheld (Message Box)","Focus Mode (w/ Darken Sprites)","Sheld Hide","Focus Mode w/ Darken Sprites","To install the Prome Visual Novel Extension, you can either install by going to Download Extensions Assets and finding Prome Visual Novel Extension, or follow the installation instructions on the Prome Visual Novel Extension Github page. Adjusting Prome's settings can be found either in Extensions-> Prome (Visual Novel Extension) or via the \uD83E\uDE84 (Wand) menu."]}],[{"l":"Personas"},{"l":"What is a Persona?","p":["A persona in SillyTavern is the identity you use to participate in chats — essentially a combination of your display name, avatar, and optional descriptive text. Personas allow you to easily switch roles or \"characters\" you speak as, without having to manually update your username/avatar each time.","Note: Legacy user avatars/names that weren't tied to a persona have been removed. Existing data will be migrated to personas. If no name was specified, the persona will be named \"[Unnamed Persona]\"."]},{"l":"How to Create a Persona?","p":["Open the Persona Management panel ( button in the top menu).","Create a blank persona with the Create button and give it a name.","In the persona list, select the newly created persona.","On the right side, you can fill in your description and set an avatar via the \"Change Persona Image\" button. Both are optional.","Now your persona is ready to use in chats."]},{"l":"Convert Character to Persona","p":["Personas can also be created by converting any existing character. Simply open the character, select \"More...\" and click \"Convert to Persona\". A persona with the same name and description will be created. Other character card fields like Scenario or Personality will not be used. The character will not be deleted.","Since {{user}} and {{char}} macros have opposite meanings when used in Persona and Character descriptions, you'll be prompted to swap them if the converted description contains either of them."]},{"l":"Persona Description","p":["Each persona can store a custom text description — mental and physical traits, age, occupation, or any personal details. These can also include template macros such as {{char}} or {{user}}(see Macros).","Where your persona description is injected into the AI prompt depends on the Position setting in the Persona Management panel:","None (disabled)","In Story String / Prompt Manager(the default)","Top of Author's Note/ Bottom of Author's Note(will only be added when an Author's Note exists)","In Chat @ Depth(this will open up configuration options to set depth and the role)","The position is saved per persona."]},{"l":"Persona Title","p":["The title is an optional text field that can be used to store additional information about the persona and is not used in the prompt, but displayed in the Persona Management panel.","To set a title, click the Rename Persona button in the Persona Management panel and enter the title in the \"Persona Title\" field, or specify it during persona creation. Setting an empty value when the title already exists will remove it."]},{"l":"Persona Connections / Locking","p":["Persona connections ensure that a given persona is automatically selected in certain situations. If no persona is connected, the currently chosen persona will stay selected.","There are three types of locking:","Chat lock– The persona is locked to the current chat.","Character lock– The persona is locked to a specific character.","Default persona– One persona that is used whenever no other locks apply."]},{"l":"1. Lock to a Chat","p":["If a persona is locked to a chat, opening that chat in the future will automatically switch your active persona to the locked one.","To lock: Select the desired persona, then click the Chat button under the \"Connections\" section (or use /persona-lock type=chat on).","To unlock: Click the button again (or use /persona-lock type=chat off)."]},{"l":"2. Lock to a Character","p":["You can also link a persona to a specific character. Opening any chat with that character automatically selects your locked persona.","To lock: Select the desired persona, then click the Character button under the \"Connections\" section (or use /persona-lock type=character on).","To unlock: Click the button again (or use /persona-lock type=character off).","The Persona Management panel also shows which characters are linked to that persona (displayed as small avatars). Clicking them navigates directly to that character's chat."]},{"l":"Locking Multiple Personas to the Same Character","p":["If another persona was already linked with that character, it will be automatically unlinked by default.","To have multiple personas linked at once, the global setting Allow multiple persona connections per character can be used. If multiple personas are linked to the same character, you'll see a popup asking which persona to use each time you open or start a new chat with that character (unless a persona is bound to the chat)."]},{"l":"3. Default Persona","p":["Your default persona is used whenever there's no other relevant lock. The default persona is recognizable by a yellow border around its avatar.","To set/unset default: Select the desired persona, then click the Default button under the \"Connections\" section (or use /persona-lock type=default).","Only one persona can be chosen as the default persona."]},{"l":"Temporary Persona","p":["If any of the three connection options connects a persona to the current character/chat, you can still choose to use a different persona. This persona will be marked in the persona panel as \"Temporary Persona\". Any reload of the browser window or switch to a different chat and back will reset it to the linked persona again.","You can manually convert a Temporary Persona to be persistently connected by linking it to the chat."]},{"l":"Global Persona Settings","p":["All settings under the Current Persona are saved per-persona. A few global settings exist too, those can be found under Global Persona Settings in the Persona Management panel.","Show notifications on switching personas","Enables persona-related toast messages (e.g., \"Persona Auto Selected\", \"Temporary Persona\").","Allow multiple persona connections per character","When enabled, you can link multiple personas to a single character. Opening that character's chat will prompt you which persona to use. If disabled, only one persona can be connected to a character at a time.","Auto-lock a chosen persona to the chat","When enabled, any time you select a persona (manually or by auto-selection) or create a new chat, it locks that persona to the chat. This combined with \"Allow multiple\" provides the option to have a persona selection per character, but keep it bound once chosen for a chat."]},{"l":"Slash Commands for Personas"},{"l":"/persona-lock type=type?","p":["chat locks the current persona to your active chat.","character locks the current persona to the character in use.","none(or no argument) unlocks/clears the persona lock for the current context.","If used without arguments, it returns the current lock state (or an error if none is set).","The lock state can be chosen via on, off or toggle. Default is toggle."]},{"l":"/persona name","p":["Quickly switch your active persona by name without opening the Persona Management panel.","Example: /persona Blaze.","Using mode=temp allows to temporarily set your name of the current persona, even though a persona with the same name might already exist (preserving your current avatar and description)."]},{"l":"/persona-sync","p":["Re-attributes all user messages in the active chat to the current persona and its name.","Note: The older /lock and /unlock commands remain for backward compatibility but may be removed in the future. Use /persona-lock instead."]},{"l":"Pro Tips","p":["Switching personas mid-chat doesn't re-attribute your past user messages to the new persona; those remain attributed to whichever persona you were using at the time.","Batch re-attribution: If you ever need all prior messages to match a new persona, hit the sync button or use /persona-sync.","Replace persona images without losing description or locks by choosing your persona and clicking the Change Persona Image button.","Character link popups: If multiple personas are linked to the same character, you'll get a popup to pick which persona each time you open the chat. This is a handy way to have a small selection of personas to choose from for specific characters.","Backups: You can back up your entire persona list (names, character connections, descriptions) with the Backup button in Persona Management, and restore it later if needed.","Images and chat connections are not saved together with personas and will not be backed up via this.","These backups are not designed to be shared, as they contain internal links."]}],[{"l":"Characters","p":["Characters are the AI identities that you can create and manage to shape the AI's role in the conversation. Each character has a name, personality, and conversation history. You can create as many characters as you like, and switch between them at any time.","Characters can be used in solo chats, or add multiple characters to a group chat to let them interact with each other."]},{"l":"Character Management Panel","p":["Open the Characters panel from the navbar to access the character list. Click on a character or group to chat with them or edit them, or choose Create New Character to add a new character."]},{"l":"Panel Controls","p":["Pin Panel: Keep panel open while interacting","Character List: Return to character list view","HotSwap Bar: Quick access to favorite characters"]},{"l":"Character List","p":["Create New Character: Add a new character","Import Character: Load character from file","External Import: Import from URL","Create Group: Start a new group chat"]},{"l":"Search and sort","p":["Search Bar: Filter characters by name or attributes","Sort Dropdown: Multiple sorting options:","Alphabetical (A-Z, Z-A)","Chronological (Newest, Oldest)","Usage-based (Recent, Most/Least chats)","Size-based (Most/Least tokens)","Special (Favorites, Random)"]},{"l":"Filter characters by type or tag","p":["Favorites Filter: Show favorite characters","Groups Filter: Show only group chats","Tags as Folders: Organize by tag hierarchy","Manage Tags: Tag configuration","Tag List: View all available tags","Clear Filters: Reset all filters"]},{"l":"Character Creation/Edit Panel","p":["Avatar Image: Upload and preview character profile picture","Token Count: Token usage for the character","Stats: Chat history and usage statistics","Tag management"]},{"l":"Quick Actions","p":["Favorite toggle","Advanced definitions","Character lore","Chat lore: link the chat to a World Info","Export character","Duplicate","Delete"]},{"l":"Extended Options","p":["World Info linking","Card lore import","Scenario override","Persona conversion","Character rename","Source linking","Replace/Update","Tag import","Gallery view"]},{"l":"Content Fields","p":["Character Description: Brief character summary","First Message: Initial greeting or prompt when starting a new chat","Alternative greetings: Define multiple first messages that you can swipe between when starting a chat"]},{"l":"Advanced Definitions Panel","p":["Click on the Advanced Definitions button to access the extended character settings."]},{"l":"Prompt Overrides (Chat Completion/Instruct Mode)","p":["Main Prompt: Replaces default main/system prompt, can use{{original}} placeholder to include the original prompt","Post-History Instructions: Overrides default post-history instructions"]},{"l":"Creator's Metadata","p":["Non-prompt information about the character:","Creator name/contact","Character version","Creator's notes","Embedded tags list"]},{"l":"Character Personality","p":["Personality Summary: Brief overview of character's traits","Scenario: Context and circumstances of the dialog","Character's Note: Custom message with selectable depth and message role (also see Author's Note)","Talkativeness(Group Chats): Slider for Shy → Normal → Chatty","Example Messages: Examples of character's writing style"]},{"l":"Group Chat Management","p":["If this is a group chat, you can manage the group members and settings from this panel.","See Group Chats for more details."]}],[{"l":"Character Design","p":["Character Name is the only required field. You can leave the rest empty and still use the character in chats."]},{"l":"Character Description","p":["Used to add the character description and other relevant information for the AI. This information is always included in the prompt, so all important facts should be included here.","For example, you can add information about the world in which the action takes place, describe the character's appearance, personality, and background.","It could be of any length (be it 200 or 2000 tokens) and formatted in any style (free text, pseudo-code conversation style, etc.)."]},{"l":"Methods and format","p":["Methods of character formatting are a complicated topic beyond the scope of this documentation page.","Recommended guides that were tested with or rely on SillyTavern's features:","Trappu's PLists + Ali:Chat guide: https://wikia.schneedc.com/bot-creation/trappu/creation","AliCat's Ali:Chat guide: https://rentry.co/alichat","kingbri's minimalistic guide: https://rentry.co/kingbri-chara-guide"]},{"l":"Character tokens","p":["TL;DR: If you're working with an AI model with a 2048 context token limit, a 1000-token character definition cuts the AI's 'memory' in half.","To put this in perspective, a decent response from a good AI can easily be around 200-300 tokens. In this case, the AI would only be able to 'remember' about 3 exchanges worth of chat history."]},{"l":"Why did my character's token counter turn red?","p":["When we see your character has over half of the model-defined context length of tokens in its definitions, we highlight it for you because this can lower the AI's capabilities to provide an enjoyable conversation."]},{"l":"What happens if my Character has too many tokens?","p":["Don't worry - it won't break anything. At worst, if the Character's permanent tokens are too large, it simply means there will be less room left in the context for other things (see below).","The only negative side effect this can have is that the AI will have less 'memory', as it will have less chat history available to process.","This is because every AI model has a limit to the amount of context it can process at one time."]},{"l":"'Context'?","p":["This is the information that gets sent to the AI each time you ask it to generate a response. SillyTavern automatically calculates the best way to allocate the available context tokens before sending the information to the AI model.","Read more about how the context is built in the Prompts section."]},{"l":"What are a Character's 'Permanent Tokens'?","p":["These will always be sent to the AI with every generation request:","Character Name","Character Description Box","Character Personality Box","Scenario Box"]},{"l":"What parts of a Character's Definitions are NOT permanent?","p":["The first message box - only sent once at the start of the chat.","Example messages box - only kept until chat history fills up the context (optionally these can be forced to be kept in context)"]},{"l":"Popular AI Model Context Token Limits","p":["LLaMA 3 and its finetunes - 8192","OpenAI GPT-4 - up to 128k","Google Gemini - up to 2M","Anthropic's Claude - 200k (Claude 3)","NovelAI - 8192 (Erato and Kayra, Opus tier; Clio, all tiers), 6144 (Kayra, Scroll tier), or 3072 (Kayra, Tablet tier)"]},{"l":"First message","p":["The First Message is an important element that defines how and in what style the character will communicate. The model is most likely to pick up the style and length constrains from the first message than anything else, so it's important to write it in a way that you want the responses to be (short and concise, long and detailed, etc.).","Supports Markdown and HTML formatting.","For example:"]},{"l":"Alternate Greetings","p":["Messages added here are displayed as additional 'swipes' for the character's first message when starting a new chat. If the character is part of a group chat, the system randomly selects one of these greetings to initiate the conversation."]},{"l":"Favorite Character","p":["Click the Add to Favorites button to mark the character as a favorite to quickly filter them on the side menu bar by selecting the \"Favorites\" sort option. Favorite characters have a golden highlight in the list. This will also make the character portrait appear in the hotswaps area (if enabled in User Settings)."]},{"l":"Advanced Definitions","p":["The following fields are hidden by default. To access and edit them, you need to click on the Advanced Definitions button on the menu bar of the character definition page."]},{"l":"Prompt Overrides","p":["Main Prompt: If the \"Prefer Char. Prompt\" user setting is enabled, any text you put here will override the main/system prompt for the character.","Post-History Instructions: If the \"Prefer Char. Instructions\" user setting is enabled, any text you put here will be used as the post-history instructions for the character.","Insert {{original}} into either box to include the respective default prompt from system settings in a designated place."]},{"l":"Creator's Metadata","p":["Not used for prompt building, but provides additional metadata about the character.","Created by: The name of the character's creator. Can be displayed in the character list if the \"Char List Subheader\" user setting is set accordingly.","Character Version: The version of the character. Can be displayed in the character list if the \"Char List Subheader\" user setting is set accordingly.","Creator's Notes: Any additional notes about the character that the creator wants to share. The first few lines are displayed in the character list, and the full text is displayed in the \"Creator's Notes\" section on the character's page. Supports Markdown/HTML formatting.","Tags to Embed: A comma-separated list of tags that will be embedded in the character's description. These tags are not imported by default when importing the character, but you can merge them with your existing tags by selecting \"Import Tags\" from the \"More...\" menu on the character's page."]},{"l":"Personality summary","p":["A brief summary of the character's personality."]},{"l":"Scenario","p":["The circumstances and context of the dialogue."]},{"l":"Character's Note","p":["A text to be used as an in-chat prompt injection for the character at a specific message depth. It is usually used to reinforce certain character traits, as it always stays at a static depth in the chat history, regardless of its progression.","@ Depth: The number of messages in the chat history after which this note will be injected (in order from newest to oldest). If set to 0, it will be injected after the last message.","Role: The role of the message. Can be \"User\", \"System\", or \"Assistant\"."]},{"l":"Talkativeness","p":["Determines the probability of the character's response being triggered in group chats when using a Natural activation order. Ranges from 0% to 100%, with 50% being the default value."]},{"l":"Examples of dialogue","p":["Describes how the character speaks. Before each example, you need to add the START tag. The blocks of example dialogue are only inserted if there is free space in the context for them and are pushed out of context block by block. START will not be present in the prompt as it is just a marker; it will be replaced with the \"Example Separator\" from Advanced Formatting for Text Completion APIs and the contents of the \"New Example Chat\" utility prompt for Chat Completion APIs.","Use the {{char}}: prefix to denote a character message.","Use the {{user}}: prefix to denote a user message.","Example:"]}],[{"l":"Macros (replacement tags)","p":["This list may be incomplete or outdated. Use the /help macros slash command in any SillyTavern chat to get the list of macros that work in your instance.","Macros can be used in character description, author's notes, world info and many other places and replaced with the corresponding values when generating a response. They can be used to insert dynamic content into the prompt, such as the user's name, character's description, or the current time. Macros are enclosed in double curly braces, e.g. {{user}} and are usually case-insensitive. Please keep in mind that macro nesting is currently not supported.","Note: some extensions may also add special context-specific macros that only work in certain areas (i.e. special placeholders for extension prompts). These will not be documented here unless the macro is not bound to a specific functionality."]},{"l":"General Macros","p":["{{// (note)}}","{{banned text here}}","{{bias text here}}","{{char}} or BOT","{{charDepthPrompt}}","{{charJailbreak}}","{{charPrompt}}","{{charVersion}}","{{currentSwipeId}}","{{date}}","{{datetimeformat ...}}","{{description}}","{{firstIncludedMessageId}}","{{group}} or {{charIfNotGroup}}","{{groupNotMuted}}","{{idle_duration}}","{{input}}","{{isodate}}","{{isotime}}","{{lastCharMessage}}","{{lastGenerationType}}","{{lastMessage}}","{{lastMessageId}}","{{lastSwipeId}}","{{lastUserMessage}}","{{mesExamples}}","{{mesExamplesRaw}}","{{model}}","{{newline}}","{{noop}}","{{original}}","{{persona}}","{{personality}}","{{pick::(args)}}","{{pipe}}","{{random::arg1::arg2}}","{{random:(args)}}","{{reverse:(content)}}","{{roll:(formula)}}","{{scenario}}","{{time_UTC±X}}","{{time}}","{{timeDiff::(time1)::(time2)}}","{{trim}}","{{user}} or USER","{{weekday}}","1-based ID of the currently displayed last message swipe.","Allows leaving a note that will be replaced with blank content. Not visible for the AI.","Alternate syntax for random that supports commas in its arguments.","Alternative to random, but the selected argument is stable on subsequent evaluations in the current chat if the source string remains unchanged.","Can be used in Prompt Overrides fields to include the default prompt from system settings. Applied to Chat Completion APIs and Instruct mode only.","Character's description.","Character's examples of dialogue (instruct-formatted).","Character's examples of dialogue (unaltered and unsplit).","Character's Main Prompt override.","Character's name.","Character's personality.","Character's Post-History Instructions Prompt override.","Character's scenario or chat scenario override (if set).","Comma-separated list of group member names or character name in solo chats.","Contents of the user input bar.","Current date/time in specified format (e.g. {{datetimeformat DD.MM.YYYY HH:mm}}).","Current system date.","Current system time.","Current time in the specified UTC offset (timezone), e.g. for UTC+02:00 use {{time_UTC+2}}.","Description","Dynamically adds quoted text to banned word sequences for Text Generation WebUI backend. Does nothing for other backends. Quotes required.","Generates a random value using D&D dice syntax: XdY+Z (e.g. {{roll:d6}} generates a value 1-6).","Inserts a humanized string of the time range since the last user message was sent (examples: 4 hours, 1 day).","Inserts a newline.","Last chat message ID.","Last chat message sent by character.","Last chat message sent by user.","Last chat message text.","Macro","No operation, just an empty string.","Number of swipes in the last chat message.","Only for slash command batching. Replaced with the returned result of the previous command.","Returns a random item from the list (e.g. {{random:1,2,3,4}} will return 1 of the 4 numbers at random).","Reverses the content of the macro.","Same as {{group}} but excludes muted members.","Sets a behavioral bias for the AI until the next user input. Quotes around text are required.","Text generation model name for the currently selected API. Can be inaccurate!","The character's at-depth prompt.","The character's version number.","The current ISO date (YYYY-MM-DD).","The current ISO time (24-hour clock).","The current weekday.","The ID of the first message included in the context. Requires generation to be run at least once in the current session.","The time difference between time1 and time2. Accepts time and date macros.","Trims newlines surrounding this macro.","Type of the last queued generation request. Values: \"normal\", \"impersonate\", \"regenerate\", \"quiet\", \"swipe\", \"continue\".","User's name.","User's persona description."]},{"l":"Instruct Mode and Context Template Macros","p":["(enabled in the Advanced Formatting settings)","{{chatStart}}","{{defaultSystemPrompt}}","{{exampleSeparator}}","{{instructAssistantPrefix}}","{{instructAssistantSuffix}}","{{instructFirstAssistantPrefix}}","{{instructFirstUserPrefix}}","{{instructLastAssistantPrefix}}","{{instructLastUserPrefix}}","{{instructStop}}","{{instructSystemInstructionPrefix}}","{{instructSystemPrefix}}","{{instructSystemPrompt}}","{{instructSystemPromptPrefix}}","{{instructSystemPromptSuffix}}","{{instructSystemSuffix}}","{{instructUserFiller}}","{{instructUserPrefix}}","{{instructUserSuffix}}","{{maxPrompt}}","{{systemPrompt}}","Assistant first output sequence.","Assistant last output sequence.","Assistant message prefix sequence.","Assistant message suffix sequence.","Context template chat start line.","Context template example dialogues separator.","Description","Instruct stop sequence.","Instruct system prompt.","Instruct user first input sequence.","Instruct user last input sequence.","Macro","Max size of the prompt in tokens (context length reduced by response length).","System instruction prefix sequence.","System message prefix sequence.","System message suffix sequence.","System prompt content (excluding character prompt override).","System prompt content, including character prompt override if allowed and available.","System prompt prefix sequence.","System prompt suffix sequence.","User filler message text.","User message prefix sequence.","User message suffix sequence."]},{"l":"Chat variables Macros","p":["{{addglobalvar::name::value}}","{{addvar::name::increment}}","{{decglobalvar::name}}","{{decvar::name}}","{{getglobalvar::name}}","{{getvar::name}}","{{incglobalvar::name}}","{{incvar::name}}","{{setglobalvar::name::value}}","{{setvar::name::value}}","{{var::name::index}}","{{var::name}}","Description","Global variables = works in any chat for any character","Local variables = unique to the current chat","Macro","Replaced with empty string, adds a numeric value of \"increment\" to the global variable \"name\".","Replaced with empty string, adds a numeric value of \"increment\" to the local variable \"name\".","Replaced with empty string, sets the global variable \"name\" to \"value\". Allows empty values.","Replaced with empty string, sets the local variable \"name\" to \"value\". Allows empty values.","Replaced with the result of decrementing the value of global variable \"name\" by 1.","Replaced with the result of decrementing the value of variable \"name\" by 1.","Replaced with the result of incrementing the value of global variable \"name\" by 1.","Replaced with the result of incrementing the value of variable \"name\" by 1.","Replaced with the value at index of the scoped variable \"name\" (for arrays/objects in STscript).","Replaced with the value of the global variable \"name\".","Replaced with the value of the local variable \"name\".","Replaced with the value of the scoped variable \"name\" (STscript only)."]},{"l":"Extension-specific Macros","p":["Added by extensions and only work under certain conditions.","Macro","Description","{{summary}}","Replaced with the summary of the current chat session (if available).","{{authorsNote}}","Replaced with the contents of the Author's Note.","{{charAuthorsNote}}","Replaced with the contents of the Character's Author's Note.","{{defaultAuthorsNote}}","Replaced with the contents of the default Author's Note.","{{charPrefix}}","Replaced with a character-specific Image Generation positive prompt prefix (if available).","{{charNegativePrefix}}","Replaced with a character-specific Image Generation negative prompt prefix (if available)."]}],[{"l":"Chat File Management","p":["This page describes the ways you can manage your AI chat files.","Some of these options are available in the \"Manage chat files\" dialog that opens from the bottom left options menu."]},{"l":"Solo Chats vs Group Chats","p":["The simplest way to use a character card is a Solo chat; just click on their card and start chatting.","Once you have a few character cards, you can also use the \"Create New Chat Group\" button to create a group chat including multiple characters which will then interact with each other and you."]},{"l":"Chat import","p":["Import chats from Character.AI into SillyTavern.","To import Character.AI chats and bots, use the CAI Tools browser extension: https://github.com/irsat000/CAI-Tools.","Other programs and tools that you can import chats from include:","TavernAI (original): https://github.com/TavernAI/TavernAI","Text Generation WebUI (oobabooga): https://github.com/oobabooga/text-generation-webui","Agnai: https://github.com/agnaistic/agnai","KoboldAI Lite: https://github.com/LostRuins/lite.koboldai.net","RisuAI: https://github.com/kwaroran/RisuAI"]},{"l":"Export as .jsonl","p":["When clicking on \"Manage chat files\", each entry on the the chat file list will have a button to export it in a format that can then be re-imported as is. Use this to share or migrate chats including all their metadata (but excluding images and file attachments).","If you're mindful of privacy, be sure to inspect the exported JSONL file and scrub anything you don't want to share."]},{"l":"Export as .txt","p":["You can also export a simplified text-only version with the \"Download chat as plain text document\" button. It can't be re-imported again as it loses important metadata!"]},{"l":"Checkpoints","p":["\"Checkpoints\" are clones of the current chat, in that they copy all messages from the given chat up to a certain point, and they store a link to the source (by chat file name).","From the three dots button at the right of each chat message, you have two ways to create checkpoints:","\"Create Branch\" will clone the current chat up to that message and switch to it","\"Create Checkpoint\" will clone current chat up to that message, ask for a name and create it but NOT switch to it","You can think of them as roughly as \"open link in new tab\" and \"open link in new tab in the background\" in a browser.","You can go back to the parent from a checkpoint by entering the burger menu button on the left of the message text box, then clicking \"Back to parent chat\"."]},{"l":"Rename Chat","p":["By default chat files are given a named with the date and time they were started.","You can change this by clicking the pencil icon and typing in a new name.","Note that this will break links to that chat from checkpoints (since they are linked by chat file name)."]}],[{"l":"Group Chats"},{"l":"Reply order strategies","p":["Decides how characters in group chats are drafted for their replies."]},{"l":"Manual","p":["You can select the character to reply manually from the menu or with the /trigger command. The selected group member will be the only one to reply. User messages won't trigger any replies automatically. Triggering a generation with an empty user input will trigger a random unmuted group member to reply."]},{"l":"Natural Order","p":["Tries to simulate the flow of a real human conversation. The algorithm is as follows:","Mentions of the group member names are extracted from the last message in chat.","Only whole words are recognized as mentions! If your character's name is \"Misaka Mikoto\", they will reply only activate on \"Misaka\" or \"Mikoto\", but never to \"Misa\", \"Railgun\", etc.","Unless the \"Allow Self Responses\" setting is enabled, characters won't reply to mentions of their name in their own message!","Characters are activated by the \"Talkativeness\" factor.","Talkativeness defines how often the character speaks if they were not mentioned. Adjust this value on the \"Advanced Definitions\" screen in the character editor. Slider values are on a linear scale from 0% / Shy(character never talks unless mentioned) to 100% / Chatty(character always replies). The default value for new characters is 50% chance.","A random character is selected.","If no characters were activated at previous steps, one speaker is selected randomly, ignoring all other conditions."]},{"l":"List Order","p":["Characters are drafted based on the order they are presented in the group members list. No other rules apply."]},{"l":"Pooled Order","p":["Activates one random character who have't spoken yet since the last user message. If all characters have spoken, selects one randomly until the next user message."]},{"l":"Group generation handling mode","p":["This setting decides how to handle the character information of the group chat members. No matter the choice, the group chat history is always shared between all the members."]},{"l":"Swap character cards","p":["Default mode. Every time the message is generated, only the character card information of the active speaker is included in the context."]},{"l":"Join character cards","p":["The information of all of the group members is combined into one joint prompt in their list order. This can help in cases when altering large chunks of the context is undesirable, e.g. with llama.cpp prompt caching.","This mode has two sub-modes (you must choose one):","Include muted - muted characters will always be included into the joint prompt.","Exclude muted - muted characters won't be included if they aren't the current speaker.","The following fields are being combined:","Description","Scenario, if not overridden for the chat","Personality","Message examples","Character notes / Depth prompts","Important! Please be aware that due to how the typical character card is structured, the use of this mode can lead to unexpected behavior, including but not limited to: characters being confused about themselves, having merged personalities, uncertain traits, etc."]},{"l":"Join Prefix and Suffix","p":["When 'Join character cards' is selected, all respective fields of the characters are being joined together. This means that in the resulting prompt all character descriptions will be joined to one big blob of text. If you want those fields to be separated, you can define a prefix and/or suffix.","These options support normal macros and will also replace {{char}} with the relevant characters's name and <FIELDNAME> with the name of the part (e.g.: description, personality, scenario, etc.)"]},{"l":"Other Group Chat menu options"},{"l":"Mute Character","p":["The struck-out speech bubble icon next to the character avatar in the group chat menu can disable or enable replies from a particular character in the chat."]},{"l":"Force Talk","p":["The speech bubble icon next to the character avatar in the group chat menu will trigger a reply only from a particular character, bypassing the reply order strategy. It will work even if the group member is muted."]},{"l":"Auto-mode","p":["While auto-mode is enabled, the group chat will follow the reply order and trigger the message generation without user interaction. The next auto-mode turn is triggered after a 5-second delay when the last drafted character sends its message. When the user starts typing into the send message text area, the auto-mode will be disabled, but already queued generations are not stopped automatically."]},{"l":"Allow Self Responses","p":["Will allow consecutive replies from the character who sent the latest message of each turn if they happen to be triggered due to being self-mentioned when the Natural Order is selected. Has no effect on List order."]},{"l":"Group Chat Scenario Override","p":["All group members will use the entered scenario text instead of what is specified in their character cards. Branched chats inherit the scenario override from their parent and can be changed individually after that."]},{"l":"Peek Character Definitions","p":["Clicking on the character card icon next to the avatar in the group chat menu will quickly navigate to the usual character definitions screen. Any changes made here will be saved to the card itself.","To return back to the group chat, click the Group Name title link."]},{"l":"Member Management","p":["Any of your existing characters can be added, removed, muted, or re-ordered within the group chat. By default, a new member is added to the top of the group members list and then can be re-ordered using the arrow icons."]},{"l":"Group Chat pop-out","p":["The group chat menu pop-out can be activated by clicking on the icon next to the \"Current Members\" field. This creates a pop-out of the group chat menu. By enabling MovingUI from user settings, this menu can resized and dragged to any position within the interface and functions just like the regular group chat menu."]}],[{"l":"Tags","p":["Character cards and groups can be assigned zero or more tags. They are useful to organize quickly growing collections by themes, quality, provenance or whatever you like."]},{"l":"Tagging","p":["There are several ways to add or remove tags to a character card:","Import embedded tags during the import.","Open a card from the Character Management panel. From there you will be able to assign tags to a character card.","Mass tagging.","To do mass tagging, click the \"Bulk edit characters\" button (pencil icon), select the cards you want to tag, right click on any of them, then click \"Tag\" in the contextual menu.","Please note that groups cannot be mass tagged.","From this screen you will be able to:","Add or remove tags using the combo box.","Remove all tags from the selected cards (\"All\").","Remove the intersection of tags among all selected cards from those cards (\"Mutual\").","Import (create locally) all tags stored in the character card, in case you imported it (\"Import All\").","Import (create locally) tags stored in the character card which also exist locally with matching names (\"Import Existing\")."]},{"l":"Managing","p":["To view and manage all existing tags, open the Character Management panel then click on the \"Manage tags\" button (gear icon).","You can backup and restore all the information here (tag list, tag assignments to cards, colors, folder settings, etc) using the buttons on the top right.","You can use grip buttons on the left to reorder tags as they will appear in the tag filter in Character Management.","The tags backup JSON file is not intended for sharing with others as it contains information specific to your instance only, such as internal entity names!"]},{"l":"Importing tags when importing character cards","p":["When importing external character cards from downloaded images (or from the \"Import content from external URL\" button), you'll be prompted to optionally import the tags that it contains. They are not required for the card to function; tags are simply organizational.","Embedded card tags are stored in the \"Creator's Metadata\" section of \"Advanced Definitions\" menu of the character editor. If you wish to propose some tags to other users who would import that character, populate the \"Tags to Embed\" field with a comma-separated list of tags.","This popup will appear only if a User Settings option \"Import Card Tags\" is set to \"Ask\".","In the \"Import tags for CHARACTER NAME\" popup that opens, you'll see a list of Existing tags (which you already had locally with a matching name), and New tags (which you did not have locally).","You can either:","Trim the lists as needed and then hit \"Import\" - remaining Existing tags will be added to the imported character card, and remaining New tags will be created locally and then added to the card.","Or simply hit \"Import none\" to ignore tags contained in the character card and import ONLY the card.","Or \"Import All\" as a shortcut to import all tags found in the character card (NOTE: including any that you trimmed from the lists above; use the \"Import\" button if you did).","Or \"Import Existing\" as a shortcut to only import tags that existed locally with a matching name."]},{"l":"Filtering character cards","p":["After you create tags, you will see them on a row in the Character Management panel. You can click these to switch tag filtering state; in order:","One click will show cards tagged with this tag.","Another click to only show cards NOT tagged with this tag.","Another click to reset filtering by this tag.","You can filter by any number of tags at the same time."]},{"l":"Tags as Folders","p":["To use this functionality, it has to be enabled first in the User Settings, under the UI Theme column. The state of this toggle also saves with the UI theme.","From the \"Manage tags\" button (gear icon), each tag entry has a multi-state toggle button to cycle between these tags-as-folder modes (called \"bogus folder\" in the code):","one click to turn this tag into an \"open folder\". It will appear as a virtual entry in the card list; clicking into it will only show cards with that tag","another click to turn this tag into a \"closed folder\". As above, but cards tagged with this tag will not appear by default - you'll need to click into the folder to see them.","another click to reset tag-as-folder state for this tag."]}],[{"l":"Author's Note"},{"l":"What is it?","p":["Author's Note is a powerful tool for customizing AI responses which inserts a section of text into the prompt at any position and at any frequency you desire."]},{"l":"Usage","p":["The Author's Note can be found in the Options menu on the left side of the chat input bar.","Options Menu","Author's Note Panel"]},{"l":"Configuring Author's Notes"},{"l":"Chat-specific Author's Note","p":["The box at the top of the Author's Note panel contains the Author's Note for your current chat.","The Content of this box is not automatically transferred to any new chat."]},{"l":"Placement options"},{"l":"After Scenario","p":["This places the Author's Note towards the top of the context after the 'Scenario' section of the Character Definition. If no scenario is specified, it will be placed after the last portion of the Character Definition, and before the Example messages."]},{"l":"In-chat","p":["This places the Author's Note into the chat history at the specified depth.","Depth 0 = placed at the very end of the chat history.","Depth 4 = placed before the most recent 3 chat history messages, making it become the 4th entity in the chat history.","The closer the Author's Note is to the bottom of the prompt, the more impact it has on the next AI response."]},{"l":"Insertion Frequency","p":["This is how often you want the Author's Note to be included in the chat.","Frequency 0 = Author's Note will never be inserted.","Frequency 1 = Author's Note will be inserted with every user input prompt.","Frequency 4 = Author's Note will be inserted into every 4th user input prompt."]},{"l":"Default Author's Note","p":["The box at the bottom of the panel contains the Default Author's Note which will be applied to each new chat."]},{"l":"Common Use Cases"},{"l":"Remind AI of response formatting","p":["The Author's Note can be used to specify how the AI should write it's responses.","[Your next response must be 300 tokens in length.]","[Write your next reply in the style of Edgar Allan Poe]","[Use markdown italics to signify unspoken actions, and quotation marks to specify spoken word.]"]},{"l":"Reinforcing Instructions","p":["[Remember the instructions you were given at the beginning of this chat.]"]},{"l":"As temporary World Info, Character Bias, or Instruct for non-Instruct models","p":["[{{char}} is in the library]","[{{user}} has a fresh wound to his leg, so won't be able to run away.]","[{{char}} cannot speak and must communicate using hand signals.]"]}],[{"l":"Data Bank (RAG)","p":["Retrieval-augmented generation (RAG) is a technique for providing external sources of knowledge to the LLM. It helps improve the accuracy of AI answers by accessing information outside of the model's training data.","SillyTavern provides a set of tools for building a multi-purpose knowledge base from a diverse number of sources, as well as using the collected data in LLM prompts."]},{"l":"Accessing the Data Bank","p":["The built-in Chat Attachments extension (included by default in release versions >= 1.12.0) adds a new option in the \"Magic Wand\" menu - Data Bank. This is your hub for managing the documents available for RAG in SillyTavern."]},{"l":"About Documents","p":["Data Bank stores file attachments, also known as documents. The documents are divided into three scopes of availability.","Global attachments - available in every chat, either solo or group.","Character attachments - available only for the currently chosen character, including when they are replying in a group. Attachments are saved locally and are not exported with the character card!","Chat attachments - available only in the currently open chat. Every character in the chat can pull from it.","While not formally a part of the data bank, you can attach files even to individual messages. Use the Attach File option from the \"Wand\" menu, or a paperclip icon in the message actions row.","What can be a document? Practically anything that is representable in plain text form!","Examples include, but are not limited to:","Local files (books, scientific papers, etc.)","Web pages (Wikipedia, articles, news)","Video transcripts","Various extensions and plugins can also provide new ways to gather and process data, more on that below."]},{"l":"Data Sources","p":["To add a document to any of the scopes, click \"Add\" and pick one of the available sources."]},{"l":"Notepad","p":["Create a text file from scratch, or edit an existing attachment."]},{"l":"File","p":["Upload a file from the hard drive of your computer. SillyTavern provides built-in converters for popular file formats:","PDF (text only)","HTML","Markdown","ePUB","TXT","You can also attach any text files with non-standard extensions, such as JSON, YAML, source codes, etc. If there are no known conversions from the type of a selected file, and the file can't be parsed as a plain text document, the file upload will be rejected, meaning that raw binary files are not allowed.","Importing Microsoft Office (DOCX, PPTX, XLSX) and LibreOffice documents (ODT, ODP, ODS) requires a Server Plugin to be installed and loaded. See the plugin's README page for installation instructions."]},{"l":"Web","p":["Scrape text from a web page by its URL. The HTML document is then processed through the Readability library to extract only usable text.","Some web servers may reject fetch requests, be protected by Cloudflare, or rely heavily on JavaScript to function. If you're facing issues with any particular site, download the page manually through the web browser and attach it using the file uploader."]},{"l":"YouTube","p":["Download a transcript of the YouTube video by its ID or URL, either uploaded by the creator or automatically generated by Google. Some videos may have the transcripts disabled, also parsing of age-restricted videos is unavailable as it requires login.","The script is loaded in the video's default language. Optionally, you can specify the two-letter language code to try and fetch the transcript in a specific language. This feature is not always available and may fail, so use it with caution."]},{"l":"Web Search","p":["This source requires to have a Web Search extension installed and properly configured. See the linked page for more details.","Perform a web search and download the text from the search result pages. This is similar to the Web source but fully automated. A chosen search engine will be inherited from the extension settings, so set it up in advance.","To begin, specify the search query, max number of links to be visited, and the output type: one combined file (formatted according to the extension rules) or an individual file for every single page. You can choose to save the page snippets as well."]},{"l":"Fandom","p":["This source requires to have a Server Plugin installed and loaded. See the plugin's README page for installation instructions.","Scrape articles from a Fandom wiki by its ID or URL. As some wikis are very large, it may be beneficial to limit the scope using the filter regular expression, it will be tested against the article's title. If no filter is provided, then all of the pages are subject to be exported. You may save them either as individual files for every page, or joint into a single document."]},{"l":"Bronie Parser Extension (Third-Party)","p":["This source comes from a third-party and is not affiliated with the SillyTavern team. This source requires you to have Bronya Rand's Bronie Parser Extension installed as well as Server Plugins that require the parser to work.","Bronya Rand's Bronie Parser Extension allows the use of third-party scrapers, such as miHoYo/HoYoverse's HoYoLab into SillyTavern, similar to the other data sources.","Currently, Bronya Rand's Bronie Parser Extension supports the following:","miHoYo/HoYoverse's HoYoLab (for Genshin Impact/Honkai: Star Rail) via HoYoWiki-Scraper-TS","To begin, install Bronya Rand's Bronie Parser Extension by following it's installation guide and install a supported Server Plugin into SillyTavern. Restart SillyTavern and go to the Data Bank menu. Click + Add and you should see that your recently installed scrapers are added into the possible list of sources to obtain information from."]},{"l":"Vector Storage","p":["So, you've built yourself a nice and comprehensive library of information on your specific subject matter. What's next?","To use the documents for RAG, you need to use a compatible extension that will insert related data into the LLM prompt.","Vector Storage, which comes bundled with SillyTavern, is a reference implementation of such an extension. It uses embeddings (also known as vectors) to search for documents that relate to your ongoing chats.","Embeddings are arrays of numbers that abstractly represent a piece of text, produced by specialized language models. More similar texts have a shorter distance between their respective vectors.","Vector Storage extension uses the Vectra library to keep track of file embeddings. They are stored in JSON files in the /vectors folder of your user data directory. Every document is internally represented by its own index/collection file.","As the Vectors functionality is disabled by default, you need to open the extensions panel (\"Stacked Cubes\" icon on the top bar), then navigate to the \"Vector Storage\" section, and tick the \"Enabled for files\" checkbox under the \"File vectorization settings\".","By itself, Vector Storage does not produce any vectors, you need to use a compatible embedding provider."]},{"l":"Vector Providers","p":["Embeddings are only usable when they are retrieved using the same model that generated them. When changing an embedding model or source, the vectors need to be recalculated."]},{"l":"Local","p":["These sources are free and unlimited and use your CPU/GPU to calculate embeddings.","Local (Transformers) - runs on a Node server. SillyTavern will automatically download a compatible model in ONNX format from HuggingFace. Default model: jina-embeddings-v2-base-en.","WebLLM - requires an extension to be installed and a web browser that supports WebGPU. Runs directly in your browser, can use hardware accelleration. Automatically downloads supported models from HuggingFace. Install the extension from here: https://github.com/SillyTavern/Extension-WebLLM.","Ollama - get it from https://ollama.com/. Set the API URL in the API connection menu (under Text Completion, default: http://localhost:11434). Must download a compatible model first, then set its name in the extension settings. Example model: mxbai-embed-large. Optionally, check an option to keep the model loaded in memory.","llama.cpp server - get it from ggerganov/llama.cpp and run the server executable with --embedding flag. Load compatible GGUF embedding models from HuggingFace, for example, nomic-ai/nomic-embed-text-v1.5-GGUF.","vLLM - get it from vllm-project/vllm. Set the API URL and API key in the API connection menu first.","Extras (deprecated) - runs under the Extras API using the SentenceTransformers loader. Default model: all-mpnet-base-v2. This source is not maintained and will be eventually removed in the future."]},{"l":"API sources","p":["All these sources require an API key of the respective service and usually have a usage cost, but generally calculating embeddings is pretty cheap.","OpenAI","Cohere","Google AI Studio","Google Vertex AI","TogetherAI","MistralAI","NomicAI"]},{"l":"Vectorization Settings","p":["After you've selected your embedding provider, don't forget to configure other settings that will define the rules for processing and retrieving documents.","Splitting, vectorization, and retrieval of information from the attachments take some time. While the initial ingestion of the file may take a while, the RAG search queries are usually fast enough not to create a significant lag."]},{"l":"Message attachments","p":["These settings control the files that are attached directly to the messages.","The following rules apply:","Only messages that fit in the LLM context window can have their attachments retrieved.","When the vector storage extension is disabled, file attachments and their accompanying message are fully inserted into the prompt.","When file vectorization is enabled, then the file will be split into chunks and only the most relevant pieces will be inserted, saving the context space and allowing the model to stay focused.","Size threshold (KB) - sets a chunking splitting threshold. Only the files larger than the specified size will be split.","Chunk size (chars) - sets the target size of an individual chunk (in textual characters, not model tokens!).","Chunk overlap (%) - sets the percentage of a chunk size that will be shared between adjacent chunks. This allows for a smoother transition between the chunks, but may also introduce some redundancy.","Retrieve chunks - sets the maximum amount of the most relevant file chunks to be retrieved. They will be inserted in their original order."]},{"l":"Data Bank files","p":["These settings control how the Data Bank documents are handled.","The following rules apply:","When file vectorization is disabled, the Data Bank is not used.","Otherwise, all available documents from the current scope (see above) are considered for the query. Only the most relevant chunks across all the files are retrieved. Multiple chunks of the same file are inserted in their original order.","The inserted chunks will reserve a part of the context before fitting the chat messages.","Size threshold (KB) - sets a chunking splitting threshold. Only the files larger than the specified size will be split.","Chunk size (chars) - sets the target size of an individual chunk (in textual characters, not model tokens!).","Chunk overlap (%) - sets the percentage of a chunk size that will be shared between adjacent chunks. This allows for a smoother transition between the chunks, but may also introduce some redundancy.","Retrieve chunks - sets the maximum amount of the file chunks to be retrieved. This allowance is shared between all files.","Injection Template - defines how the retrieved information will be inserted into the prompt. You can use a special {{text}} macro to specify the position of the retrieved text, as well as any other macros.","Injection Position - sets where to insert the prompt injection. The same rules as for Author's Note and World Info apply."]},{"l":"Shared settings","p":["Query messages - how many of the latest chat messages will be used for querying document chunks.","Score threshold - adjust to allow culling the retrieval of chunks based on their relevance score (0 - no match at all, 1 - perfect match). Higher values allow for more accurate retrieval and prevent completely random information from entering the context. Sane values are in a range between 0.2 (more loose) and 0.5 (more focused).","Chunk boundary - a custom string that will be prioritized when splitting the files into chunks. If not specified, the default is to split by (in order) double line breaks, single line breaks, and spaces between words.","Only chunk on custom boundary - if enabled, the chunking will only occur on the specified chunk boundary. Otherwise, the chunking will also occur on the default boundaries.","Translate files into English before processing - if enabled, will use the translation API configured in the Chat Translation extension to translate the files into English before processing them. This is useful when using embedding models that only support English text.","Include in World Info Scanning - check if you want the injected content to activate lore book entries.","Vectorize All - forcibly ingests the embeddings for all unprocessed files.","Purge Vectors - clears the file embeddings, allowing to recalculate their vectors.","For \"Chat vectorization\" settings see Chat Vectorization."]},{"l":"Conclusion","p":["Congratulations! Your chatting experience is now enhanced with the power of RAG. Its capabilities are only limited by your imagination. As always, don't be afraid to experiment!"]}],[{"l":"Welcome Page Assistants","p":["SillyTavern features a Welcome Screen that can greet you with a designated \"Assistant\" character. This screen appears when you launch SillyTavern without an active chat or after you close your last chat session.","If you don't see a Welcome Screen on app startup, make sure the \"Auto-Load Last Chat\" option is disabled in the \"Chat/Message Handling\" section of the User Settings panel. If this option is enabled, SillyTavern will automatically load your last chat instead of showing the Welcome Screen."]},{"l":"The Welcome Screen","p":["When no chat is active, the Welcome Screen provides several useful elements:","SillyTavern Version: Displays the application's logo and current version.","Quick Links: Easy access to:","Docs: Opens the official SillyTavern documentation (you're already here!).","GitHub: Takes you to the SillyTavern GitHub repository ( https://github.com/SillyTavern/SillyTavern).","Discord: Provides a link to the official SillyTavern Discord server ( https://discord.gg/sillytavern).","Temporary Chat Button: Allows you to quickly start a new, temporary chat session with the default neutral assistant, which won't be saved to your chat history unless you explicitly save it.","Recent Chats Section: Lists your recent conversations for quick access. You can:","Show or hide this section.","Expand the list if more than 3 chats are available (up to 15 recent chats)."]},{"l":"Temporary Chat","p":["Due to a technical limitation, the Temporary Chat feature will not use your customized Welcome Page Assistant. It will always start an empty chat without any additional prompts or character information.","The Temporary Chat button allows you to quickly start a new chat session without saving it to your chat history. This is useful for testing or casual conversations without cluttering your saved chats. This chat will be deleted as soon as you close it or switch to another chat.","Save button will allow you to export the temporary chat as a JSONL file, which you can then import later.","Load button will allow you to restore a previously saved temporary chat file."]},{"l":"What is a Welcome Page Assistant?","p":["A Welcome Page Assistant is a character you choose to be featured on the Welcome Screen. This allows for a personalized greeting and a quick way to start a chat with a familiar character right from the start."]},{"l":"Setting and Unsetting an Assistant","p":["You can choose any of your characters to act as your Welcome Page Assistant.","To set an assistant:","Navigate to the Character Management panel (usually found in the right-hand sidebar via the icon).","Find the character you wish to set as your assistant in the list.","Click on \"More...\" and select \"Set / Unset as Welcome Page Assistant\" from the dropdown menu.","A small icon () will appear next to the character's name, indicating they are now your active Welcome Page Assistant.","To unset an assistant:","Go to the Character Management panel.","Locate your current Welcome Page Assistant (they will have the icon).","Click on \"More...\" and select \"Set / Unset as Welcome Page Assistant\" again.","The character will no longer be your assistant, and the icon will disappear.","SillyTavern will revert to using the Default Assistant (see below)."]},{"l":"Interacting with the Assistant","p":["Once the Welcome Screen is displayed with your chosen assistant, simply type your message into the chat input bar at the bottom of the screen and press Enter or click the send button. This will start a new chat session with your Welcome Page Assistant.","To open a previous chat with the assistant, use the Recent Chats section or find the chat in the Manage chat files dialog (accessible via the Options menu)."]},{"l":"Default Assistant","p":["SillyTavern will automatically create a default character named \"Assistant\" when you interact with the Welcome Screen for the first time. This character serves as a fallback option if you haven't set a specific character as your Welcome Page Assistant.","The default assistant doesn't have any specific prompts attached to it, and you're free to customize it as you like (e.g. renaming, adding a picture, or setting a personality).","If you haven't explicitly set a character as your Welcome Page Assistant, this default assistant will be used.","If you unset your chosen assistant, the system will revert to this default assistant.","If a character you had set as an assistant is deleted, the system will also revert to the default assistant.","Note: You cannot \"unset\" the default system assistant in the same way you unset a character you've chosen. To change from the default assistant, you must set one of your other characters as the assistant."]}],[{"l":"Extensions","p":["SillyTavern comes with many extensions that can be enabled or disabled in the Extensions panel. Extensions can add new features, change the behaviour of existing features, or provide additional content for your AI to use. More extensions can be installed from the \"Download Extensions & Assets\" menu in the Extensions panel."]},{"l":"Extensions panel","p":["To open or close the Extensions panel, choose Extensions in the top bar.","Manage extensions: Activate, deactivate, and update extensions","Download Extensions & Assets: Install more extensions, characters, sounds, and backgrounds from the SillyTavern repository","Notify on extension updates: Check to be notified when there are updates available for installed extensions","Install extension: Import a third-party extension from a Git repository URL"]},{"l":"Built-in extensions","p":["Auto-summary of the chat history","Chat Translation","Chat Vectorization","Converts text into tokens and counts the number of tokens","Expression Images","Finds relevant messages from chat history and adds them into the context","Generates text from images so your AI can \"see\" and respond to visual content in your conversations","Image Captioning","Image Generation","Images (aka 'sprites') of your AI character, shown next to or behind the chat window","Quick Reply","Reply to chat messages with a single click, run commands and STscripts, and more","Summarize","Text To Speech","These extensions are built into SillyTavern and do not need to be installed. They can be enabled or disabled in the Extensions panel.","Token Counter","Translate chat messages to a different language","Use local or cloud-based Stable Diffusion, FLUX or DALL-E APIs to generate images","Voice narration for your chat messages via ElevenLabs, Silero, your system TTS, AllTalk, XTTS, and more"]},{"l":"Installable extensions","p":["A set of 7 classic D&D dice for all your dice rolling needs.","AccuWeather","Adds \"idle prompting\" after the user has been idle for some time to organically continue the conversation.","Adds a button to quickly insert a /sendas command template for the selected group member.","Adds a button to quickly insert emojis into a chat message.","Adds a dropdown menu for selecting user personas from the chat bar.","Adds a place to store your notes. Supports rich text formatting.","Adds a silence audio player to the extensions menu. Can help if the browser tab is being killed in a background.","Adds a timeline navigation to the chat history.","Adds a top bar to the chat window with shortcuts to quick actions.","Adds ability to randomize API settings sliders with every generation.","Adds an ability to cluster characters by similarity groups to easily find duplicates.","Adds an option to inspect and edit output prompts before sending them to the server.","Adds immersive background music and ambient sounds to your chats.","Adds Mermaid diagrams & flowcharts rendering to SillyTavern chats.","Adds Realtime Voice Cloning capabilities to the Text-to-Speech module.","Adds support for live2d models. Customizable expressions, animations and interactions.","Adds support for VRM models. Customizable expressions, animations and interactions.","Adds web search results to LLM prompts.","Allows running JavaScript and STscript code from code blocks in chat.","Allows setting alternate greetings that are specific to group chats.","Allows to receive push notifications for incoming chat messages.","Animate the text of character messages with variable speed and play sound along the animation.","Blip","Chat Top Bar","Chess","Code Runner","Convert your speech to text using browser or extras.","D&D Dice","Duplicate Finder","Dynamic Audio","Easy way to view and modify variables.","Emoji Picker","EmulatorJS","Enhances the current visual novel experience with more features (Focus Mode, Letterbox Mode, and more)!","Gets the latest news from RSS feeds as a slash command or a function tool.","Group Greetings","Group SendAs","HypeBot","Idle","Image Metadata Viewer","LaTeX","Live2d","Mermaid","Notebook","Objective","Parameter Randomizer","Play retro console games directly in SillyTavern chats.","Play the game of chess with the LLM.","Prome Visual Novel Extension","Prompt Inspector","Provides an interface for extensions to use language models directly in the browser.","Provides the screen image for multimodal models when you send a message.","Provides weather information using the AccuWeather API as a slash command or a function tool.","Push Notifications","Quick Persona","Render LaTeX and AsciiMath formulas in chat messages.","RSS","RVC","Screen Share","Set an Objective for the AI to aim for during the chat.","Show personalized suggestions based on your recent chats using the NovelAI's HypeBot engine. Requires an active NovelAI subscription.","Silence Player","Speech Recognition","The Extras project was discontinued in April 2024. You do not need to install Extras to use extensions.","Timelines","Variable Viewer","View metadata of enlarged images attached to a chat.","VRM","Web Search","WebLLM","You can browse a list of all available extensions directly from the app by going to the Extensions=> Download Extensions & Assets menu and clicking the Load Asset List button. To install an extension, click the Download button. To read more about an extension, click the Link button next to its name to open its GitHub page.","You must have git installed to download extensions. Follow the instructions on the Git installation page if you don't have it installed."]},{"l":"Third-party extensions","p":["Using third-party extensions can have unintended side effects and may pose security risks. Always make sure you trust the source before importing an extension via Install extension. We are not responsible for any damage caused by third-party extensions.","To install a third-party extension, go to the Extensions=> Install Extension menu and paste the URL of the extension repository. Optionally, specify the branch and (in multi-user scenarios) the installation target: all users or just the current user. The extension will be downloaded and loaded automatically."]}],[{"l":"Blip","p":["This guide will walk you through setting up and customizing blip extension for your SillyTavern experience. This extension animate the text of messages with variable speed and play sound along the animation. You can use audio file or generate the sound."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest version of SillyTavern.","Install the \"Blip\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Blip global settings","p":["Blip user message:","Enable checkbox to play animation on user message.","Set a profile for the user or a default profile if you want blip animation for user.","Blip only for certain text:","Enable checkbox to only blip for text inside quotes.","Enable checkbox to ignore everything inside asterisks.","Automatic scroll down:","Enable checkbox to make the chat go down to follow the text animation, disable it if you wanna scroll freely during animation.","Audio volume","Mute the audio if just the animation of the text is desired.","You can adjust the global volume of blip audio."]},{"l":"Character animation/voice profile","p":["Any profile can be deleted using the remove button.","Audio parameters:","Blip origin: file:","Blip origin: Generated sound:","Choose a file in the list.","Enable the checkbox to force to wait entire file is played before playing again if needed.","If it does not have a profile yet the current parameters will become his profile settings.","If min/max are different a random sound in this range is played each time.","If only the current chat characters are shown in the list, click the checkbox to show all your characters.","including the user and an optional default profile that will be used when character have no profile.","Or put file directly into: \\SillyTavern\\data\\user-handle\\assets\\blip.","Select a character, if he have a profile it will be loaded.","Select the character to assign/update profile:","Set a volume multiplier that will only affect this voice profile if needed.","Set audio speed: the delay between each blip sound, independant of text speed.","Set comma/phrase delay superior to 0 to add a pause when special character are printed, can add more liveliness to animation. Audio is paused too in this case.","Set Min/max speed multiplier different to 1.0 for randomness of speed animation.","Set the text speed: the delay in milliseconds between each letter printed.","Text animation settings:","Thank you for following this guide! Your SillyTavern experience is now enriched with text animation and blip voices.","Use refresh button if your character does not appear in the list.","Use the min/max frequency slider to customize the blip sound played.","You can get official ST blip assets from the assets extension menu.","You can save a profile for each character:"]}],[{"l":"Character Expressions"},{"l":"What is it?","p":["Expression images are images (aka 'sprites') of your AI character which are shown next to (or behind) the chat window.","Expression images can automatically change based on a classification, adjusting to the sentiment expressed in the AI's most recent chat response."]},{"l":"Adding Character Expression Images","p":["Open the Extensions Panel and expand the 'Character Expressions' section. If you have the character chat open, you will see a grid of image placeholders. Expression Drawer","Click the 'Upload image' button at the top left of each image in the grid, and select the image you want to apply to that emotion. This will save the image with the correct filename inside the /data/user-handle/characters/(character_name_here)/ folder.","Repeat this for all expressions you want to assign an image to."]},{"l":"Importing an Expression images ZIP file","p":["Using the ' Upload sprite pack (ZIP)' button, you can import a zip file that contains a collection of expression images, and those images will automatically be added to the correct folder for your currently selected character. The ZIP file must contain all images in a flat structure (no subfolders) and correctly named files. Importing a zip will not automatically rename any images to make them match the emotions."]},{"l":"Change Expressions Manually","p":["Click on any of the uploaded expression images (sprites) to display them near the chat interface (with default UI mode) or at the center of the screen (in Visual Novel mode).","Use the /expression-set (name) slash command or matching Quick Reply to set the sprite without opening the extensions menu."]},{"l":"Change Expressions Automatically","p":["To automatically set expressions when the character replies, you have multiple options. Expressions change per message or at regular intervals when message streaming is enabled."]},{"l":"How does the classify module work?","p":["The classify module uses a small 'sentiment parsing' model that runs alongside the SillyTavern server. This model takes the new output from the AI and detects what kind of sentiment, or emotion, the text is expressing. While multiple sentiments may be expressed in a single message, the model only picks the most likely one and returns that to the SillyTavern. The frontend extension then displays the image that is associated with that sentiment."]},{"l":"Setup Instructions (Local)","p":["Open the extensions panel and expand the \"Character Expressions\" extension menu.","Select \"Local\" in the classification source dropdown.","This will start a one-time download of the classification model from HuggingFace Hub (about ~ 100 Mb).","Generate any message to verify that the classification works and the sprite appears. You may also check the server console for debug logs.","Local classification defaults to 28 possible image labels: Cohee/distilbert-base-uncased-go-emotions-onnx","To use the 6-option classification model, change the value of extensions.models.classification variable in the config.yaml file to: Cohee/bert-base-uncased-emotion-onnx"]},{"l":"Setup Instructions (with LLM)","p":["Connect to any of the supported and properly configured APIs via API Connections.","Import the expression images the same way as mentioned above.","Select \"Main API\" in the classification source dropdown.","Optionally, configure the classification instruction prompt.","Generate any message to verify that the classification works and the sprite appears. You may also check the server console for debug logs."]},{"l":"Prompt Building Strategies","p":["Main LLM source allows to choose how the classification prompt will be built:","Limited Context: Only the last message and a system instruction prompt are sent.","Full Context: The entire chat history, including the character card are sent."]},{"l":"Setup Instructions (WebLLM)","p":["Install the official WebLLM extension.","Import the expression images the same way as mentioned above.","Select \"WebLLM\" in the classification source dropdown.","Optionally, configure the classification instruction prompt.","Generate any message to verify that the classification works and the sprite appears. You may also check the server console for debug logs."]},{"l":"Setup Instructions (with Extras)","p":["Extras is deprecated and may be removed in future updates.","Have Extras installed and running with the classify module enabled: python server.py --enable-modules=classify","Import the expression images the same way as mentioned above.","Select \"Extras\" in the classification source dropdown.","The appropriate expression image will display automatically whenever the AI sends you a response.","Extras API uses a classification model with 6 options by default: nateraw/bert-base-uncased-emotion","There is also a model with 28 options: joeddav/distilbert-base-uncased-go-emotions-student","To use this model you need to change your Extras command line to include the following argument (with a space before and after): --classification-model=joeddav/distilbert-base-uncased-go-emotions-student"]},{"l":"Custom Expressions","p":["How to get more expression options than provided by default? You can set up Custom Expressions in the extension settings. You can assign any name to Custom Expressions. They will appear in the expression image list and can be assigned images like other expressions. They will have an indicator showing that those are custom.","Both Local and Extras only support a limited list of expressions.","If you want Custom Expressions to be displayed, you either need to train a classification model with supported labels (outside the scope of this guide), or you can use LLM or WebLLM as classification source, which both will automatically use all existing expressions - both the default and any custom ones."]},{"l":"What image formats are supported for Expressions?","p":["Any image format is allowed, including webp and animated gifs.","The most common format is a PNG file with a transparent background."]},{"l":"Using Default Expressions","p":["If you don't have expression images for all expressions of a character, or no images at all, there are multiple options on what to display by default. All of those can be selected via the dropdown under 'Default / Fallback Expression'.","Choose a Fallback Expression: If an expression gets chosen where you don't have an image for, the fallback expression gets shown instead. Simply select one of the available expressions from the dropdown.","[No Fallback]: When no image exists, show nothing.","[Default emojis]: You can use the built-in default expressions which are included with in SillyTavern. These are simple emoji-style images."]},{"l":"Using Multiple Images per Expression","p":["It is possible to add multiple images per expression to allow for more variety in displayed expressions. To enable this, simply toggle Allow multiple sprites per expression. You can now upload more than one image, and any additional images will be displayed with a small marker.","Individual images can be manually chosen by selecting them with a click, or via /expression-set type=sprite, which will list available sprite images, instead of expressions.","Whenever an expression with multiple images gets automatically chosen, one of the existing images will be selected at random. If you want to force a new image of that expression to be chosen when the same expression gets used multiple times, you can enable Re-roll if same sprite is used again."]},{"l":"Naming Convention for Multiple Images per Expression","p":["In case of multiple images per expressions, files need to be named a specic way. The files need to start with the name of the expressions, and then followed by a suffix, either separated by a dot or a dash. Examples: joy.png, joy-1.png, joy.expressive.png File names must follow this format for both direct uploads and ZIP imports."]},{"l":"Sprite Folder Override","p":["Display names (not character card filenames) dictate which image set is used","If you have more than one character with the same display name, they will both use the same set of expression images.","If you want a different image set to be used for each version of the same-named character, you can use the sprites folder override. Folder overrides can also be used to define different sprite sets (outfits, etc.) of the same character."]},{"l":"How to set an override","p":["Create a folder in the /data/user-handle/characters with any name and put images there, e.g. /data/user-handle/characters/Boris.","Open the chat with the character whose sprites you'd like to override.","Enter the name of the override folder into the \"Sprite Folder Override\" input and click \"Submit\".","The Sprites list will reload and the \"Sprite set\" indicator should show the override folder.","Alternatively, you can use the /costume slash command to achieve the same result: /costume Boris.","By prepending a backslash to the override folder name, it will resolve to a subfolder in the current character sprites folder, e.g. /costume \\tracksuit for the character named Boris will resolve to the /data/user-handle/characters/Boris/tracksuit folder."]}],[{"l":"Chat Translation"},{"l":"Overview","p":["The Chat Translation Extension enables real-time translation of chat messages between different languages using various translation providers. It supports both manual and automatic translation modes.","Character message translated from English to Chinese using 'Translate Message/翻譯訊息' message action button","Translate Chat, Translate Input","翻译聊天, 翻译输入","翻譯聊天內容, 翻譯輸入內容","채팅 번역하기, 입력 번역하기","Перевести чат, Перевести моё сообщение"]},{"l":"Usage","p":["All the ways to translate chat messages:","Translate Chat button in the Extensions menu","Translates the entire chat history at once","Translate Input button in the Extensions menu","Translates just the current input text","Useful before sending a message","Translate Message icon in the Message Actions toolbar of any message","Click to translate just that message","Click again to revert to original text","Auto-mode configuration in the Chat Translation drawer of the Extensions panel","Automatically translates user inputs, AI responses, or both","/translate slash command","Use /translate [target=language_code] text to translate text"]},{"l":"Configuration","p":["Configuration options are available in the Chat Translation drawer of the Extensions panel."]},{"l":"Provider","p":["Choose your preferred translation service","Click the API Key icon, if it appears, to enter an API key","Click the Custom URL icon, if it appears, to enter a custom API URL"]},{"l":"Target Language","p":["Select the language you want to write your messages in, or read AI responses in."]},{"l":"Auto-mode","p":["Configure automatic translation behavior.","None: No automatic translation","Translate responses: Automatically translates AI responses into the target language","Translate inputs: Automatically translates user inputs into English","Translate both: Translates both user inputs and AI responses"]},{"l":"Clear Translations","p":["The Clear Translations button removes all translations from messages in the current chat. The original messages are preserved."]},{"l":"Configuration Example: Chinese to English Chatting","p":["To set up a workflow where a Chinese-speaking user can chat in Chinese with an AI that operates in English:","Set Auto-mode to \"Translate both\"","Set Target Language to \"Chinese (Simplified)\" or \"Chinese (Traditional)\"","Choose a translation provider with good language auto-detection (e.g., Google or DeepL)","This setup will:","Translate user's Chinese input to English for the AI","Translate AI's English responses back to Chinese for the user","This setup relies on automatic language detection for input. For more precise control, future updates may include explicit source language selection."]},{"l":"Translation providers","p":["Alternative front-end for Google Translate, open source (AGPL-3.0), privacy-focused","Bing Translator","Cloud-based Local, custom URL Requires API key","DeepL","DeepLX","Features","Good for Russian and Eastern European languages","Google Translate","High-quality translations, especially for European languages","Libre Translate","Lingva Translate","Location","Microsoft's translation service, integrates with Azure services","OneRing Translator","Provider","Self-hosted (AGPL-3.0) alternative to proprietary translation services, with cloud-hosted Pro tier","Self-hosted DeepL proxy, open source (MIT), free but proxying DeepL Pro requires DeepL API key","Self-hosted front-end to Google Translate and other providers, privacy-focused, open source (AGPL-3.0)","Widely used, supports many languages, good accuracy","Yandex Translate"]},{"l":"DeepL-specific configuration","p":["Formality levels available for German, French, Italian, Spanish, Dutch, Japanese, and Russian","Configure via deepl.formality in config.yaml"]},{"l":"Slash Commands","p":["Use /translate command for quick translations. Syntax: /translate [target=language_code] text. If target language is not provided, the value from the extension settings will be used."]},{"l":"Basic usage","p":["Translate text to the current target language and show it in a popup:","Popup in Chinese (Simplified), '欢迎来到酒馆/Welcome to the Tavern'","Translate text to Spanish and add it to the chat:","User message in Spanish, 'Hola Mundo/Hello world'"]},{"l":"Testing, pipeline translation, localization","p":["Prompt the user for a message and a language, translate the message into that language, then re-translate it into the configured target language and show both translations in a popup. This example uses the /input and /buttons commands to gather user input:","This is useful for checking the quality of a translation into a language that you don't speak, before writing it somewhere important.","Popup, 'Welcome to the Tavern/欢迎来到酒馆/welcome to the pub', en, zh-CN, en Popup, 'My hovercraft is full of eels/我的氣墊船裡裝滿了鰻魚/My hovercraft is filled with eels', en, zh-TW, en","The UI controls are shown in the current locale, independent of the configured target language.","/input","/buttons","Input dialog, '发送测试消息/Send Test Message'","Buttons dialog, '语言/Language'","Popup, '我的氣墊船裡裝滿了鰻魚/My hovercraft is full of eels', zh-TW - en - zh-TW","Input language detection is relatively effective in the following examples:","Popup, '(My hovercraft is full of eels)/A légpárnás hajóm tele van angolnával/我的氣墊船裡裝滿了鰻魚', zh-TW - hu - zh-TW Popup, '我的氣墊船裡裝滿了鰻魚/Mi aerodeslizador está lleno de anguilas/My hovercraft is full of eels', zh-TW - es - en Popup, 'Il mio hovercraft è pieno di anguille/我的气垫船里装满了鳗鱼/My hovercraft is filled with eels', it - zh-CN - en"]},{"l":"Technical Notes","p":["UTF-8 encoding, special characters, and emojis are supported","Handles large messages by splitting into chunks when needed","Preserves formatting and embedded images in messages","Caches translations to avoid redundant API calls"]},{"l":"AI input language","p":["internal_language controls the language into which user messages are auto-translated before being sent to the AI. It is hardcoded to 'en' in the default settings and cannot be changed through the UI. Thus, the translation target language for messages to the AI is always English. Previous testing showed that AI performance was better when receiving English messages, but this may change as more LLMs are being trained on more varied language data. I suppose one could change internal_language in settings.json and find out."]},{"l":"Chinese variant handling","p":["The extension supports both Simplified and Traditional Chinese, but not all translation providers do. The UI presents these as 'Chinese (Simplified)' and 'Chinese (Traditional)' respectively, with language codes 'zh-CN' and 'zh-TW'. They are mapped to the following language codes for translation providers:","Libre Translate: 'zh-CN' to 'zh' and 'zh-TW' to 'zt'.","DeepL and DeepLX: both variants to 'ZH'.","Bing: 'zh-CN' to 'zh-Hans', 'zh-TW' as-is.","Other providers use 'zh-CN' and 'zh-TW' as provided."]},{"l":"Text length limits","p":["Some providers have character limits per request:","Yandex: 5000 characters","DeepLX: 1500 characters","Bing: 1000 characters","Google: 5000 characters","Longer texts are automatically split into chunks for translation."]}],[{"l":"Chat Vectorization","p":["The use of this extension does not guarantee a better chatting experience or improved memory of any sort. Only use if you understand all the implications of vector database utilization.","Chat vectorization searches for messages in your current chat history that seem relevant to your most recent messages. It temporarily shuffles the most relevant messages to the beginning or end of the chat history. This happens when the model's reply to your last message is generated.","The messages at the start and end of the chat history tend to have the greatest impact on the model's reply. Therefore, shuffling relevant messages to these locations can help the model focus on relevant information in its reply.","In particular, chat vectorization can find relevant messages that are too far back in the message history to fit into the request context. Shuffling these messages into context provides the model with information that it would not have otherwise.","Chat vectorization is a kind of retrieval-augmented generation (RAG). Retrieval-augmented generation increases the quality of responses generated by a model, by providing additional relevant information in the prompt.","Retrieval: the most recent messages are used to retrieve relevant past messages","Augmented: the model's context is augmented by inserting past messages in a useful way","Generation: the model is instructed to use the past messages when generating the response","A vector is a set of numbers that could represent the themes, content, style, or other characteristics of a piece of text.","Vectorization is calculating the vector that represents a piece of text. This is done by a vectorizing model. Just as text generation models make text from text, vectorizing models make vectors from text.","Vector search finds relevant results by comparing vectors rather than, say, keywords. If we calculate the vector for a search query, we can compare it to the stored vectors for a collection of pieces of text. This finds the texts in our collection that are most similar to the text in the search query. In the case of chat vectorization, the\"search query\" is the most recent 2 messages, and the \"texts in our collection\" are all the other messages in the chat."]},{"l":"Setting up","p":["Like any dynamic prompt source (World Info, Summarization, etc.), Chat Vectorization restructures the prompt prefix between the LLM calls, which can lead to frequent cache misses. When used with caching, vectorization is often counter-productive, as the modified prompts rarely hit the cache – effectively making caching useless. You have to choose one or the other, but not both.","To enable Chat vectorization, select \"Extensions\" > \"Vector Storage\" > \"Enabled for chat messages\".","Configure a vectorization source and vectorization model. Chat vectorization uses the same vector source as Data Bank, so you may have set this up already. The settings for the Vectorization Source and Vectorization Model are documented in Data Bank.","Chat vectorization uses the same vector storage as Data Bank, but this does not need to be set up or configured. There is also information about Vector Storage in Data Bank.","Chat vectorization does not use Data Bank to store the chat messages. The messages are stored in the chat."]},{"l":"Preparing chat messages for search (vector storage)","p":["So that chat messages can be searched, a vector is calculated for each message and stored.","Vectorizing occurs in the background, whenever you send or receive a message.","Each message is stored individually, so that it can be found and shuffled individually during generation.","Large messages are split into \"chunks\" so that the model can be given the most relevant part of a long message. The chunk size is 400 characters. You can change this with \"Chunk size (chars)\".","Messages are divided into chunks by finding a chunk boundary such as a paragraph break, line break, or space between words. This is so that the all the chunks make sense, as far as possible. If your chat messages have some other way to mark natural splitting points, such as ----, you can add this to \"Chunk boundary\". The setting for \"Chunk boundary\" is shared with Data Bank."]},{"l":"Vector storage controls","p":["To calculate vectors for all messages in the current chat, without waiting for them to be processed in the background, choose \"Vectorize All\" from the settings.","To see how many messages in the current chat have been vectorized, choose \"View Stats\". This displays the total number of vectors stored. It also indicates the specific chat messages that have been vectorized, by marking them with a green ball.","To remove all the vectors for messages in the current chat, choose \"Purge Vectors\".","The controls for \"Vectorize All\" and \"Purge Vectors\" within Chat vectorization only affect the stored vectors for the current chat. However, there are identical buttons in File vectorization that affect the vectors for files in Data Bank. Ensure that you are purging the vectors that you intend to purge."]},{"l":"Finding relevant messages to shuffle (vector retrieval)","p":["To find the most relevant messages in the chat history, the most recent messages are converted (vectorized) into a query vector. By default, the 2 most recent messages are used. To change this, change the value of \"Query messages\". This value is also used when finding relevant content from Data Bank.","Past messages must have a relevance score of at least 25% to be included. You can change this with \"Score threshold\". The setting for score threshold is shared with Data Bank.","The 3 most relevant messages from chat history are shuffled. You can change this with \"Insert#\".","To avoid disturbing the most recent events in the chat, the 5 most recent messages are not shuffled. To change this, change the value of \"Retain#\"."]},{"l":"Shuffling messages (augmented generation)","p":["The messages are shuffled to one of 3 places:","The top of the chat, after the Main Prompt / Story String (the default)","The top of the chat and before the Main Prompt / Story String","The end of the chat, before the last 2 messages (\"In-chat @ Depth 2\"). Since you just sent a message, this position is usually just before the previous reply from the model.","You can change this with \"Injection Position\" and \"Depth\".","The messages are included in order of relevance, with more relevant messages shown after less relevant messages.","The name of the person or character who sent each message is included.","The messages are shown to the model as \"past events\". This assists the model to understand that the messages contain information from a different point in the chat history than the point at which they are inserted. You can change this with \"Injection Template\".","You can see the final prompt to the model using the Prompt Itemization popup, the terminal logs, or the browser console logs. The browser console logs are useful for understanding what all the steps in Chat vectorization are doing."]},{"l":"Vector summarization","p":["The Vector summarization feature is experimental.","Vector summarization does not create summaries of your chat. It does not turn the retrieved messages into summaries. It does not make your chat history shorter. It is not \"like Summarize but better\".","Vector summarization is intended to make vector search of chat messages more effective. It does this by introducing a summarizing step prior to vectorizing. The summarizing step extracts the most important parts of the message, so that the resulting vector is a better indicator of what the message relates to.","Vector summarization may make vector search less effective.","To summarize the messages in the chat history, and generate a vector for each summarized message, choose \"Summarize chat messages for vector generation\".","The summarized message does not replace the original message in chat. If a vector search matches the vector of a summarized message, the original message is retrieved from chat history and shuffled into context. The summarized versions of the messages are retained in Vector Storage, which may be of interest for debugging.","To summarize the content of the messages used to search the chat history (the last 2 messages by default), choose \"Summarize chat messages when sending\".","Each time a message is summarized for vectorising, a separate request is made to the summarizing model. You can choose which summarizing source is used with \"Summarize with\". Choosing \"Main API\" will generate the summaries using the same model and connection settings that you use for generating chat or text completions.","The request consists of the raw message content and an instruction about how the model should produce the summary. You can change the instruction with \"Summary Prompt\"."]}],[{"l":"Dynamic Audio","p":["This guide will walk you through setting up and customizing dynamic audio assets for your SillyTavern experience."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest version of SillyTavern.","Install the \"Dynamic Audio\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Dynamic Audio Setup (Browser)","p":["Connect to the Assets Repository:","Launch SillyTavern and navigate to Extensions> Assets.","Click on the \"Connect\" button to establish a connection to the official assets repository.","Download the desired audio assets, such as background music (BGM) or ambient sounds, that correspond to the backgrounds you intend to use.","Enable Dynamic Audio Extension:","In SillyTavern, go to Extensions> Dynamic Audio.","Enable the extension, unmute and adjust the volume of BGM and ambient sounds to your preference.","When bgm end another one will play randomly, click on loop button to keep current bgm playing","Click on roll button to pick another bgm randomly","Expression based BGM:","Enable expression BGM switch if you want bgm to follow character expression (require bgm in character folder see below).","Adjust the cooldown timer (in seconds) between BGM updates. Increase it if you find the BGM changes too frequently in group chats or when using character-specific BGM with emotion detection."]},{"l":"Importing Music for Characters","p":["To set up custom music for your characters' emotions, follow these steps:","Navigate to Character Folder:","Go to the characters folder, e.g., \\SillyTavern\\data\\user-handle\\characters\\Seraphina.","Create BGM Folder:","Inside the character folder, create a subfolder named bgm.","Import Emotion Music:","Within the bgm folder, import the music files for each emotion. Supported audio extensions include .mp3, .ogg, and .wav.","Naming convention: [emotion]_[number].mp3, e.g., anger_0.mp3, joy_0.mp3.","Multiple Tracks for Emotions:","You can import multiple tracks for the same emotion by incrementing the number, e.g., neutral_1.mp3, neutral_2.mp3.","Default Music Selection:","When no emotion is detected, a random neutral track will play as the default. Emotions are detected similarly to updating sprites; refer to the expression images documentation for details."]},{"l":"Changing Default BGM Music","p":["If a character doesn't have custom BGM in their folder, a default track will play. Here's how you can change it:","Navigate to BGM Folder:","Go to the following folder: \\SillyTavern\\data\\user-handle\\assets\\bgm.","Replace/Add Music:","Replace or add music files (.mp3, .ogg, .wav) to this folder.","These are the official audio assets downloaded using the assets extension.","One of these tracks will play randomly when no character-specific BGM is found (solo or group chat)."]},{"l":"Changing Ambient Sounds","p":["Ambient sounds add depth to your scenes. Here's how you can customize them:","Navigate to Ambient Folder:","Go to the following folder: \\SillyTavern\\data\\user-handle\\assets\\ambient.","File Naming Convention:","Ambient audio filenames correspond to background image filenames, replacing spaces with dashes.","Example: bedroom-clean.mp3 corresponds to the \"bedroom clean.jpg\" background.","If the lock button is unlock the audio file corresponding to the background will play. Activating lock will keep current ambient playing.","Custom Ambients:","You can add your own ambient sounds for custom or existing backgrounds by following the same naming pattern.","Thank you for following this guide! Your SillyTavern experience is now enriched with dynamic audio."]}],[{"l":"EmulatorJS","p":["This extension allows you to play retro console games right from the SillyTavern chat."]},{"l":"Installation","p":["Prerequisites:","Latest release version of SillyTavern.","ROM files downloaded from the net. You can find them anywhere.","How to install:","Install using SillyTavern's extensions downloader.","Or use this link: https://github.com/SillyTavern/SillyTavern-EmulatorJS"]},{"l":"Usage","p":["Open the \"EmulatorJS\" extension menu.","Click \"Add ROM file\". ROMs are saved to your browser storage and not stored on a server.","Select the game file to add. Input the name and core (if it wasn't auto-detected). If the core requires a BIOS file, add it too.","Click the \"Play\" button in the list or launch via the wand menu.","You can customize controls and other settings in the emulator frame after launching the game.","Use save/load state functions if you need to take a break.","Check the EmulatorJS docs to see the list of available cores and their requirements: Cores."]},{"l":"Comments mode","p":["With the power of multimodal models, your AI bots can see your gameplay and provide witty in-character comments."]},{"l":"Requirements","p":["A browser that supports ImageCapture. Tested on desktop Chrome. Firefox requires to enable it with config. Safari won't work.","Chat Completion API with image inlining mode is recommended. Check the API documentation to see if the chosen model supports multimodal prompts.","If image inlining is disabled, make sure that the Image Captioning extension is enabled, then select the \"Multimodal\" captioning source."]},{"l":"How to enable comments","p":["Make sure you set the interval of providing comments in the EmulatorJS extension settings. This setting defines how often the character is queried for comments using an image of your current gameplay. A value of 0 indicates that no comments are provided.","Select a character chat and launch the game. For the best performance, make sure that the ROM file is properly named so that AI can have more background context.","Start playing as you normally would. The vision model will be queried periodically to write a comment based on the latest screenshot it \"sees\"."]},{"l":"Settings","p":["Caption template - a prompt used to describe the in-game screenshot.{{game}} and {{core}} additional macros are supported.","Comment template - a prompt used to write a comment based on the generated caption. {{game}}, {{core}}, {{caption}} additional macros are supported. For image inlining mode, {{caption}} is replaced with see included image.","Force captions - will force the use of multimodal captioning even if image inlining is supported and enabled."]},{"l":"Why I'm not seeing any comments?","p":["Comments are temporarily paused (interval step skipped) if:","Emulator is paused (with a pause button, not in-game).","The browser window is out of focus.","The user input area is not empty. This is to let you type your reply in peace.","Another reply generation is currently in progress.","TTS voice is being read aloud. Comment is held off (30 seconds maximum) until it finishes, but not skipped.","A character card or group is currently open. Comment mode is disabled when starting the game from a welcome screen.","Other common issues:","Make sure you've set a commenting interval before launching the game.","Make sure you have set a multimodal API key and there are no errors in the ST server console.","Still doesn't work? Send us your browser debug console logs (press F12)."]},{"l":"Credits","p":["EmulatorJS engine (GPLv3): https://github.com/EmulatorJS/EmulatorJS"]}],[{"l":"Image Captioning","p":["Image Captioning allows SillyTavern to automatically generate text descriptions for images used in chats.","Use Image Captioning when you want your AI character to \"see\" and respond to visual content in your conversations.","Create captions for images you upload or paste into messages","Add context to existing images in the chat history","Use various sources for generation, including local models, cloud APIs, and crowdsourced networks","There are options that require no setup, no money, and no GPU. There are also options that require some or all of those things. Choose the one that fits your needs and resources.","The image captioning extension is built-in to SillyTavern and does not need to be installed separately."]},{"l":"Quick start","p":["Set up:","Open the Image Captioning panel in the Extensions panel","Choose a captioning source (most likely \"Local\" or \"Multimodal\")","For \"Multimodal\" ensure you've set up the connection in the API Connections tab","Generate a caption:","Choose \" Generate Caption\" from the Extensions popup menu","Select an image file when prompted","Wait for the caption to be generated","Review and send:","The captioned image will be inserted into your message","See the caption using the image tooltip","Click Send to see what your character thinks of the image!"]},{"l":"Panel controls"},{"l":"Source Selection","p":["Choose the source for image captioning. Supported options:","Source","Description","Multimodal","Cloud: OpenAI, Anthropic, Google, MistralAI, and others. Local: Ollama, llama.cpp, KoboldCpp, Text Generation WebUI, and vLLM. Supports custom prompts so you can ask your images questions.","Local","Uses transformers.js running locally inside your SillyTavern server. Zero setup!","Horde","Uses the AI Horde network, a crowdsourced distributed network of image generation models. Nothing to download, configure, or pay for. Variable response times.","Extras","The Extras project was discontinued in April 2024 and is not maintained or supported."]},{"l":"Caption Configuration","p":["Caption Prompt: Enter a custom prompt for captioning. The default prompt is \"What's in this image?\"","Ask every time: Toggle to request a custom prompt for each image caption"]},{"l":"Message Template","p":["Message Template: Customize the caption message template. Use {{caption}} macro to insert the generated caption. The default template is [{{user}} sends {{char}} a picture that contains: {{caption}}]"]},{"l":"Auto-captioning","p":["Automatically caption images: Toggle to enable automatic captioning of images pasted or attached to messages","Edit captions before saving: Toggle to allow editing captions before they are saved"]},{"l":"Captioning images","p":["All the ways to caption images in SillyTavern:","Choose \" Generate Caption\" from the Extensions popup menu and select an image file when prompted","Click the Caption icon at the top of an image already in a message","Paste an image directly into the chat input with auto-captioning enabled","Attach an image file to a message using the Embed File or Image button in the actions of a message.","Send a message with an embedded image","Use the /caption slash command"]},{"i":"auto-captioning-1","l":"Auto-Captioning","p":["The auto-captioning feature allows you to automatically generate captions for images as they are added to the chat, without manually triggering the captioning process each time.","To enable, select the \"Automatically caption images\" checkbox in the Image Captioning panel. You can also choose to edit captions before they are saved by checking the \"Edit captions before saving\" box.","Once enabled, auto-captioning will trigger in the following scenarios:","When an image is pasted directly into the chat input.","When an image file is attached to a message.","When a message with an embedded image is sent.","The system will use your selected captioning source (Local, Extras, Horde, or Multimodal) and the configured settings to generate a caption for the image."]},{"l":"Editing captions before saving (Refine Mode)","p":["If you've enabled the \"Edit captions before saving\" option:","After an image is added, a popup will appear with the generated caption.","You can review and edit the caption as needed.","Click \"OK\" to apply the caption, or \"Cancel\" to discard the caption without saving."]},{"l":"Caption sending","p":["The generated (and optionally edited) caption will be automatically inserted into the prompt using the Message Template you've configured. By default, it will be sent in this format:"]},{"l":"Slash Command: /caption","p":["The extension provides a /caption slash command to use in the chatbox or in scripts."]},{"l":"Usage","p":["prompt(optional): A custom prompt for the captioning model. Only supported by multimodal sources.","quiet=true|false: If set to true, suppresses sending a captioned message to the chat. Default is false.","mesId=number: Specifies a message ID to caption an image from an existing message instead of uploading a new one.","If no mesId is provided, the command will prompt you to upload an image. When quiet is false (default), a new message with the captioned image will be sent to the chat. The generated caption can be used as input for other commands."]},{"l":"Examples","p":["Caption a new image with the default settings:","Caption a new image with a custom prompt:","Caption an image from message #5 without sending a new message:","Caption an image from message #10 with a custom prompt then generate a new image based on the caption:"]},{"l":"Local source","p":["You can change the model in config.yaml. The key is called extensions.models.captioning. Enter the Hugging Face model ID you want to use. The default is Xenova/vit-gpt2-image-captioning.","You can use any model that supports image captioning ( VisionEncoderDecoderModel or \"image-to-text\" pipeline). The model needs be to compatible with the transformers.js library. That is, it needs ONNX weights. Look for models with the ONNX and image-to-text tags, or that have a folder called onnx full of .onnx files."]},{"l":"Multimodal source"},{"l":"General configuration","p":["Model: Choose the model for image captioning. Options vary based on the selected API.","Allow reverse proxy: Toggle to allow using a reverse proxy if defined and valid (OpenAI, Anthropic, Google, Mistral, xAI)","API keys and endpoint URLs for captioning sources are managed in the API Connections panel. Set the connection up in API Connections first, then select it as your captions source in Captioning.","One last time: configure the API key/address/port in API Connections and use the connection in Captioning.","You can still use Claude for chats and Google AI Studio for image captioning, or whatever. Just set them both up in the 'API Connections' tab first. Then flip your Chat Completion source to Claude and your Captioning source to Google AI Studio.","For most local backends, you will need to set some options in the model backend rather than in SillyTavern. If your backend can only run one model at a time and doesn't support automatic switching, you have several options to use different models for chat and captioning:","Secondary endpoints: Use the secondary endpoint feature (see Secondary endpoints section below) to connect to a different API server for captioning","Multiple connection types: Connect to your backend using both Text Completion and Chat Completion modes in API Connections - this gives you two separate connections to the same backend type"]},{"l":"Sources","p":["\"I don't want to pay anything or run anything\": Google AI Studio free tier","\"I want the best captioning possible, and I don't mind paying for it\": Anthropic","\"I want to caption images locally and have it just work\": Ollama","\"I want to complain when it doesn't work\": Extras","\"I want to keep the dream of local AI alive\": KoboldCpp","01.AI (Yi)","AI/ML API","Anthropic","API Provider","Cloud, free","Cloud, free tier then paid, Gemini Flash/Pro","Cloud, free tier, Gemini Flash/Pro","Cloud, llama-3.2-vision in 11B/90B, LLaVA","Cloud, paid (maybe free options), many models, pick from what's available within Captioning after configuring in API connections","Cloud, paid, Aya Vision 8B / 32B","Cloud, paid, Claude models with vision capabilities: claude-3-5-sonnet/haiku, claude-3-opus/sonnet","Cloud, paid, GPT-4 Vision, 4-turbo, 4o, 4o-mini","Cloud, paid, grok-vision","Cloud, paid, pixtral-large, pixtral-12B","Cloud, paid, various GPT, Claude, and Gemini models with vision capabilities","Cloud, paid, yi-vision","Cohere","Custom (OpenAI-compatible)","Description","For custom OpenAI-compatible APIs, uses currently configured model in API Connections tab","Google AI Studio","Google Vertex AI","Groq","KoboldCpp","llama.cpp","Local","Local, can switch between available models and download additional vision models within Captioning after configuring in API Connections","Local, must configure model in KoboldCpp","Local, must configure model in llama.cpp","Local, must configure model in ooba","MistralAI","Ollama","OpenAI","OpenRouter","Pollinations","Text Generation WebUI (oobabooga)","To use one of these caption sources, select Multimodal in the Source dropdown.","vLLM","xAI (Grok)"]},{"l":"Secondary endpoints","p":["By default, the Multimodal source uses the primary endpoint configured in the API Connections tab. You can also set up a secondary endpoint specifically for multimodal captioning.","Open the Image Captioning panel in the Extensions panel.","Select \"Multimodal\" as the captioning source and a preferred API provider.","Enter a valid URL for the secondary endpoint in the \"Secondary captioning endpoint URL\" field.","Check the \"Use secondary URL\" box to enable the secondary endpoint.","Do not append /v1 or /chat/completions to the end of the URL. The extension will handle that automatically.","This is only supported by the following APIs:","KoboldCpp","llama.cpp","Ollama","Text Generation WebUI (oobabooga)","vLLM"]},{"l":"Source-specific guides"},{"l":"KoboldCpp","p":["For general information on installing and using KoboldCpp, see the KoboldCpp documentation.","To use KoboldCpp for multimodal captioning:","get a multimodal-capable model, trained to process text and image prompts at the same time.","also get the multimodal projections for the model. These weights allow the model to understand how the text and image parts of the input relate to each other.","load the model and projections in the KoboldCpp launch GUI or command line interface.","The original and classic local multimodal model is LLaVA. GGUF-format files for the model and projections are available from Mozilla/llava-v1.5-7b-llamafile. To load them from the command line, set the model and projections with the --model and --mmproj flags. For example:","Some LLaVA finetunes you can try: xtuner/llava-llama-3-8b-v1_1-gguf, xtuner/llava-phi-3-mini-gguf.","You can use multimodal projections for the base model that your particular finetune was built from. Projections for some common base models are available from koboldcpp/mmproj."]}],[{"l":"Image Generation","p":["Ability to view all generated images in a character gallery","Advanced ComfyUI integration for highly customizable workflows","Automatically generate images as replies to your messages for full immersion, generate from chat history and character information from the wand menu or slash commands, or use the /sd (anything_here) command in the chat input bar to make an image with your own prompt.","Character-specific prompt prefixes for tailored character images","Customizable prompt templates and prefixes for consistent style and quality","Flexible visibility options for generated images in chat","Image swipes feature to regenerate images while keeping the same prompt","Integration with AI function calling for automatic image generation detection","Interactive mode to trigger image generation based on natural language requests","Most common Stable Diffusion generation settings are customizable within the SillyTavern UI.","Options to edit prompts before generation and extend free-mode prompts","Slash commands for easy image generation within chats","Style presets to quickly switch between different image generation settings","Supports multiple image generation sources, both local and cloud-based","Use local or cloud-based Stable Diffusion, FLUX or DALL-E APIs to generate images.","Various generation modes for characters, scenes, and custom prompts"]},{"l":"Supported sources","p":["AI.ML API","Black Forest Labs","Cloud","Cloud, free of charge","Cloud, open source (AGPL3), free of charge","Cloud, open source (MIT), free of charge","Cloud, paid","Cloud, paid. Imagen model series. AI Studio only supports Imagen 3.0 002 model.","Cloud, requires an active subscription","ComfyUI","Deprecated, not recommended","Draw Things","FAL.AI","Google AI Studio/ Google Vertex AI","HuggingFace Serverless","Local, Mac/iOS, free of charge","Local, open source (AGPL3), free of charge","Local, open source (GPL3), free of charge, see ComfyUI Configuration.","NanoGPT","NovelAI Diffusion","OpenAI","Pollinations","Remarks","SD.Next / vladmandic","SillyTavern Extras","Source","Stability AI","Stable Diffusion WebUI / AUTOMATIC1111","Stable Horde","TogetherAI","x.AI"]},{"l":"Generation modes","p":["-","\"Background\"","\"Me\"","\"Raw Last Message\"","\"The Last Message\"","\"The Whole Story\"","\"Your Face\"","\"Yourself\"","A chat background based on story context.","A close-up portrait of the current character.","A full-body portrait of the current character.","A portrait of the user persona.","A visual recap of the chat events.","A visual recap of the last chat message.","background","Description","face","Forces a portrait aspect ratio.","Forces a wide landscape aspect ratio.","last","Last message used as a prompt verbatim.","me","raw_last","Remarks","scene","Slash command argument","Wand menu item","you"]},{"l":"How to generate an image","p":["Use the \"Image Generation\" item in the extensions context menu (wand).","Type a /sd (argument) slash command with an argument from the Generation modes table. Anything else would trigger a \"free mode\" to make SD generate whatever you prompted. Example: /sd apple tree would generate a picture of an apple tree.","Look for a paintbrush icon in the context actions for chat messages. This will force the \"Raw Message\" mode for the selected message.","Every generation mode besides raw message and free mode will trigger a prompt generation using your currently selected main generation API to convert chat context into the SD prompt. You can configure the instruction template for generating prompts for every generation mode using the \"SD Prompt Templates\" settings drawer in the extensions panel."]},{"l":"Tips and tricks for the /sd command usage"},{"l":"View all generated images","p":["To view all saved images for a character (including other chats), open a gallery from a \"More...\" dropdown menu on a character info panel, or use a /show-gallery slash command."]},{"l":"Specify a negative prompt","p":["Use a negative named argument before the prompt to enforce a specific negative prompt for this generation."]},{"l":"Include a character-specific prefix","p":["Use a special {{charPrefix}} macro in free-prompt mode to include positive and negative prompt prefixes (if defined) for the current character."]},{"l":"Suppress a chat message","p":["You can avoid posting a generated image into the chat by passing a quiet=true named argument. The image will still be added into the character gallery, and the command will produce a relative URL to the image that can be consumed by other commands.","The example below will send the generated image using Markdown as a user persona."]},{"l":"Image swipes","p":["Images swipes allow to reroll the image generation while keeping the same prompt. If a fixed seed is set, it will be randomized for the next generation.","To cycle through images, hover a mouse cursor (tap on mobile) over a generated image to reveal arrow buttons and swipes counter. Tapping right arrow on the latest image will generate a new one.","'Swipes' here is just a name, don't try the actual swiping gesture, as this will regenerate the message itself, not the attached image."]},{"l":"Options"},{"l":"Edit prompts before generation","p":["Allow to edit the automatically generated prompts manually before sending them to the Stable Diffusion API."]},{"l":"Use function tool","p":["Uses function calling to automatically detect the intention to generate an image.","Requirements:","Must have image generation configured with a supported source.","Must use a supported Chat Completion API model and have function tool calling enabled in the AI Response settings.","The \"Use function tool\" option must be enabled in the Image Generation settings.","The user should express an intent to generate an image in the chat message, e.g. \"Send me a picture of a cat\".","The interactive mode will not trigger when the function tool is enabled."]},{"l":"Use interactive mode","p":["Allows to trigger an image generation instead of text as a reply to a user message that follows the special pattern:","Contains one of the following verbs: send, mail, imagine, generate, make, create, draw, paint, render","Followed by one of the following nouns (not further than 10 characters away): pic, picture, image, drawing, painting, photo, photograph","Followed by a target subject of image generation, could be optionally preceded by phrases like \"of a\" or \"of this\".","Examples of valid requests and captured subjects:","Can you please send me a picture of a cat=> cat","Generate a picture of the Eiffel tower=> Eiffel tower","Let's draw a painting of Mona Lisa=> Mona Lisa","Some special subjects trigger a predefined generation mode:","'you, 'yourself' => \"Yourself\"","'your face', 'your portrait', 'your selfie' => \"Your Face\"","'me', 'myself' => \"Me\"","'story', 'scenario', 'whole story' => \"The Whole Story\"","'last message' => \"The Last Message\"","'background', 'scene background', 'scene', 'scenery', 'surroundings', 'environment' => \"Background\""]},{"l":"Extend free-mode prompts","p":["When using the interactive mode of the slash command, automatically extend free-mode generation subject descriptions by prompting your main API."]},{"l":"Snap auto-adjusted resolutions","p":["Snap image generation requests with a forced aspect ratio (portraits, backgrounds) to the nearest known resolution, while trying to preserve the absolute pixel counts. Refer to the \"Resolution\" dropdown for the list of possible options.","Recommended for SDXL models."]},{"l":"Common prompt prefix","p":["Use {prompt} macro to specify where exactly the generated prompt will be inserted.","Added before every generated or free-mode prompt. Commonly used for setting the overall style of the picture.","Example: best quality, anime lineart."]},{"l":"Negative prompt","p":["Characteristics of the image you don't want to be present in the output.","Example: bad quality, watermark."]},{"l":"Character-specific prompt prefix","p":["If supported by the generation source, you can also use LoRAs/embeddings here, for example: lora:DonaldDuck:1.","Any characteristics that describe the currently selected character. Will be added after a common prefix.","Example: female, green eyes, brown hair, pink shirt.","You can also specify a negative prompt prefix for any unwanted content. It will be combined with the general negative prompt.","Limitations:","Works only in 1-to-1 chats. Will not be used in groups.","Won't be used for backgrounds and free mode generations.","To force include a character prefix into a free mode prompt, use the {{charPrefix}} macro anywhere in the prompt.","If you want to share the prefixes with others, tick the \"Shareable\" checkbox. This will save them with the character data, rather than your local settings."]},{"l":"Styles","p":["Use this to quickly save and restore your favorite style/quality presets to use them later or when switching between models. The following is included in the Style preset:","Common Prompt Prefix","Negative Prompt","You can also switch between styles using the /imagine-style command (or /sd-style or /img-style)."]},{"l":"Chat Message Visibility","p":["Generated images inserted into the chat are hidden in the main API prompts by default, but this can be overriden individually per generation initiator (\"Magic wand\" icon, slash command, interactive mode). This can be used for making the experience more immersive by letting the characters \"acknowledge\" the images. Multimodal models in Chat Completions API may also 'see' the images if \"Send inline images\" is enabled.","A text message can be customized by changing the \"Chat Message Template\" under Image Prompt Templates. All regular macros can be used in this template, plus a special {{prompt}} macro to specify where the image prompt will be added."]},{"l":"ComfyUI Configuration","p":["ComfyUI is a fast and very flexible option for image generation.","If you're familiar with ComfyUI, the tl;dr is: make your workflow in ComfyUI, download it in API format, and paste it into the SillyTavern ComfyUI Workflow Editor. ST will submit your workflow to ComfyUI's API and you will get an image in your chat. But with great power comes great responsibility, and the main responsibility is inserting placeholders in your workflow JSON so you can change settings from SillyTavern.","If you're not familiar with ComfyUI, you can still use it to generate images in SillyTavern using the default workflow. Later, when you want great power, you can learn how to use ComfyUI..."]},{"l":"Controls","p":["This panel allows you to configure and manage your ComfyUI integration with SillyTavern.","Enter the URL of your ComfyUI server in the ComfyUI URL input field. The default value is http://127.0.0.1:8188. If you are using SwarmUI, the default port for the managed ComfyUI server is 7821, 20 ports higher than the default port for SwarmUI.","After entering the URL, choose Connect to validate and establish a connection. The ComfyUI server must be accessible from the SillyTavern host machine."]},{"l":"Workflow Management","p":["Select a ComfyUI workflow from the dropdown menu. Two default workflows are provided:","Default_Comfy_Workflow.json: A basic text-to-image workflow supporting the most common image generation settings.","Char_Avatar_Comfy_Workflow.json: A sample image-to-image workflow that uses the character avatar, plus the prompt, to generate an image.","Use the following buttons to manage your workflows:","Open workflow editor to view and modify the selected workflow.","Create new workflow to create a new workflow with a custom name.","Delete workflow to remove the selected workflow."]},{"l":"Workflow Editor","p":["The ComfyUI Workflow Editor allows you to view and modify ComfyUI workflows for use with SillyTavern.","The main component of the editor is a large text area where you can insert or edit your ComfyUI workflow in JSON format.","To add a ComfyUI workflow to the editor, follow these steps:","Enable 'Dev Mode' in ComfyUI settings.","Use the 'Save (API Format)' option in ComfyUI to download the JSON data.","Create a new workflow in SillyTavern and open the editor.","Paste the downloaded JSON data into the text area.","Replace specific values with placeholders as needed for your use case.","You can add the API-format JSON file directly to the data/default-user/user/workflows directory in your SillyTavern installation. This will save you from steps 3 and 4.","Retain the original JSON file. If you need to open the workflow again in ComfyUI to make changes, it is much more convenient to edit the original file than the one with all the placeholders."]},{"l":"Placeholders","p":["The editor provides a list of predefined placeholders that can be used in your workflow JSON. These placeholders are replaced with dynamic values when the workflow is executed in SillyTavern.","Placeholders marked with ✅ are present in your workflow JSON. Placeholders marked with ❌ are not present in your workflow JSON. You can add these placeholders to your workflow JSON as needed. You do not need to add all the placeholders, only the ones that your workflow uses and you want to replace dynamically."]},{"l":"Prompts","p":["The %prompt% and %negative_prompt% placeholders are used to insert the image generation prompts into the workflow. These contain the final prompts generated by SillyTavern, including the generated prompt for your chosen /sd mode, the common prompt prefix, negative prompt, and character-specific prompt prefix.","For example, you may have tested your workflow with a prompt like \"forest elf\" in ComfyUI. To use this workflow in SillyTavern, you can replace the \"forest elf\" prompt with the %prompt% placeholder:","Notice that the placeholder is wrapped in double quotes. This is important for the JSON format, and required by SillyTavern's placeholder replacement system. Even for numbers, you must use double quotes in the template JSON.","Sometimes the prompt (or other value) doesn't appear where you might expect. ComfyUI will remove nodes from the API version of the workflow if they are not necessary for the workflow to function in API mode.","For instance, this workflow uses a LoRA tag loader node with a prompt primitive so the workflow is clearer in UI mode:","Prompt primitive and LoRA loader","The prompt primitive node will be removed from the API version of the workflow, so you insert the placeholder in the LoraTagLoader node. Find the text \"apple tree\" in the workflow and replace it with the %prompt% placeholder:","In some cases you may need to make several replacements in the workflow JSON, even if the prompt appears only once in the UI."]},{"l":"Model","p":["The %model% placeholder will insert the value of the selected model in the image generation settings.","An example from the default text-to-image workflow:","To load GGUF-quantized UNets, use a UNet Loader (GGUF) node in your workflow, choose a GGUF model in the SillyTavern model dropdown, and use the %model% placeholder in the node's settings like this:","Stable Diffusion checkpoints, SD UNets, and GGUF-quantized UNets all appear in the Model dropdown. Models of one type will not work with workflows/loader nodes expecting another type. If you choose an incompatible model type in ST, ComfyUI will report a problem with the loader node."]},{"l":"Avatar images","p":["Use the %user_avatar% and %char_avatar% placeholders to include the user and character avatars in the workflow. These placeholders are replaced with the PNG data of the avatars when the workflow is executed. The image data is encoded in base64 format, so you must decode it in your workflow. A popular choice for this task is the Load image (Base64) node.","In this example, the character avatar is loaded with a Load Image (Base64) node. It also uses an Image Resize node to rescale the image to whatever size is specified in the image generation settings:","Load image from base64 string and resize","Insert the %char_avatar%, %width%, and %height% placeholders into the JSON for the Load Image (Base64) and Image Resize nodes:","To get a base64-encoded image string for testing your workflow in ComfyUI, use any online tool that converts images to base64 strings. Here's an example string you can use for initial testing: sd-comfy-base64-test-string.txt."]},{"l":"Other placeholders","p":["Most other placeholders use the values of the corresponding controls in image generation settings, or the values that you specify with the /sd command:","%vae%, but most SD models include a VAE so the default workflows do not use this placeholder. Use it with custom workflows to load a VAE alongside a UNet, override the default VAE, etc.","%sampler%","%scheduler%","%steps%","%scale%","%width%","%height%","%denoise%: for the sample image-to-image workflow, vary the denoise amount between about 0.5 (barely-noticeable changes to the source image) and 1.0 (a completely different image as if no source image was used). Not used by the default text-to-image workflow because there's no point using a value other than 1.0 for text-to-image.","%clip_skip%: not used by the default workflows but available for custom workflows.","The %seed% placeholder will insert the seed value from the control if you have specified one. If you set the seed to -1, SillyTavern will generate a new random seed for each image in %seed%."]},{"l":"Custom placeholders","p":["You can add custom placeholders to your workflow:","Look for the \"Custom\" section below the predefined placeholders.","Click the \"+\" button to add a new custom placeholder.","Enter a name for the placeholder in the find field.","Enter the value that you want to replace the placeholder with in the replace field.","Custom placeholders will appear in a separate list below the predefined ones.","For example, you could replace the \"SillyTavern\" prefix for saved image filenames in the default workflow with a custom placeholder. Add a new custom placeholder with find set to filename_prefix and replace set to ServiceTesnor. Insert the new %filename_prefix% placeholder into your workflow JSON. Now you can change the filename prefix from SillyTavern to ServiceTesnor by changing the value of the custom placeholder."]},{"l":"Comfy tricks","p":["Read all the general information on this page so you're familiar with the image generation options. Options such as switchable styles and common prompt prefixes, when combined wih the total flexibility of ComfyUI workflows, allow you to create a wide variety of image generation setups."]},{"l":"Loading LoRAs","p":["Use a LoRA tag loader node (such as Load LoRA Tag) to load any LoRAs specified in the prompt. Now you can add as many LoRAs as you like to your prompt with tags like lora:CroissantStyle:0.8, and they will be loaded into your workflow. This will also make the \"pro-tip\" of using LoRAs in character-specific prompt prefixes work with ComfyUI."]},{"l":"Setting workflow values from styles or slash-commands","p":["You can use macros in custom placeholder values. As a practical example, let's say you sometimes want to generate images without a background, and you'd like this to be switchable with a slash-command or image style. Here's how you could do it:","Make a ComfyUI workflow that removes the image background, or not, depending on the value of an input","Use a custom placeholder to set the value of that input, but use {{getvar::remove_background}} as the replace value","Now you can set the value of remove_background with /setvar key=remove_background true or /setvar key=remove_background false before generating an image","The workflow will use the value you set to determine whether to remove the background","Make an image style \"No background\" with common prompt prefix {{setvar::remove_background::true}}","Use the style control or /imagine-style No background to set the value of remove_background to true before generating an image"]}],[{"l":"Live2D","p":["This guide will walk you through the process of setting up and customizing the Live2D extension for your SillyTavern experience. This extension allows you to use Live2D animated models for your character, providing a dynamic and interactive element to your virtual character."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Branch Selection: Make sure you're using the latest version of SillyTavern to access the latest features and updates.","Extension Installation: Install the \"Live2D\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (represented by the stacked blocks icon).","Model Folder Placement: Place your Live2D model folders into the /data/user-handle/assets/live2d directory. A properly organized live2d assets folder might look like this:","Asset folder example","A Live2D model folder should include all necessary components for the Live2D model, such as expressions, motions, textures, sounds, and settings files. Notably the ***.model.json file must be at the root of the Live2D model folder for the model to be detected by the extension. In this example the shizuku live2d model folder may look like this:","Live2d model folder example","Note: Models can also be placed in character-specific folders, such as /data/user-handle/characters/Shizuku/live2d/. However, models in character folders will only be accessible for that specific character."]},{"l":"Extension Settings","p":["The Live2D extension offers various settings to customize the behavior of your animated model. Here are the key settings:","UI global settings"]},{"l":"Global Settings","p":["Enabled:","Enable this checkbox to activate the extension, allowing your Live2D model to interact within SillyTavern.","You can disable the extension if you want to use normal sprites only.","You can disable the extension when you want to move normal sprites in a group chat and enable it again when you're ready to use Live2D models.","Follow Cursor:","Enable this checkbox to make the Live2D model follow your cursor, provided that the model supports this feature.","Auto-send Interaction:","Enable this checkbox to automatically trigger character interactions when you click on areas with mapped messages (refer to the hit areas section for details)."]},{"l":"Debug Settings","p":["These settings help you control the behavior and visibility of your Live2D model for debugging purposes.","Reset Model Before Animation:","Enable this checkbox to reload the model before any animation. This forces the animation to start and allows you to spam clicks if necessary. Some models may require this to ensure that animations begin from a compatible state.","Show Model Frames:","Enable this checkbox to display the model frame, making it easier to identify where to click to drag the model around. It also shows the hit area, if available. Hovering over a hit area will show its name.","Reload button","Click this button to reload every live2d model. Use it in case something glitches."]},{"l":"Character Selection","p":["These settings allow you to manage characters and assign Live2D models to them.","Refresh Button:","Click the refresh button to update the list of characters in the current chat.","Select Character:","Use the drop-down list to choose a character to assign a Live2D model to.","Remove Button:","Click this button to delete all assigned models for a character. A confirmation prompt will appear to confirm the deletion."]},{"l":"Model Selection","p":["UI model list","Refresh Button:","Click the refresh button if your Live2D model does not appear in the list.","Select Model:","Choose a model from the list to assign it to the selected character.","The model can be located in the asset folder or the current character's folder.","The list displays the model folder name, its origin (asset or character), and the name of the detected model setting file.","Note that some model folders may contain different versions of the same model. You can try different model files to see which one works best.","Selecting none will use normal sprites if there is any","Settings are saved per character and model"]},{"l":"Model Settings","p":["UI model settings","Model Scale:","Use the slider to adjust the size of the model, making it larger or smaller.","Model Center X Offset:","Use the slider to change the horizontal position of the model relative to the window center.","Model Center Y Offset:","Use the slider to adjust the vertical position of the model relative to the window center."]},{"l":"Remarks","p":["The settings are saved and carry over different chats.","You can also drag the model with your mouse, and those settings will be updated and saved.","Use these UI settings to bring your model back on the screen if you somehow made it out of view. Also, check the \"Show frame\" checkbox to see clearly where you can click to drag the model."]},{"l":"Model Talk","p":["UI model talk","Param mouth open Y id","Select from the list the ID of the parameter corresponding to the model's mouth Y value. Not all models have one, and names may vary from model to model. Usually something like \"PARAM_MOUTH_OPEN_Y\" or \"ParamMouthOpenY\". Check the model when selecting an element from the list; it will try to run the speak animation. If the mouth moves, you got it!","Mouth movement speed","Adjust the slider to change the movement speed of the mouth animation.","Time per character","Set the time duration of each character. The duration of the talk animation will be this time multiplied by the number of characters of the message."]},{"i":"remarks-1","l":"Remarks","p":["This mouth animation does not work on every model and every animation. Even if your model has animations where the mouth moves, it does not mean the mouth animation can be controlled by this extension. If nothing shows in the parameter list, your model is probably made with a too old version of Live2D to access the parameters properly."]},{"l":"Model Animations","p":["UI model animations","Starter animation","Select an expression and motion from the lists that will play when starting a chat with the character. You can also add a delay during which the model will be invisible if you need to hide the character for some time to achieve a perfect effect.","Default animation","Select an expression and motion from the list that will play when the character sends a message. Use a fallback animation when using the classify expression extension."]},{"i":"remarks-2","l":"Remarks","p":["Animations will play when you select one in the lists.","Use the replay button to replay the selected animation.","Some models have expressions defined as motions.","If nothing shows in the lists, it's probable your model's setting file has no expressions/motions defined."]},{"l":"Hit areas mapping","p":["UI model mapping","Default click animation","Select an expression and motion from the list that will play when you click on the model. You can also set a message that will be sent as a user message.","Hit areas","If the model has hit areas, they will be listed, and you can assign an animation/message to each of them."]},{"i":"remarks-3","l":"Remarks","p":["Some models have no hit areas, but the default click is detected for all.","The default click will trigger if you click on a hit area with nothing mapped or if you click outside of any hit area.","Hit areas have priority defined in the model; for example, \"mouth\" is inside \"head.\" If it does not behave properly, it may be due to the model file.","For some models, animations need to be finished before starting another one. Use the debug checkbox if you want to force the refresh and spam animations."]},{"l":"Classified Expressions Mapping","p":["UI model classify","Requirements","Requires the use of the classify expression extension; otherwise, it will fall back to the default animation.","Mapping","For each detected emotion by the classify extension, you can assign an expression/motion animation."]},{"i":"remarks-4","l":"Remarks","p":["If the previous animation did not finish when a new message is received, it's possible that the new animation will not play. This behavior is dependent on the Live2D model. Use the debug checkbox if you want to force the animation to play.","Thank you for following this guide! Your SillyTavern experience is now enriched with animated and interactive Live2D models."]}],[{"l":"Objective"},{"l":"What is it?","p":["The Objective extension lets the user specify an Objective for the AI to strive towards during the chat. This objective is broken down into step-by-step tasks. Tasks may be branched, where child tasks can be created automatically or manually. This gives the ability to create complex task trees. The completion status of each task in the list will be checked at certain intervals.","This differs from adding static direction through prompting in that it adds sequential and paced directives for the AI to follow without user intervention. It gives a more genuine experience of the AI autonomously striving to reach a goal."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest version of SillyTavern.","Install the \"Objective\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Common Use Cases","p":["Your imagination is the limit, you can give the AI any objective you wish and it will plan out how to achieve it. You can ask it to plan how to slay a demon, rob a temple, throw a lavish party, or even take over the world.","Objective Settings Panel"]},{"l":"Configuration","p":["The extension is found in the Extensions menu under Objective.","Type an objective into the top text box, then click on Auto-Generate Tasks. This sends a request to the connected API and asks it to provide a list of tasks which match the objective you have typed in.","Note: Clicking Auto-Generate Tasks will delete all existing tasks for the currently selected Objective before adding new ones.","Upon receiving the response from the AI, a list of tasks will be created automatically in the space below the Objective input box. Tasks can be edited after creation.","At the bottom of the panel are two boxes: Position in Chat and Task Check Frequency","Position in Chat- This is how 'deep' in the chat section of the prompt you want the current task to be inserted. The lower the number, the more attention the AI will give to the task. Setting to 0 will make the task the primary thing in the AI's mind. Setting at high values will put the task in the background and allow the AI to focus on the conversation at hand, but setting it too high may cause the AI to never 'get around' to the task at all.","Task Check Frequency- This is how often you want the AI to check if the task has been completed. If it is set to 3, the AI will be asked if the current task has been completed every 3rd message.","Objectives, tasks, and their descriptions are saved in real-time to the current chat session. Custom prompts are saved globally."]},{"l":"Custom Prompts","p":["You can customize the prompts sent to the LLM to generate tasks, check task completion, and for prompt injection. Editing prompts will save them for the current session. Custom prompts can be saved and loaded for persistence.","Click Edit Prompts to open the prompt editor window. You can edit your prompts as desired.","To save prompts, enter a name and click Save Prompt.","To load prompts, select the prompt from the dropdown list.","To delete a saved prompt, select it from the dropdown list and click Delete Prompt","WARNING: Task Checking happens in a separate API request. Setting Task Check Frequency to 1 will double your API calls to the LLM service. Be careful with this if you are using a paid service."]},{"l":"Usage","p":["By default the Objective extension will keep track of all tasks and their respective completion status automatically.","The User can also manually create, update, delete, and complete tasks at any time."]},{"l":"Current Task Selection","p":["The current task will always be the first listed incomplete task. Any manual updates to tasks will trigger a check for what the current task should be. So if you add a task above a bunch of completed tasks, it will be set as the current task. Once it's completed, previously completed tasks will be skipped and the next incomplete task will be selected as 'Current'.","When using parent/child tasks in a task tree, tasks are selected depth-first, meaning all child tasks will be selected in order first, then continue down the list of tasks for the current Objective/Task."]},{"l":"Branch Tasks","p":["Click the Branch Task button to set the current task as an Objective where you can auto generate or manually create tasks as child tasks. You can continue to turn any child task into an Objective and keep generating to your hearts content.","Marking a parent task as complete will cause the extension to skip all subtasks. When all child tasks are complete, the parent task will be marked as complete"]},{"l":"Manually Complete Tasks","p":["You can manually toggle the completion status of a task by clicking the checkbox next to it. This will set the next incomplete task to be selected."]},{"l":"Manual Task Check","p":["If you want to manually trigger the AI to check for task completion, click on the Extras Extension button (the magic wand on the right side of the chat input bar) and select Manual Task Check."]},{"l":"Manually Add Tasks","p":["When no tasks are present, an Add Task button is visible, allowing you to manually create the first task.","If other tasks are already present, click the + button to the right of any task to insert a new task after it."]},{"l":"Delete Tasks","p":["Click the red x to delete an existing task. The next incomplete task will be selected as the current task automatically.","Deleting a task with child tasks will delete all child tasks and their descendants."]},{"l":"Hiding Tasks","p":["If you want to remain unaware of what tasks the AI is attempting to complete, check the Hide Tasks box to hide the task list and make the AI's intentions a mystery. For 100% mysteriousness, do this before clicking Auto-Generate Tasks!"]}],[{"l":"Regex"},{"l":"What is it?","p":["The Regex extension lets the user automatically detect specific patterns in a string of text (called 'sequences') and apply manipulations (replacements) to them. It can be a powerful tool when used in conjuction with other SillyTavern features such as Quick Replies or STscript, or simply a way to remove certain words from a chat."]},{"l":"Helpful Links","p":["This document will not explain the process of writing a RegEx sequence in depth. There are many online resources to assist you with that.","https://regexr.com","https://regex101.com","https://extendsclass.com/regex-tester.html","https://en.wikipedia.org/wiki/Regular_expression"]},{"l":"Prerequisites","p":["Regex is a built-in extension of SillyTavern, so no additional setup is required.","You may find its settings in the Extensions panel."]},{"l":"Common Use Cases","p":["RegEx is often used to apply a find-replace function on certain words in the chat, to add markdown styles to certain words or sentence types, or to return a boolean value to an STscript."]},{"l":"Script List","p":["RegEx Extension Script List","The buttons at the top are used to make a new script.","'Global' scripts will apply to all characters and will be saved into settings.json.","'Scoped' scripts will only apply to the currently active character, and will be saved into the character card's data.","'Import' lets you import RegEx scripts which were exported from another instance of SillyTavern.","Below this is a list of your scripts with some action buttons.","Drag handles (three horizontal bars to the left of the script name) let you drag/drop the scripts into any order you like.","Primary on/off switch can be quickly toggled to enable or disable the script without changing anything else. Disabled scripts are shown with strikethrough styling. If a script is disabled here, it will be untriggerable by a Quick Reply or STscript.","'Edit' (pencil) button will open the RegEx script editor.","'Move to scoped' (down arrow) will convert a global script to a scoped script and apply it to the current character. In reverse (up arrow), it would convert a scoped script to global.","'Export' will cause your browser to download an exported .json file of the Script, which can then be shared and imported into another instance of SillyTavern.","'Delete' (trashcan) deletes the script."]},{"l":"RegEx Editor","p":["'AI Response': script will be run against the contents of the AI's response after it is received.","'Disabled' prevents the script from running. This is used as an override to prevent the script from running when you simply don't want to change any of the script's settings and/or don't want to disable it entirely via the switch on the script list (as doing so would prevent slash commands from triggering it).","'Don't Substitute' will cause any SillyTavern macros to be ignored so the RegEx script will treat them literally when searching.","'Escaped' will add a RegEx escape slash \\ before each character to ensure they do not accidentally alter the overall RegEx sequence. This can be useful if you have certain special characters in the values of the macro.","'Raw' will send in the value of the macro verbatim. This might alter the way your RegEx script searches the text if the value of the macro contains certain special characters.","'Reasoning': script will be run against the contents of the 'reasoning' object returned by Chat Completion API's like Gemini or Deepseek. If 'Alter Outgoing Prompt' is checked under Ephemerality, the script will also be applied to any reasoning blocks that are added into prompt in subsequent chat turns.","'Run on Edit' makes the script also run after a chat message has been edited. If this is unchecked, the contents of edited chat messages will not trigger the script.","'Slash Commands': script will be run against the values inserted into prompt/chat by slash commands.","'User Input': script will be run against the contents of the user's typed input after they hit Send.","'World Info': script will be run on against contents of World Info entries as they are injected into the prompt. Requires 'Alter Outgoing Prompt' to be checked (or both ephemerality boxes to be unchecked).","Adding the extension-specific macro {{match}} in this box will insert the full matched sequence of text. This is commonly used to apply styles to specific words. Going back to the above example, if **{{match}}** were put into the 'Replace With' box instead, all occurences of the word 'apple' would be replaced with **apple**, which would apply the bold markdown style to it.","Affects: This list of checkboxes defines the text sources to which the RegEx script will be applied.","Find Regex: This is the Regular Expression that is used to detect your targeted text pattern. This is usually the most complex part of any RegEx script, and is the easiest place to make mistakes. Refer to the links at the top of the page for information how to write a RegEx sequence. This box can resolve the values of common SillyTavern macros(such as {{user}}, {{char}}, etc) if the 'Macros in Find Regex' is set to do so (see below).","If everthing here is unchecked the script will never activate during normal chatting, but it can still be activated via slash command or STscript.","Macros in Find Regex: Select whether or not to replace macros (such as {{user}}, {{char}}, etc) that are present in the Find Regex box's sequence.","Name: The label for the script shown on the extension's script list. This is also used to target the script when triggering it via slash command or STscript.","Other Options:","Replace With: This is what will replace the matched sequence. In a very simple example, if your 'Find Regex' is apple, and your 'Replace With' is orange, the first occurence of 'apple' would be automatically changed to 'orange' in any text where the script is applied.","Test Mode: This will open a comparison view at the top of the editor. Type some text into the 'Input' box, and the results of your RegEx script will be shown in the Output box. It is a valuable debug tool as it will update the Output box in real time as you make changes to the script settings.","Trim Out: text put in this box will be removed from the matched text sequence before the 'Replace With' process is applied. For example, if our match was 'apple', and the Trim Out box contains 'le', then the letters 'le' would be removed first before the 'Replace With' process is applied. Since our 'Replace With' box contains **{{match}}** it would result in **app** being put in as the replacement for 'apple' (first 'le' is removed, and the remaining matched text is given the bold markdown style). Multiple trims can be applied by adding a newline between each string you want to remove.","Variables such as $1, $2, $3 etc can be used to insert what are called 'Capture Groups'. These are substrings located in the text sequence matched by the 'Find Regex' sequence. Note that using these variables requires the matching expression to contain sets of parentheses to define which part of the matched string counts as a captured group. Refer to the links at the top for reference on how to set up Capture Groups."]},{"l":"Depth Settings","p":["The Min/Max Depth settings provide precise control over which messages in the chat history your regex pattern will affect:","Min Depth: Only affects messages that are at least N levels deep in the chat history","0 = last message","1 = second-to-last message","etc.","When blank (set to 'Unlimited'), or -1, will also affect the message to continue on the Continue action","Max Depth: Only affects messages no deeper than N levels in the chat history","Must be greater than Min Depth for the regex to apply","System prompts and utility prompts are not affected by these settings","For example, setting Min Depth to 0 and Max Depth to 2 would only apply your regex to the three most recent messages in the chat."]},{"l":"Flags","p":["By default the Find Regex pattern is case-sensitive and applies only to the first match. To adjust this behavior, as well as other RegEx flags, you can add them like so:","Example: /yourpattern/gi will match all instances of 'yourpattern' in the text, regardless of case.","Some of the most common flags are:","i: case-insensitive","g: global (applies to all matches, not just the first)","s: dotAll (treats the input as a single line, so . will match newlines)","m: multi-line (treats the input as multiple lines, so ^ and $ match the start/end of each line, not just the whole string)","u: unicode (treats the input as unicode, so \\d, \\w, etc. will match unicode characters)","For more information on RegEx flags, see the following MDN page: Advanced searching with flags"]},{"l":"Ephemerality","p":["By default (when neither box here is checked) a RegEx script will directly edit the text values stored inside the chat's JSONL file. This ensures both the outgoing prompt and the chat display will always contain the same values. However, these changes to the chat file are irreversible.","If you do not want this to happen, you can enable either of the checkboxes here to limit the RegEx script's affects to only the display or the outgoing prompt.","If only one of the boxes is checked, there will be no changes made to the chat file, but only the checked item will be changed. This means you will be seeing one thing, but the LLM will be seeing another. Use this carefully.","If both are selected, the script will function as normal in all ways EXCEPT it will not write any changes to the chat file."]},{"l":"Advanced Use","p":["While RegEx is commonly used as a simple Find/Replace tool, it can also be used in more complex ways.","For example the 'Replace With' box could include a set of CSS rules and HTML to add a specific styled HTML element into your chat whenever a certain word is found. This will require the Show tags in responses box to be unchecked in the User Settings panel.","The script can also be set to never trigger during normal use, but could instead be triggered via slash command as part of a logic check inside an STscript. The 'Replace With' box would include a unique value the script recognizes to indicate if a logic check is true or false. This expands the utility of RegEx to the full capabilities of all slash commands, allowing for truly unlimited levels of control and automation based on the contents of the chat."]}],[{"l":"Retrieval-based Voice Conversion (RVC)","p":["This guide will walk you through using RVC, a technique that allows transferring voice features from one audio clip to another, enabling voices to speak in different tones and styles.","Ever enjoyed those famous \"Presidents Play X\" videos? They were created using RVC. With the RVC extension, you can make your SillyTavern characters speak in any voice you desire, be it anime, movie, or even your own unique voice.","RVC is NOT TTS: it's more like speech-to-speech. It takes an audio clip as its input. In the background, what RVC does is work in tandem with SillyTavern's TTS extension: it waits for TTS to generate an audio file (which TTS would've done regardless of whether you use RVC or not), then RVC will perform a second pass that takes the TTS audio file and transforms it into the cloned voice from your RVC configuration."]},{"l":"RVC Setup","p":["SillyTavern's RVC supports several API sources that perform audio conversion:","rvc-python","SillyTavern Extras(deprecated)"]},{"l":"Common prerequisites","p":["Before you begin, ensure you've met the following prerequisites."]},{"l":"ffmpeg","p":["Make sure you have ffmpeg binary in your PATH environment variable. This tool is used to convert incoming audio.","Windows:","Use the Toolbox in SillyTavern Launcher script to install ffmpeg automatically: https://github.com/SillyTavern/SillyTavern-Launcher","Or download the build here: https://www.gyan.dev/ffmpeg/builds/","How to modify PATH variable: https://www.architectryan.com/2018/03/17/add-to-the-path-on-windows-10/","To test whether you did things correctly, open a command prompt and run ffmpeg. It should print the ffmpeg version and info.","Linux:","Install ffmpeg using your package manager.","macOS:","Install ffmpeg using Homebrew:"]},{"l":"Make sure TTS is enabled and works","p":["RVC depends on TTS, you need to enable a TTS extension. Your TTS has to be already working properly and narrating your chats before you try to add RVC to the mix!","Please note, that:","System TTS engine does not support voice conversion at all.","Streaming TTS will wait for the audio stream to end before conversion."]},{"l":"Install the extension","p":["Install the \"RVC\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Enable RVC in SillyTavern*","p":["In SillyTavern, navigate to Extensions> RVC and enable it."]},{"l":"Pick the source","p":["In the extension settings, choose an RVC source to use. Then proceed to the source-specific installation instructions."]},{"l":"rvc-python Setup"},{"l":"1. Install the package","p":["Follow the installation instructions from the GitHub page: rvc-python Installation. It is recommended to follow CUDA installation instructions if you have an Nvidia GPU.","If you're experiencing problems when installing on Windows (e.g. building fairseq step fails), make sure the following software is installed on your PC:","Windows 10 SDK","Visual Studio Build Tools 2022"]},{"l":"2. Prepare the models","p":["Create a directory for storing RVC models. By default it is named rvc_models and is picked up from your current directory when starting up the server. Every model is a subfolder (its name will be visible in the UI) that should contain .pth(required) and .index(optional) files.","Read more: rvc-python Model Management"]},{"l":"3. Start the API server","p":["Start the API server by running the following command:","Arguments:","5050- sets a listening port for the server. Change if you want to host on a different port.","models_path- sets a path for models. Remove if you want to use the default rvc_models directory.","-l- sets the server to listen on all network interfaces. Remove to only listen on localhost."]},{"l":"4. Connect to the server","p":["In the RVC extension settings, set an appropriate rvc-python API URL. By default, it will be http://localhost:5050.","Check the Use CUDA checkbox if you have installed rvc-python to support CUDA acceleration.","Press \"Refresh\" to load a list of available voices."]},{"l":"5. Configure a voice map","p":["Voice map defines voice conversion settings for every character or user persona.","To set up a voice map, choose your character or persona name from the \"Character\" dropdown, then choose an RVC \"Voice\", then click Apply.","Optionally, you can also configure other related settings such as pitch correction or filtering.","If you did everything correctly, the Voice Map debug area will show something like 'Betty:MyVoice(rvpme)'."]},{"l":"SillyTavern Extras Setup"},{"l":"1. Prepare RVC Model Files","p":["In a file browser, navigate to: \\SillyTavern-extras\\data\\models\\rvc.","Create a subfolder like 'Betty' and place the .pth and .index files into it. (Hint: you can download voice files from https://voice-models.com, make sure the voice name says it's RVPME.)"]},{"l":"2. Install Requirements","p":["Install the necessary requirements using the command:"]},{"l":"3. Run SillyTavern-extras with RVC enabled","p":["Launch SillyTavern-extras with the RVC module enabled. This example invocation assumes you used Edge TTS which comes pre-installed with SillyTavern-extras:","Optionally, you may wish to run RVC on your GPU if you have a capable one, by adding --cuda to the startup command. Based on a quick test, VRAM usage was 3.4GB for narrating 50 tokens (~ 36 words), and 7.6GB for 200 tokens (~ 150 words)."]},{"l":"4. Set Up Voice Mapping","p":["Create a Voice map for RVC. Set your Character to your desired SillyTavern character name, and set Voice to the RVC folder you created at step 1, then click Apply. If you did things correctly, the Voice Map will show something like 'Betty:MyVoice(rvpme)'."]},{"l":"5. Select Pitch Extraction","p":["Choose \"rmvpe\" as the pitch extraction method.","If you have trouble with \"rmvpe\" try other methods (for example, \"harvest\" or \"torchcrepe\")."]},{"l":"6. (Optional) Configure RVC to save your generations to file","p":["If for testing or troubleshooting purposes you wish to save the generated RVC audio, add --rvc-save-file to your startup command. This will save the last generation under SillyTavern-extras/data/tmp/rvc_output.wav:"]},{"l":"Expression-Based Dynamic Voice"},{"l":"1. Configure RVC Models","p":["In your RVC model folder, have separate .pth and .index files for each classified expression (e.g., anger, fear, joy, love, sadness, surprise)."]},{"l":"2. Enable Modules","p":["Enable both RVC and classify modules:"]},{"l":"3. Use RVC Module","p":["The remaining setup is similar to using the RVC module alone (as explained above)."]},{"l":"Train Your Own RVC Model"},{"l":"Using RVC Easy Menu by Deffcolony (Windows Only)","p":["Automatically install and launch Mangio-RVC: https://github.com/deffcolony/rvc-easy-menu"]},{"l":"1. Clone Repository","p":["Clone the repository to your desired location:"]},{"l":"2. Launch RVC-Launcher.bat","p":["Open the RVC-Launcher.bat file.","Choose option 1 to install RVC."]},{"l":"3. Complete Installation","p":["When prompted, install required packages and dependencies."]},{"l":"4. Open WebUI for Voice Training","p":["After installation, choose option 2 to open the WebUI for voice training."]},{"l":"Mangio-RVC: Training a Voice Model","p":["1. Access Training Tab:","1. Prepare Audio:","2. Configure Experiment:","3. Process Data and Extract Features:","4. Training Parameters:","Click \"Process data\" and \"Feature extraction\".","Click \"Train feature index\" and \"Train model\".","Click on the training tab in the WebUI.","Dataset Preparation:","Ensure the audio is free of background noise – only raw voice is needed.","Enter an experiment name (e.g., my-epic-voice-model).","Longer audio makes a better output quality.","Place the audio you want to train in the datasets folder.","Set \"Save frequency\" to 50.","Set \"Total training epochs\" to 300.","Set version to v2.","WebUI Training:"]}],[{"l":"Speech Recognition","p":["This guide will walk you through setting up speech recognition to transcribe your voice into text within SillyTavern."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest version of SillyTavern.","Install the \"Speech Recognition\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon).","Have ffmpeg binary installed. See RVC setup for more details."]},{"l":"Speech Recognition Setup (Browser)","p":["Append: Your message will be appended to the current user message text area.","Auto send: Your message will automatically be sent once the end of speech is detected.","Choose the \"Message Mode\" you want:","Choose the language you want to speak (Note: not every browser supports all languages).","Configure SillyTavern:","Enable Message Mapping(Optional):","For instance, by adding \"command delete = /del2\", the \"/del2\" command will replace your voice message when \"command delete\" is detected.","If your browser doesn't support voice recognition, an error popup will appear.","Launch SillyTavern and go to Extensions> Speech Recognition.","Recording:","Replace: Your message will replace the current user message in the text area.","Select \"Browser\" from the dropdown options.","Select Language:","Select Message Mode:","Setup phrases mapping for vocal shortcuts.","To start recording, click the microphone button to the right of the message area next to the send button. Click again to stop recording. Recording may stop automatically if no voice is detected.","Useful when combined with auto send mode for full voice control. Enable this by checking \"Enable messages mapping\"."]},{"l":"Speech Recognition Setup (Whisper/Vosk)","p":["Enable Provider:","Enable the desired speech recognition provider on the extras server using the following command:","or","You can also use a custom model by adding the option --stt-vosk-model-path or --stt-whisper-model-path with the path to the model.","Configure SillyTavern:","Launch SillyTavern and go to Extensions> Speech Recognition.","Select \"Vosk\" or \"Whisper\" from the dropdown options (whisper is more accurate).","The settings are similar to the \"Browser\" provider setup (except for language) see above."]},{"l":"Speech Recognition Setup (Streaming)","p":["Enable Provider:","Enable the streaming speech recognition module on Sillytavern-extras with the following command:","Configure SillyTavern:","(Optional) Specify a custom Whisper model as in the Whisper setup above.","(Optional but recommended) Set up trigger words in SillyTavern. Only messages starting with these trigger words will be sent to SillyTavern as actual messages. This prevents random speech or noise from being transcribed. Enable this with the checkbox. The trigger words can be included/excluded from the actual message using a checkbox.","Other settings are similar to other providers.","You're now ready to transcribe your voice into text using speech recognition in SillyTavern."]}],[{"l":"Summarize"},{"l":"What is it?","p":["This extension allows you to create, store, and utilize automatically generated summaries based on the events happening in your chats. Summarization can help with outlining general details of what is happening in the story, which could be interpreted as a long-term memory, but take that statement with a grain of salt. Since the summaries are generated by language models, the outputs may lose some important details or contain hallucinations, so you're always advised to keep track of the summary state and correct it manually if needed."]},{"l":"Common configuration","p":["The summarization extension is installed in SillyTavern by default, thus it will show up in ST's Extensions panel (stacked cubes icon) list like this:","Summarize Config Panel","Current summary- displays and provides an ability to modify the current summary. The summary is updated and embedded into the chat file's metadata for the message that was the last in context when the summary was generated. Deleting or editing a message from the chat that has a summary attached to it, will revert the state to the last valid summary.","Restore Previous- removes the current summary, rolling it back to the previous state. This is useful if the summarizer does a poor job at any given point.","Pause- check this to prevent the summary from being automatically updated. This is useful if you want to provide a custom summary of your own or to effectively disable the summary by clearing the box and stopping updates.","Popup window- allows to detach the summary into a movable UI panel on the sidebar. Useful for the desktop layout to easily have access to summarization settings without having to navigate through the extensions menu.","Injection Template- defines how the summary will be wrapped when being inserted into regular chat prompts. A special {{summary}} macro should be used to denote the exact location of the current summary state in the prompt injection text.","Injection Position- sets the location of the prompt injection. The options are the same as for Author's Notes: before or after the main prompt, or in-chat at designated depth."]},{"l":"Supported summary sources"},{"l":"Main API","p":["Summarization will be powered by your currently selected AI backend, model and settings. This method requires no additional setup, just a working API connection.","This option has the following sub-modes that differ depending on how the summary prompt is built:","Raw, blocking. The summary will be generated using nothing but the summarization prompt and the chat history. Subsequent prompts will also include the previous summary with messages that were sent after the summary was generated (see example). This mode can (and will) generate prompts that have a lot of variability between them, so it is not recommended to use it with backends that have slow prompt processing times, such as llama.cpp and its derivatives.","Raw, non-blocking. Same as above, but the chat generation will not be blocked during the summary generation. Not every backend supports simultaneous requests, so switch to blocking mode if summarization fails.","Classic, blocking. The summarization prompt will be sent at the end of your usual generation prompt, as a neutral system instruction, not omitting the character card, main prompt, example dialogues and other parts of chat prompts. This usually results in prompts that play nicely with reusing processed prompts, so it is recommended to use with llama.cpp and its siblings."]},{"l":"Summary Settings explained","p":["Summary Prompt- defines the prompt that will used for creating a summary. May include any of the known macros, as well as a special {{words}} macro (see below).","Target summary length (words)- defines the value of the {{words}} macro that can be inserted into the Summary Prompt. This setting is completely optional and has no effect at all if the macro is not used.","API response length (tokens)- allows to set an override API response length for generating summaries that are different from the globally set value.","Max messages per request (raw modes only)- set to limit the maximum number of messages that will be included in one summarization prompt. 0 means no explicit limitation, but the resulting number of messages to summarize will still depend on the maximum context size, calculated using the formula: max summary buffer = context size - summarization prompt - previous summary - response length. Use this when you want to get more focused summaries on models with large context sizes.","No WI/AN- omit World Info and Author's Note from text to be summarized. Only has an effect when using the Classic prompt builder. The Raw prompt builder always omits WI/AN.","Update every X messages- sets the interval at which the summary is generated. 0 means that the automatic summarization is disabled, but you can still trigger it manually by clicking the \"Summarize now\" button. This should be adjusted based on how quickly the prompt buffer entirely fills with chat messages. Ideally, you'd want to have the first summary generated when the messages are starting to get dropped out of the prompt.","Update every X words- same as above, but using words (not tokens!) instead of messages, theoretically can be a more accurate measurement due to how unpredictable the contents of chat messages usually are, but your mileage may vary.","If both \"Update every\" sliders are set to a non-zero value, then both will trigger summary updates at their respective intervals, depending on what happens first. It is strongly advised to update these values accordingly when you switch to another model that has differing context sizes, otherwise, the summary generation may trigger too often, or never at all.","If you're unsure about the interval settings, you can click the \"magic wand\" button above the \"Update every\" sliders to try and guess the optimal values based on some simple heuristics. A brief description of the algorithm is as follows:","Calculate token and word counts for all chat messages","Determine target summary length based on desired prompt words","Calculate the maximum number of messages that can fit in the prompt based on the average message length","If \"Max messages\" is set, adjust the average to account for messages that don't fit the summary limit","Round down the adjusted average messages per prompt to a multiple of 5"]},{"l":"Example prompts","p":["Raw prompt","Classic prompt"]},{"l":"Extras API","p":["Extras server with the summarize module could run an auxiliary summarization model (BART).","It has a very small context size (~ 1024 tokens), so its ability to handle large summaries is quite limited.","To configure the Extras summary source, do the following:","Install or Update Extras to the latest version.","Run Extras with the summarize module enabled: python server.py --enable-modules=summarize"]},{"l":"Changing Summary Model","p":["By default, Summarize uses the Qiliang/bart-large-cnn-samsum-ChatGPT_v3 model for summarization purposes.","This can be changed by using the command line argument --summarization-model=(###Hugging-Face-Model-URL-Here###)","A known alternate Summarize model is Qiliang/bart-large-cnn-samsum-ElectrifAi_v10."]}],[{"l":"TTS","p":["SillyTavern has a wide range of TTS options. This page explains the setup and use."]},{"l":"What is it?","p":["TTS is used to have a voice narrate parts of your chat."]},{"l":"Configuring TTS"},{"l":"TTS Provider Selectbox","p":["Used to select which TTS service you want to use.","ElevenLabs- paid subscription required, highest quality voices available at present.","Silero- free, runs on your PC, quality can vary widely","System- uses your OS TTS engine, if one exists. Quality can vary widely depending on the OS.","Edge- free, runs via Azure, generally quite fast, and voices feel natural but dry and emotionless. Like listening to the evening news or a radio announcer. When running with \"Plugin\" selected as the provider, you also need to install this server plugin, otherwise the TTS won't work.","Coqui-TTS- free, No API Implementation at this time. High-performance Text2Speech models (Tacotron, Tacotron2, Glow-TTS, SpeedySpeech) as well as Bark.","Novel- requires a paid NovelAI subscription, generated by NovelAI's TTS engine","RVC- free, voice cloning"]},{"l":"Checkboxes","p":["\"Good evening, senpai\"","\"Good evening, senpai\", she says.","\"nya\"... \"Good evening, senpai\"","Auto Generation- lets TTS start playing automatically when a new message enters the chat","Cohee approaches you with a faint \"nya\" \"Good evening, senpai\", she says.","Disabled","Enabled","Enabled- turns TTS playback on/off","Given the example text: *Cohee approaches you with a faint nya* Good evening, senpai, she says. Here's a table showing how the text will be modified based on the boolean states of Ignore *text, even \"quotes\", inside asterisks* and Only narrate \"quotes\":","having both \"only narrate quotes\" and \"ignore asterisks\" checkboxes both checked will result in the TTS only reading \"quotes\" which are not in asterisks, and ignoring everything else.","Ignore *text, even \"quotes\", inside asterisks*","Ignore *text, even \"quotes\", inside asterisks*- TTS will not play any text within *asterisks*, even \"quotes\" (internal variable name = narrate_dialogues_only)","Narrate only the translated text- this will make the TTS only narrate the translated text.","Only narrate \"quotes\"","Only narrate \"quotes\"- Limits TTS playback to only include text within quotation marks. This will *include quotes within asterisk lines*(internal variable name = narrate_quoted_only)","Output"]},{"l":"Sliders","p":["These will change depending on the API you select.","(explanation coming soon)"]},{"l":"Buttons","p":["Apply- this must be clicked after setting a TTS API and after editing the voice map.","Available voices- loads a popup with all voices available for your selected API, and lets you preview them with sample dialogues."]},{"l":"Using TTS","p":["Click the \"Enable\" checkbox, or nothing will ever happen.","Click the \"Auto-generation\" checkbox if you want the TTS to start automatically every time a new message arrives in chat.","Optionally, click the megaphone icon inside the top-right of any message to playback on demand.","Click the lower right \"Stop\" button (found inside the wand menu) to stop any playback."]},{"l":"Voice Map","p":["You must provide a voice map for the TTS to use, otherwise, it won't know what voices should be used for each character.","These must be in the exact format stated below:","CharacterName:TTSVoice,CharacterName2:TTSVoice2","For Coqui-TTS the format needs to include the speaker and language from the WebGUI:","CharacterName:TTSVoice[speakerid][langid] or Aqua:tts_models--multilingual--multi-dataset--your_tts\\model_file.pth[2][1]"]},{"l":"Bark ZeroShot Voice Cloning Speakers","p":["If using Bark you must create a voice folder with a voice file to clone. Ensure you add voices to homedir\\tts\\bark_v0\\speakers. On Windows it is probably C:\\Users\\USERACCOUNT\\AppData\\Local\\tts\\bark_v0\\speakers\\ type %appdata% in windows explorer then go UP a directory to local and you should see tts.","The directory should look like this:","homedir","tts","bark_v0","speakers","customvoice1","speaker.wav","speaker.npz","robinwilliams","speaker.mp3","me","One first load of this model and voice bark will clone the voice and create a .npz file, this is needed for faster TTS."]}],[{"l":"AllTalk TTS V2","p":["AllTalk is a voice cloning system based on Coqui XTTS, F5-TTS, VITS, Piper and other TTS model engines, designed to produce high-quality voice reproduction (either zero shot voice cloning or built-in voices). In AllTalk V2, significant updates enhance functionality and ease of use, including multiple TTS engine support, expanded customization, and performance optimizations. For a comprehensive list of features, refer to the AllTalk Wiki here."]},{"l":"\uD83D\uDFE9 Key Features in AllTalk V2","p":["Multi-engine Support: Easily switch between Coqui XTTS, VITS, Piper, Parler, F5, and custom engines.","Voice Conversion (RVC): Enhanced retrieval-based voice cloning pipeline.","Customizable Settings: Adjust per-engine settings and save startup configurations.","Narrator Functionality: Specify separate voices for narration and characters.","Standalone and Integrated Use: Seamless integration with SillyTavern.","DeepSpeed and Low VRAM Modes: Performance optimization for resource-limited environments.","Screenshots: See AllTalk V2’s interface here."]},{"l":"\uD83D\uDFE8 Setup and Installation Options","p":["AllTalk offers both standalone and integrated installation methods. The fastest setup involves using one of the quick installation options provided, with scripts automating most of the process.","Standalone Installation: Recommended for most users ( Standalone Guide)","Text-generation-webui Integration: For integration into Text-generation-webui ( TGWUI Installation Guide)"]},{"l":"\uD83D\uDFE9 Automated Installation","p":["This method is for Windows users only. For new users who want a quick setup, the automated installation uses the SillyTavern-Launcher. Note: This assumes you have already installed the SillyTavern-Launcher. If you haven’t, visit https://github.com/SillyTavern/SillyTavern-Launcher and follow the instructions in the readme.md file to install it. Once the SillyTavern-Launcher is installed:","Run Launcher.bat","Go to: Home Toolbox App Installer Voice Generation","Select the option labeled: Install AllTalk V2"]},{"l":"\uD83D\uDFE9 Manual Installation","p":["For advanced users requiring detailed control, follow the Manual Installation Guide for a step-by-step setup on Windows, Linux, or Mac (untested)."]},{"l":"\uD83D\uDFE9 Google Colab Installation","p":["Run AllTalk in a cloud environment with the Google Colab Installation for users who prefer not to install locally."]},{"l":"\uD83D\uDFE8 Using AllTalk within SillyTavern","p":["Once AllTalk is loaded, select it within SillyTavern on the TTS page, ensuring to select the correct AllTalk server version in the settings.","Settings Management: AllTalk may enable or disable specific settings based on your selected configuration.","Loading Sequence: If SillyTavern is loaded before AllTalk, reload the TTS extensions page.","Performance Optimization: Enable DeepSpeed and Low VRAM modes selectively to improve performance based on system resources.","Narrator function: Details of the Narrator function can be found on the AllTalk Wiki.","Full details of the SillyTavern AllTalk Extension will be updated on the AllTalk Wiki page for SillyTavern","TGWUI Users who user the AllTalk extension for TGWUI need to disable Enable TGWUI TTS in the TGWUI chat interface, otherwise you will have duplicate TTS audio generated."]},{"l":"\uD83D\uDFE8 Troubleshooting","p":["If you experience issues that you believe are specific to AllTalk within SillyTavern, please refer to the AllTalk Wiki page for SillyTavern for the lastest information."]},{"l":"\uD83D\uDFEA Support, Assistance, and Feature Requests","p":["For further assistance:","Refer to the Wiki and built-in documentation.","Join discussions on the Discussion Board.","Submit bugs or feature requests through the Issue Tracker."]}],[{"l":"XTTS with voice cloning","p":["Greetings! So, you've been blown away by those Reddit posts showcasing how far the technology went for the AI text-to-speech?","Feeling excited to give your robotic waifu/husbando a new shiny voice modulator?","Fear not, this stunning groundbreaking technology is already available at your local SillyTavern, you just need a simple..."]},{"l":"Prerequisites","p":["Latest version of SillyTavern.","Miniconda installed.","(Windows) Visual C++ Build Tools installed.","WAV files with voice clips to clone from (~ 10 seconds per file). File requirements: PCM, Mono, 22050Hz, 16-bit (convert via Audacity).","Create a folder with \"speakers\" and \"output\" subfolders. Put WAV files into \"speakers\".","Example folder structure:"]},{"l":"Installing","p":["daswer123 made an API server that runs the XTTSv2 model on your computer and connects to SillyTavern's TTS extension.","It's completely independent of Extras API and would use a separate environment.","Very important: Don't install the following requirements to your Extras environment or system Python. It will break your other packages, do unnecessary downgrades, etc.","The following instruction is provided using Miniconda, but you can also do it with venv (not covered here). Open the Anaconda command prompt and follow the instructions line by line."]},{"l":"Getting the server up and running","p":["Navigate to the folder you've created at step 4 of prerequisites.","Create a new conda env. From now on, we'll call it xtts.","Activate a newly created env.","Install Python 3.10 to your env. Confirm with \"y\" when prompted.","Install the XTTS server with its requirements.","Install PyTorch. This can take some time. The following line installs PyTorch with GPU acceleration support (CUDA). If you want to use just the CPU inference, drop the last part that starts with --index-url.","Start the XTTS server on the default host and port: http://localhost:8020","During your first startup, the model will be downloaded (about ~ 2 GB). Don't forget to read the legal notice from Coqui AI very carefully. Lol, I'm kidding, just hit \"y\" again."]},{"l":"Connecting to SillyTavern","p":["Open the extensions panel, expand the TTS menu, and pick \"XTTSv2\" in the provider list.","Choose your text-to-speech language in the Language dropdown (I'll be sad if it's not Polish).","Verify that the provider endpoint points to http://localhost:8020 and \"Available voices\" shows a list of your voice samples.","Pick any character and set a mapping between the voice sample and the character. If the characters list is empty, hit \"Reload\" a couple of times.","Configure the rest of the TTS settings according to your preferences."]},{"l":"You're all set now!","p":["Click on the bullhorn icon in the context actions menu for any message and hear the beautiful cloned voice emanating from your speakers. The generation takes some time and it's not real-time even on high-end RTX GPUs."]},{"l":"Streaming?","p":["It's possible to use HTTP streaming with the latest version of the XTTS server to get the chunks of generated audio as soon as it is available!"]},{"l":"This doesn't work with RVC!","p":["The audio will still be generated (assuming you're using the latest version of the RVC extension) and converted, but not streamed as RVC requires to have the full audio file before initiating the conversion. Streamed RVC is still being investigated..."]},{"l":"How to get streaming support?","p":["Update SillyTavern to the latest version.","Update the XTTS server to the latest version.","Start and connect XTTS to ST as usual.","Enable the \"Streaming\" XTTS extension setting in SillyTavern."]},{"l":"Choppy audio?","p":["Try increasing the \"chunk size\" setting.","For reference: with a chunk size of 200, RTX 3090 can produce uninterrupted audio at the cost of slightly increased audio latency."]},{"l":"How to restart the TTS server?","p":["Just do steps 1, 3 and 7 from the installation instruction."]},{"l":"Android??","p":["Unlikely, it can't run apps that require PyTorch without some arcane black magic that we don't provide support for. You can try it out at your own risk, but no support will be provided if you face any problems.","Your best solution is to host the TTS API on your PC over the local network, just don't forget to specify the host and port to listen on - see README."]}],[{"l":"VRM","p":["This guide will walk you through the process of setting up and customizing the VRM extension for your SillyTavern experience. This extension allows you to use VRM animated models for your character, providing a dynamic and interactive element to your virtual character."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Branch Selection: Make sure you're using the latest version branch of SillyTavern to access the latest features and updates.","Extension Installation: Install the \"VRM\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (represented by the stacked blocks icon).","Model Folder Placement: Place your VRM model files (.vrm) into the /data/user-handle/assets/vrm/model directory and your animation files into the /data/user-handle/assets/vrm/animation directory. The currently supported animation file format are .fbx and .bvh that are compatible with VRM models. This include any animation you can get from Mixamo ( https://www.mixamo.com/) and any animation you can export from tools like XR Animator ( https://github.com/ButzYung/SystemAnimatorOnline)."]},{"l":"Extension Settings","p":["The VRM extension offers various settings to customize the behavior of your animated model. Here are the key settings:","UI global settings"]},{"l":"Global Settings","p":["Enabled:","Enable this checkbox to activate the extension, allowing your VRM model to interact within SillyTavern.","You can disable the extension if you want to use normal sprites only.","Look at camera:","Enable this checkbox to make the VRM model eyes look at the camera.","Blink:","Enable this checkbox to make the VRM model eyes blink at random intervals. Model expressions should define properly blinking weight property otherwize model can blink with closed eyes for example, if that happens either:","correct the model if you have the .vroid file","don't use that incorrect face experession","disable blinking completly with this checkbox","TTS Lip sync","Enable this checkbox to have the VRM mouth movement follow the sound of your TTS when it's played. Only work with TTS whose sound is played by Sillytavern itself like XTTS (not in streaming mode). If disabled, mouth will be animated according to the message text length when a new character message is received.","Auto-send Interaction:","Enable this checkbox to automatically trigger character interactions when you click on areas with mapped messages (refer to the hit areas section for details)."]},{"l":"Performances Settings","p":["Body hitboxes","Enable this checkbox to activate detection of click on several part of the VRM model depending on the model the following area can be detected: head/chest/hands/groin/butt/legs/feets. Hitboxes location are computed at each frames and follow the body animation, disabling this option can improve performance.","Use model cache","Enable this checkbox to keep in memory VRM model when switching models, allows to switch back to previous model faster. Usefull if you use different model for the same character to change outfit or form for example. Can affect performance.","Use animation cache","Enable this checkboxx to keep in memory all animations played during the session. All animation assigned to a model will also be loaded the first time the model appear. Will increase the time you load the model the first time but make all animation switch instant. Can affect performance."]},{"l":"Debug Settings","p":["Show grid","Enable this checkbox to visualize the 3d grid, model dragging box and body hitboxes.","Reload button","Click this button to reload the 3d scene, clear the cache and all VRM models. Use it if some bug occurs or if cache starts to hit performance."]},{"l":"Scene Settings","p":["UI scene settings","Light Color","Set the color of the light in the 3d scene. Click on the reset button to set it back to the default white color. Depending on your browser you can use a color picker, for example you can color pick the color of your background image to add more immersion.","Light intensity","Set the light intensity in percent using the slider. Click on the reset button to set it back to the default value of 100%. VRM model can react differently to light depending on the baked shaders into the model, play with the value and see how it goes.","UI model settings"]},{"l":"Character Selection","p":["These settings allow you to manage characters and assign VRM models to them.","Refresh Button:","Click the refresh button to update the list of characters in the current chat.","Select Character:","Use the drop-down list to choose a character to assign a VRM model to.","Remove Button:","Click this button to delete the assigned model for a character."]},{"l":"Model Selection","p":["Refresh Button:","Click the refresh button if your VRM model does not appear in the list.","Select Model:","Choose a model from the list to assign it to the selected character.","The model has to be located in /data/user-handle/assets/vrm/model directory.","Reset button","Click this button to reset the model settings to its default. If you have animation files that correspond to the default value they will be auto mapped. See the naming mapping at the end of this README."]},{"l":"Model Settings","p":["Model Scale:","Use the slider to adjust the size of the model, making it larger or smaller.","Model Center X/Y Offset:","Use those sliders to change the horizontal/vertical position of the model relative to the window center.","Model X/Y Rotation","Use those sliders to change the horizontal/vertical rotation of the model relative to the model hips."]},{"l":"Remarks","p":["UI hitboxes settings"]},{"l":"Hitboxes mapping","p":["UI classify settings"]},{"l":"Classified Expressions Mapping","p":["Requirements","Requires the use of the classify expression extension; otherwise, it will fallback to the default animation.","Mapping","For each detected emotion by the classify extension, you can assign an expression/motion/message. The message can contain commands."]},{"l":"Commands","p":["\"/vrmmotion idle\" or \"/vrmmotion character=Seraphina motion=idle loop=true random=false\"","/vrmexpression","/vrmlightcolor","/vrmlightintensity","/vrmmodel","/vrmmotion","arguments: character, expression","arguments: character, model","arguments: character, motion, loop, random","arguments: color","arguments: intensity","assign the vrm model to the character","change the animation of the model","change the expression of the model","example: \"/vrmexpression happy\" in solo chat or \"/vrmexpression character=Seraphina expression=happy\" in group chat","example: \"/vrmlightcolor white\" or \"/vrmlightcolor purple\".","example: \"/vrmlightintensity 0\" or \"/vrmlightintensity 100","example: \"/vrmmodel Seraphina.vrm\" in solo chat or \"/vrmmodel character=Seraphina model=Seraphina.vrm\" in group chat","set the light color","set the light intensity in percent"]},{"l":"Animations default mapping","p":["If your animation file are named in the following way they will be mapped automatically when reseting a model settings. For example the files named \"assets/vrm/animation/neutral.bvh\" and \"assets/vrm/animation/neutral1.fbx\" will be automatically mapped as a group for default and neutral classified animation. Same goes for the hitboxes.","Thank you for following this guide! Your SillyTavern experience is now enriched with animated and interactive 3D models."]},{"i":"remarks-1","l":"Remarks"}],[{"l":"Web Search","p":["Adds web search results to LLM prompts.","Some Chat Completion sources provide built-in web search functionality. In this case, this extension will be largely redundant. Check the AI Response Configuration panel for the \"Enable web search\" toggle. For example, this is available for Claude, Google AI Studio / Vertex AI, xAI, and OpenRouter backends."]},{"l":"Available sources"},{"l":"Selenium Plugin","p":["Requires an official server plugin to be installed and enabled.","See SillyTavern-WebSearch-Selenium for more details.","Supports Google and DuckDuckGo engines."]},{"l":"Extras API","p":["Requires a websearch module and Chrome/Firefox web browser installed on the host machine.","Supports Google and DuckDuckGo engines."]},{"l":"SerpApi","p":["Requires an API key.","Get the key here: https://serpapi.com/dashboard"]},{"l":"SearXNG","p":["Requires a SearXNG instance URL (either private or public). Uses HTML format for search results.","SearXNG preferences string: obtained from SearXNG - preferences - COOKIES - Copy preferences hash","Learn more: https://docs.searxng.org/"]},{"l":"Tavily AI","p":["Requires an API key.","Get the key here: https://app.tavily.com/"]},{"l":"KoboldCpp","p":["KoboldCpp URL must be provided in Text Completion API settings. KoboldCpp version must be >= 1.81.1 and WebSearch module must be enabled on startup: enable Network => Enable WebSearch in the GUI launcher or add --websearch to the command line.","See: https://github.com/LostRuins/koboldcpp/releases/tag/v1.81.1"]},{"l":"Serper","p":["Requires an API key.","Get the key here: https://serper.dev/"]},{"l":"How to use","p":["Make sure you use the latest version of SillyTavern.","Install the extension via the \"Download Extensions & Assets\" menu in SillyTavern.","Open the \"Web Search\" extension settings, set your API key or connect to Extras, and enable the extension.","The web search results will be added to the prompt organically as you chat. Only user messages trigger the search.","To include search results more organically, wrap search queries with single backticks: Tell me about the `latest Ryan Gosling movie`. will produce a search query latest Ryan Gosling movie.","Optionally, configure the settings to your liking."]},{"l":"Settings"},{"l":"General","p":["Enabled - toggles the extension on and off.","Sources = sets the search results source.","Cache Lifetime - how long (in seconds) the search results are cached for your prompt. Default = one week."]},{"l":"Prompt Settings","p":["Prompt Budget - sets the maximum capacity of the inserted text (in characters of text, NOT tokens). Rule of thumb: 1 token ~ 3-4 characters, adjust according to your model's context limits. Default = 1500 characters.","Insertion Template - how the result gets inserted into the prompt. Supports the usual macro + special macro: {{query}} for search query and {{text}} for search results.","Injection Position - where the result goes in the prompt. The same options as for the Author's Note: as in-chat injection or before/after system prompt."]},{"l":"Search Activation","p":["Use function tool - uses function calling to activate search or scrape web pages. Must use a supported Chat Completion API and be enabled in the AI Response settings. Disables all other activation methods when engaged.","Use Backticks - enables search activation using words encased in single backticks.","Use Trigger Phrases - enables search activation using trigger phrases.","Regular expressions - provide a JS-flavored regex to match the user message. If the regex matches, the search with a given query will be triggered. Search query supports `` and $1-syntax to reference the matched group. Example: /what is happening in (.*)/i regex for search query news in $1 will match a message containing what is happening in New York and trigger the search with the query news in New York.","Trigger Phrases - add phrases that will trigger the search, one by one. It can be anywhere in the message, and the query starts from the trigger word and spans to \"Max Words\" total. To exclude a specific message from processing, it must start with a period, e.g. .What do you think?. Priority of triggers: first by order in the textbox, then the first one in the user message.","Max Words - how many words are included in the search query (including the trigger phrase). Google has a limit of about 32 words per prompt. Default = 10 words."]},{"l":"Page Scraping","p":["Visit Links - text will be extracted from the visited search result pages and saved to a file attachment.","Visit Count - how many links will be visited and parsed for text.","Visit Domain Blacklist - site domains to be excluded from visiting. One per line.","File Header - file header template, inserted at the start of the text file, has an additional {{query}} macro.","Block Header - link block template, inserted with the parsed content of every link. Use {{link}} macro for page URL and {{text}} for page content.","Save Target - where to save the results of scraping. Possible options: trigger message attachments, or chat attachments of Data Bank, or just images (if the source supports them).","Include Images - attach relevant images to the chat. Requires a source that supports images (see below)."]},{"l":"More info","p":["Search results from the latest query will stay included in the prompt until the next valid query is found. If you want to ask additional questions without accidentally triggering the search, start your message with a period.","Web Search function tool always overrides other triggers if enabled and available.","Priority of triggers (if multiple are enabled):","Backticks.","Regular expressions.","Trigger phrases.","To discard all previous queries from processing, start the user message with an exclamation mark, for example, a user message !Now let's talk about... will discard this and every message above it.","This extension also provides a /websearch slash command to use in STscript. More info here: STscript Language Reference"]},{"l":"What can be included in the search result?","p":["Thesaurus:","Answer box: Direct answer to the question.","Knowledge graph: Encyclopedic knowledge about the topic.","Page snippets: Relevant extracts from the web pages.","Relevant questions: Questions and answers to similar topics.","Images: Relevant images."]},{"i":"serpapi-1","l":"SerpApi","p":["Answer box.","Knowledge graph.","Page snippets (max 10).","Relevant questions (max 10).","Images (max 10)."]},{"l":"Selenium Plugin and Extras API","p":["Google - answer box, knowledge graph, page snippets.","DuckDuckGo - page snippets.","Selenium Plugin can additionaly provide images."]},{"i":"searxng-1","l":"SearXNG","p":["Infobox.","Page snippets.","Images."]},{"i":"tavily-ai-1","l":"Tavily AI","p":["Answer.","Page contents.","Images (up to 5)."]},{"i":"koboldcpp-1","l":"KoboldCpp","p":["Page titles.","Page snippets."]},{"i":"serper-1","l":"Serper","p":["Answer box.","Knowledge graph.","Page snippets.","Relevant questions.","Images."]}],[{"l":"MiniMax TTS","p":["This page will teach you how to properly use the MiniMax TTS provider."]},{"l":"Prerequisites","p":["MiniMax account with API access","Valid API Key and Group ID from MiniMax"]},{"l":"Getting API Credentials"},{"l":"1. Create a MiniMax Account","p":["Visit the MiniMax website (International)","Click \"Sign Up\" or \"Login\"","Complete the account registration process","MiniMax has separate Chinese and International versions. Please note:","The Chinese version does not support voice cloning features","The Chinese version only supports the api.minimax.chat API host"]},{"l":"2. Obtain API Key and Group ID","p":["Log into the MiniMax console (International)","You can find your GroupId on the Basic Information page","Go to Settings → API Keys on the left sidebar to create and obtain your API Key"]},{"l":"Configuration in SillyTavern"},{"l":"1. Basic Setup","p":["Open SillyTavern","Navigate to \"Extensions\" → \"TTS\"","Select \"MiniMax\" as your TTS provider","Configure the following settings:","API Key: Your MiniMax API key","Group ID: Your MiniMax Group ID","API Host: Choose the appropriate server based on your region:","api.minimax.io(Official international server)","api.minimaxi.chat(Another international server host)","api.minimax.chat(China mainland server)"]},{"l":"2. Model Selection","p":["Available models include:","Speech-02-HD: High-quality voice synthesis (recommended)","Speech-02-Turbo: Fast voice synthesis","Speech-01: Legacy model","Speech-01-240228: Legacy model (specific version)"]},{"l":"3. Voice Parameters","p":["Adjust the following parameters to customize voice output:","Speed: 0.5 - 2.0 (1.0 = normal speed)","Volume: 0.1 - 2.0 (1.0 = normal volume)","Pitch: 0.5 - 2.0 (1.0 = normal pitch)","Audio Format: MP3, WAV, FLAC"]},{"l":"Custom Voices"},{"l":"1. Obtaining Voice IDs","p":["Access the MiniMax TTS page (International)","Click \"Voice\" on the right side to enter the Voice Selection interface","Find the voice you want to use","Click the copy button next to the voice name to copy the Voice ID"]},{"l":"2. Adding Custom Voices","p":["In the MiniMax TTS settings, locate the \"Custom Voice Management\" section","Fill in the following information:","Voice Name: Choose any name for identification","Voice ID: The voice ID obtained from the MiniMax platform","Language: Select the corresponding language for the voice","Click \"Add Custom Voice\""]},{"l":"Custom Models"},{"l":"1. Adding Custom Models","p":["In the \"Custom Model Management\" section","Fill in:","Model ID: Model identifier","Model Name: Display name for the model","Click \"Add Custom Model\""]},{"l":"2. Obtaining Model IDs","p":["Check the model list in the official MiniMax documentation","Or view available custom models in the console","Copy the corresponding Model ID"]},{"l":"Troubleshooting"},{"l":"Common Issues","p":["API Authentication Failed","Verify that the API Key corresponds to the correct API Host","Confirm that the Group ID is correct","Check if your account has sufficient balance","Voice Generation Failed","Verify that the selected Voice ID is valid","Ensure the voice is compatible with your selected model","Connection Timeout","Try switching to a different API Host","Check your network connection","Verify firewall settings","Audio Quality Issues","Try using a different model (Speech-02-HD for best quality)","Adjust voice parameters (speed, pitch, volume)","Check audio format compatibility"]}],[{"l":"Extras","p":["The Extras project was discontinued in April 2024 and won't receive any new updates or modules. The vast majority of modules are available natively in the main SillyTavern application. You may still install and use it but don't expect to get immediate support if you face any issues."]}],[{"l":"Extras Installation","p":["This page contains instructions for installing SillyTavern Extras on your local device.","The Extras project was discontinued in April 2024 and won't receive any new updates or modules. The vast majority of modules are available natively in the main SillyTavern application. You may still install and use it but don't expect to get immediate support if you face any issues.","Local installation of Extras can be difficult or impossible on your OS (especially Termux)."]},{"l":"Use the Official Extras Colab","p":["Simple to setup","Free to use","No Colab GPU credits required (use the use_cpu options)","See the Colab Guide Page for details."]},{"l":"Running Extras in Colab","p":["API key will appear in the colab's console output, for example: Your API key is fee2f3f559","Click \"Connect\"","Click the Start button on the left (looks like a triangle 'play' button)","Copy the API URL link that is listed under that line. ( DO NOT copy the 'localhost' URL, use the other one)","If you have enabled the secure option, paste the generated API key into the API Key box.","If you have NOT enabled the secure option, make sure the API Key box is completely empty when using the official colab.","It will start with the text Running on","Look for the trycloudflare.com link at the bottom of the output. Ignore the localhost link, it won't work (we tried!).","Navigate to SillyTavern's Extensions menu (click the 'stacked blocks' icon at the top of the page).","Not required, but recommended: select the secure option to generate the API key to protect your shared instance.","Open the Official Extras Colab","Paste the API URL into the box at the top. ( NOT the API Key box)","Select the desired \"Extra\" options","select use_cpu to run Extras without requiring GPU credit","Start SillyTavern with extensions support: (set enableExtensions to true in your config.yaml if necessary)","this will make Stable Diffusion slower, but everything else will run normally","Wait for it to finish loading everything"]},{"l":"Local Installation Methods"},{"l":"MiniConda (recommended)","p":["(Chads who installed SillyTavern with git to begin with can skip this step!)","(Important!) Read how to use Conda","Activate the new environment","After you have both of them installed...","cd SillyTavern-extras","Clone the Extras GitHub repo","conda activate extras(you should see (extras) pop up on the left side of your command prompt)","conda create -n extras","conda install python=3.11 git","Create a new Conda environment (let's call it extras):","git clone https://github.com/SillyTavern/SillyTavern-extras","Install Extras' requirements by using one of the following commands (will take time, again):","Install git","Install Miniconda","Install the required system packages (this will take some time)","Navigate to your cloned Extras repo","pip install -r requirements-coqui.txt- for Coqui TTS (not recommended)","pip install -r requirements-rvc.txt- for real-time voice cloning","pip install -r requirements.txt- for basic features","See below 'Running Extras After Install'","See the Common Problems page if you get errors at this step!","This method is recommended because Conda makes a 'virtual environment' for the Extras requirement packages to live inside, so they do not affect your system-wide Python setup.","Type/paste the commands below ONE BY ONE IN THE CONDA COMMAND PROMPT WINDOW and hit Enter after each one."]},{"l":"System-Wide Installation","p":["This is easier, but will affect your system-wide Python installation.","This can cause conflicts if you work with many Python programs that have different requirements.","If this is your first time touching anything Python-related, that should not be a problem.","Install Python 3.11: https://www.python.org/downloads/release/python-3115/","Install git: https://git-scm.com/downloads","Open a command prompt window and go to a folder in which you have complete access permissions.","Clone the repo: git clone https://github.com/SillyTavern/SillyTavern-extras, hit Enter.","After the clone has finished, type cd SillyTavern-extras, hit Enter.","Type python -m pip install -r requirements.txt","See below 'Running Extras After Install'"]},{"l":"Running Extras After Install"},{"l":"Confirm extensions are enabled","p":["Open the file called config.yaml in a text editor. The file is located in ST's base install folder.","Look for the line that reads enableExtensions.","Make sure that line has true, and not false."]},{"l":"Decide which module to use","p":["(This only needs to be done once)","Below is a table that describes each module.","caption","chromadb","classify","Coqui TTS","coqui-tts","Decide which modules you want to add to your Python command line.","Description","edge-tts","Example: python server.py --enable-modules=caption,summarize,classify","Extras is always started with a Python command line.","Image captioning","Microsoft Edge TTS client","Name","NOTE: There must be no spaces at all in your Python command's module list!","python server.py is the bare minimum, but it does not enable any useful modules.","Real-time voice cloning","rvc","sd","Silero TTS server","silero-tts","Stable Diffusion image generation","summarize","Text sentiment classification","Text summarization","They will be used in the next step.","This would enable Image Captioning, Chat Summary, and live updating Character Expressions.","to enable modules you must use the --enable-modules= modifier, with a comma-separated list of module names","Vector storage server"]},{"l":"Start Extras Server","p":["While still in your command prompt window inside the Extras installation folder...","Make sure your conda environment is active (if you used the Conda install method)","Type activate extras if the environment is not active.","Type python server.py --enable-modules=YOUR,SELECTED,MODULE,LIST,HERE","The extras server will load.","After a while it will show you a URL at the end. For local installs, this defaults to http://localhost:5100.","Copy the API URL."]},{"l":"Connect ST to the Extras server","p":["Start your SillyTavern server, and view the SillyTavern interface in your browser.","Open the Extensions panel (via the 'Stacked Blocks' icon at the top of the page)","Paste the API URL into the input box.","Click Connect.","To run Extras again, simply activate the environment and run these commands in a command prompt.","conda activate extras, Hit Enter. python server.py, Hit Enter.","Be sure to the additional options for server.py (see below) that your setup requires."]},{"l":"Make a .bat File for Easy Startup","p":["This is Optional and only applies to Windows, but something similar should be possible on MacOS.","View your Windows Desktop","Right-click, select New, and then click Text Document","A new file will appear on your Desktop, asking for a name.","Name the file STExtras.txt","Open the newly created file in a text editor.","Paste the following code into it:","Replace the placeholder folder path with your actual Extras install folder path.","Replace the python command line with your actual command line","Save the file with a new name STExtras.bat(Use File>> Save As in most text editors)","You can now simply double-click on this .bat file to easily start Extras.","If you ever want to change the module list (or any other command line modifiers for the extras server), simply edit the python command inside the .bat file."]},{"l":"Extras Install Common Problems","p":["This section lists common questions and problems encountered while installing SillyTavern Extras."]},{"l":"Error: Could not import the 'talkinghead' module on Linux","p":["It requires the installation of an additional package because it's not installed automatically due to incompatibility with Colab. Run this after you install other requirements:","pip install wxpython"]},{"l":"Extras server can't connect to AUTOMATIC1111's Stable Diffusion Web UI","p":["Could not connect to remote SD backend at http://127.0.0.1:7860! Disabling SD module...","Make sure webui-user.bat that you start Stable Diffusion with contains --api command line option in the COMMANDLINE_ARGS variable.","Find and replace that line in your \"webui-user.bat\": set COMMANDLINE_ARGS=--api","How it should look","If the API mode is disabled for SD Web UI, the Extras server won't be able to make a connection and you won't be able to generate images!"]},{"l":"Still doesn't work?","p":["Ensure that you start everything in the proper order, waiting for every program to finish loading before proceeding to the next step:","Stable Diffusion Web UI","SillyTavern Extras","SillyTavern","The extras server can't reconnect to the Stable Diffusion API if it was loaded after."]},{"l":"hnswlib wheel building error when installing ChromaDB","p":["ERROR: Could not build wheels for hnswlib, which is required to install pyproject.toml-based projects","Before installing the ChromaDB module you must first do one of the following:","Install Visual C++ build tools: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Install the hnswlib package with conda: conda install -c conda-forge hnswlib"]},{"l":"Error when installing Python requirements on Mac","p":["ERROR: No matching distribution found for torch== 2.0.0+cu117","Mac does not support CUDA, so torch packages should be installed without CUDA support.","Install the requirements using the requirements-silicon.txt file instead."]},{"l":"Missing modules?","p":["You must specify a list of module names in your Python command line, with the --enable-modules modifier.","See Modules section."]},{"l":"What is the API Key box for?","p":["The API Key box in SillyTavern's Extensions panel is only used when you have:","created a text file named api_key.txt in your Extras install folder, which contains your chosen Extras 'password'.","started extras with the --secure commandline argument.","This makes the Extras API 'password locked', so only users who have that key in their API Key box can access it.","This is mainly useful for people who want to make their own public deployment of Extras (colab, etc).","Users running Extras on their own PC for personal use should not type anything into the API Key box."]},{"l":"What about mobile/Android/Termux? \uD83E\uDD14","p":["There are some folks in the community having success running Extras on their phones via Ubuntu on Termux.","However, Extras were not made with mobile support in mind.","No support will be provided for people running Extras on their Android devices.","Direct all your questions to the creator of the guide linked below instead."]},{"l":"❗ This is UNSUPPORTED","p":["https://rentry.org/STAI-Termux#downloading-and-running-tai-extras"]}],[{"l":"Smart Context"},{"l":"THIS EXTENSION IS NO LONGER MAINTAINED AND NOT RECOMMENDED TO USE. CONSIDER CHAT VECTORIZATION AS A POSSIBLE ALTERNATIVE.","p":["The use of this extension does not guarantee a better chatting experience or improved memory of any sort. Only use if you understand all the implications of vector database utilization."]},{"l":"What is it?","p":["Smart Context is a SillyTavern extension that uses the ChromaDB library to give your AI characters access to information that exists outside the normal chat history context limit."]},{"l":"How is that useful?","p":["If you have a very long chat, the majority of the contents are outside the usual context window and thus unavailable to the AI when it comes to writing a response.","Smart Context automatically takes the entire history of the chat file and puts it into a vector database. This database is then searched each time you input something new into the chat, and if messages with matching keywords are found, those chat messages are placed into the context so the AI can see them when writing its next reply."]},{"l":"Setup Instructions","p":["Update SillyTavern to at least version 1.10.6.","Install the \"Smart Context\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon).","Install or Update Extras to the latest version. Alternatively, use the Colab notebook.","Local installs only: Install requirements-complete.txt for Extras (even if you did it once before in a prior install).","Run Extras with the chromadb module enabled: python server.py --enable-modules=chromadb"]},{"l":"Getting an error when installing ChromaDB?","p":["Installing chromadb package requires one of the following:","Have Visual C++ build tools installed: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Installing hnswlib from conda: conda install -c conda-forge hnswlib"]},{"l":"Configuration","p":["Once Smart Context is enabled, you should configure it in the SillyTavern UI. Smart Context configuration can be done from within the Extensions menu STExtensionMenuIcon","Smart Context Config Panel","There are 4 main concepts to be aware of:","Chat History Preservation","Memory Injection Amount","Individual Memory Length","Injection Strategy"]},{"l":"SmartContext only starts after 10 mesages are in the chat history","p":["At the start of a new chat, ChromaDB is inactive.","Once the chat has accumulated 10 messages, it will begin recording all messages into the database, and recalling messages as needed."]},{"l":"Chat History Preservation ('kept mesages')","p":["By default, ChromaDB will keep as many recent natural chat history messages as specified in the slider. Any messages beyond this amount will be removed from your sent prompt, and if 'memories' exist in the database they will be added in place of the older chat history messages (see Strategy below)."]},{"l":"Memory Injection Amount","p":["The maximum number of 'memories' Smart Context will insert into the context. Not every injection attempt will get this full amount. If you send an input related to 'dogs' and only one other message in the DB is related to dogs, then only 1 item will be inserted."]},{"l":"Individual Memory Length","p":["This is the maximum length allowed for each injected 'memory'. This is in CHARACTERS(not tokens). If set too small, the memory could be cut off midway.","Example:","Ross: I like dogs with long fur and fluffy tails. I dislike dogs with short fur and short tails.","This database 'memory' is 103 characters long, so you would need to set the slider to at least 103 in order to pull it entirely into the context.","If the slider is less than 103, the message would be cut off and injected like that."]},{"l":"Injection Strategy"},{"l":"Replace oldest history","p":["This strategy keeps X recent messages, removes all message before that, and replaces them with 'memories'.","Advantage","less likely to overflow your context limit","memories existing near the top of the context will have less immediate impact on the response while still providing 'background information'.","Disadvantage","old messages are inserted directly into the chat history with no special demarcation, and usually have no immediate natural relevance to the preserved natural chat history messages. This can confuse less intelligent AI models."]},{"l":"Add to Bottom","p":["This strategy leaves the chat history in its natural state and adds 'memories' after it inside a formatted [bracket header]. This means the 'kept messages' sliders is effectively disabled.","Advantage","does not shorten or alter the current natural chat history","'memories' exist after chat and have a stronger impact on the next AI response","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit.","because the memories exist very close to the end of the prompt they can have TOO MUCH effect on the AI's response."]},{"l":"Custom Depth","p":["This strategy leaves the chat history in its natural state and adds 'memories' at the depth you determine within the template you specify. This means the 'kept messages' slider is effectively disabled. The custom injection message should include the `` template word which is where all queried memories will be placed.","Advantage","flexibility to experiment with memory placement","customizable introductions to memory within context","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit."]},{"l":"Use % Strategy","p":["Note: This is not compatible with the 'Add to Bottom' strategy, which does not remove any messages at all.","While using the 'Replace Oldest History' strategy, checking this box will enable the slider for selecting a percentage of the in-context chat history to replace with SmartContext memories. It will also disable the two sliders for manually selecting the number of messages.","This strategy automatically calculates a percentage of the chat history to be replaced with SmartContext memories, instead of a fixed number of messages.","Advantage","easier than manually calculating the number of messages yourself","adjusts with the available context size, applying the same percentage to small and large prompt spaces","Disadvantage","calculations for how much history to remove can be slightly innacurate as they are based on estimated tokens per message","it rounds the number of messages to remove to the nearest number divisible by 5 (0, 5, 10, 15, 20, etc), so it is not as fine grained as manual numeric selection."]},{"l":"Memory Recall Strategy"},{"l":"Recall only from this chat","p":["This is the default behavior of smart-context and pulls 'memories' only from the ChromaDB collection for this specific chat."]},{"l":"Recall from all character chats","p":["This is an experimental behavior of smart-context which pulls 'memories' from all ChromaDB collections for the selected character. Hypothetically this should allow for the development of a more robust memory set spanning many interactions. Reccomended that this be used with 'Add to Bottom' or 'Custom Depth' strategies and 'kept messages' set to a low number so that ChromaDB will pull from memory sooner."]},{"l":"Using Smart Context","p":["Once it is enabled and configured, Smart Context happens automatically.","ChromaDB makes a new database for each chat that is opened inside SillyTavern. This database is automatically filled with the entire chat history.","You can also manually insert text files into the database.","These text files do not have to be chats. They can be anything (wikipedia entries, fanfic, etc)."]},{"l":"Purging the Database","p":["You can use the 'Purge DB' button to clear the database for the current chat.","This can be helpful if you find inaccurate memories have been stored (such as chat message you have since deleted or edited)."]},{"l":"FAQ"},{"l":"What happens to the databases when I'm done chatting? Can I save them?","p":["For locally installed Extras servers, Smart Context saves the databases. There is no need to save them manually in usual use cases.","For colab users, the databases are wiped when the extras server shuts down. Use the export button to save the database as a JSON file, and import it next time you want to use it.","Usually there is no need to save Smart Context databases.","Currently we have an Import/Export feature, which allows you to save the chat's DB and use it again at a later date."]},{"l":"Can I make one big database for all of my chats to reference?","p":["This would not be a good use of Smart Context's capabilities. We recommend using World Info for this purpose."]}],[{"l":"talkinghead","p":["THE SUPPORT FOR TALKGINHEAD WAS DROPPED IN SILLYTAVERN 1.12.13. THIS PAGE IS KEPT FOR HISTORICAL PURPOSES."]},{"l":"What is it?","p":["An implementation of Talking Head Anime 3 Demo for AITuber. It possesses the following features:","Generates random Live 2D-like motion actions from a single static image.","Lip-syncs to the sound output from any TTS output.","This extension contains the original demo programs for the Talking Head(?) Anime from a Single Image 3: Now the Body Too project. As the name implies, the project allows you to animate anime characters, and you only need a single image of that character to do so. There are two demo programs:","The manual_poser lets you manipulate a character's facial expression, head rotation, body rotation, and chest expansion due to breathing through a graphical user interface, so you can save them as default expressions IE Happy, sad, joy, etc. ifacialmocap_puppeteer lets you transfer your facial motion to an anime character."]},{"l":"Hardware Requirements","p":["You can use either CPU or GPU Modes (CPU is default). However, in CPU mode expect about 1 FPS, and in GPU mode on an RTX3060 I am getting about 9-10 FPS.","The ifacialmocap_puppeteer requires an iOS device that is capable of computing blend shape parameters from a video feed. This means that the device must be able to run iOS 11.0 or higher and must have a TrueDepth front-facing camera. (See this page for more info.) In other words, if you have the iPhone X or something better, you should be all set."]},{"l":"How to use","p":["You must launch extras with the following modules for talkinghead to work: classify and talkinghead! classify is required for the handling of the talkinghead.png file. Additionally, you may also use --talkinghead-gpu to load the blend models into GPU memory and make the animations 10x faster. It is highly recommended to use GPU acceleration! By default, once the program starts it will load a default image SillyTavern-extras\\talkinghead\\tha3\\images\\lambda_00.png. You can verify it is working by going to http://localhost:5100/api/talkinghead/result_feed or YOUR EXT URL:PORT/api/talkinghead/result_feed.","Once the server has started go to the Extension API tab and connect. Then simply select a character card to load. (--enable-modules=classify,talkinghead --talkinghead-gpu when starting server.py)","Now select the Character Expressions, if you check the image type talkinghead box the script will replace your current character expression with the result of YOUR EXT URL:PORT/api/talkinghead/result_feed unchecking the box SHOULD return the image back to the original expression, however sometimes you have to send a new message to the chat to \"reload\" the image.","If you do not have a talkinghead.png file in the character directory it will simply show either the default image or the last character card that had a talkinghead.png file. The animation source image is changed when the character card is changed.","Now open the character expressions scroll down to the talkinghead image and upload an image file that meets the requirements in the section below called \"Constraints on Input Images\".","Then check and uncheck the talkinghead box to reload the character. If the image is funny looking it is probably because it is not transparent / has no alpha layer. Otherwise, follow the instructions and template below."]},{"l":"Constraints on Input Images","p":["In order for the system to work well, the input image must obey the following constraints:","It should be of resolution 512 x 512. (If the program receives an input image of any other size, it will resize the image to this resolution and also output at this resolution.) It must have an alpha channel. It must contain only one humanoid character. The character should be standing upright and facing forward. The character's hands should be below and far from the head. The head of the character should roughly be contained in the 128 x 128 box in the middle of the top half of the image. The alpha channels of all pixels that do not belong to the character (i.e., background pixels) must be 0.","Input Constraints"]},{"l":"ADVANCED SECTION"},{"l":"Python Environment","p":["In addition to the base feature (app.py), both manual_poser and ifacialmocap_puppeteer are available as desktop applications. To run them, you need to set up an environment for running programs written in the Python language. The environment needs to have the following software packages:","Python >= 3.8","PyTorch >= 1.11.0 with CUDA support","SciPY >= 1.7.3","wxPython >= 4.1.1","Matplotlib >= 3.5.1","One way to do so is to install Anaconda and run the following commands in your shell:","conda create -n talking-head-anime-3-demo python=3.8 conda activate talking-head-anime-3-demo conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch conda install scipy pip install wxpython conda install matplotlib"]},{"l":"Additional Blend Models","p":["There is only one (lightest) model included, if you want the additional blend models you need to download the model files from https://www.dropbox.com/s/y7b8jl4n2euv8xe/talking-head-anime-3-models.zip?dl=0 and unzip it to the SillyTavern-extras\\talkinghead\\tha3\\models folder. In the end, the data folder should look like:","tha3","models","separable_float","editor.pt","eyebrow_decomposer.pt","eyebrow_morphing_combiner.pt","face_morpher.pt","two_algo_face_body_rotator.pt","separable_half","standard_float","standard_half","The model files are distributed with the Creative Commons Attribution 4.0 International License, which means that you can use them for commercial purposes. However, Pramook Khungurn. Talking Head(?) Anime from a Single Image 3: Now the Body Too. https://github.com/pkhungurn/talking-head-anime-3-demo, is the creator."]},{"l":"Running the manual_poser Desktop Application","p":["Open a shell. Change your working directory to the repository's root directory. Then, run:","python tha3/app/manual_poser.py Note that before running the command above, you might have to activate the Python environment that contains the required packages.","conda activate extras if you have not already activated the environment."]}],[{"l":"Development and Automation","p":["SillyTavern's default package only provides a barebones platform that can be extended in a multitude of ways.","STscript","STscript is a powerful scripting language based on batched chat commands that can be approached without any prior coding knowledge.","Function Calling","Add more dynamic capabilities by letting the LLM use external sources of data or trigger specific functionality of the extension.","UI Extensions","UI extensions run in a browser environment and expand the functionality of SillyTavern by hooking into its events and API.","Server Plugins","Server plugins allow adding functionality such as new API endpoints by running code in the NodeJS environment.","Internationalization (i18n)","Learn how to translate SillTavern's UI into your language."]}],[{"l":"STscript Language Reference"},{"l":"What is STscript?","p":["It's a simple yet powerful scripting language that could be used to expand the functionality of SillyTavern without serious coding, allowing you to:","Create mini-games or speed run challenges","Build AI-powered chat insights","Unleash your creativity and share with others","STscript is built using the slash commands engine, utilizing command batching, data piping, macros, and variables. These concepts are going to be described in the following document."]},{"l":"Security precaution","p":["With great power comes great responsibility. Be careful and always inspect the scripts before executing them."]},{"l":"Hello, World!","p":["To run your first script, open any SillyTavern chat and type the following into the chat input bar:","Hello World","You should see the message in the toast on top of the screen. Now let's break it down bit by bit.","A script is a batch of commands, each one starting with the slash, with or without named and unnamed arguments, and terminated with the command separator character: |.","Commands are executed sequentially, one after another, and transfer data between each other.","The /pass command accepts a constant value of \"Hello, World!\" as an unnamed argument and writes it to the pipe.","The /echo command receives the value through the pipe from the previous command and displays it as a toast notification.","Hint: To see a list of all available commands, type /help slash into the chat.","As constant unnamed arguments and pipes are interchangeable, we could rewrite this script simply as:"]},{"l":"User input","p":["Now let's add a little bit of interactivity to the script. We will accept the input value from the user and display it in the notification.","The /input command is used to display an input box with the prompt specified in the unnamed argument and then writes the output to the pipe.","Because /echo already has an unnamed argument that sets the template for the output, we use the {{pipe}} macro to specify a place where the pipe value will be rendered.","Slim Shady Input","Slim Shady Output"]},{"l":"Other input/output commands","p":["/popup (text)— shows a blocking popup, supports lite HTML formatting, e.g: /popup font color=redI'm red!/font.","/setinput (text)— replaces the contents of the user input bar with the provided text.","/speak voice=name (text)— narrates the text using the selected TTS engine and the character name from the voice map, e.g. /speak name=Donald Duck Quack!.","/buttons labels=[a,b] (text)— shows a blocking popup with the specified text and button labels. labels must be a JSON-serialized array of strings or a variable name containing such an array. Returns the clicked button label into the pipe or empty string if canceled. The text supports lite HTML formatting."]},{"l":"Arguments for /popup and /input","p":["/popup and /input support the following additional named arguments:","large=on/off- increases the vertical size of the popup. Default: off.","wide=on/off- increases the horizontal size of the popup. Default: off.","okButton=string- adds ability to customize the text on the \"Ok\" button. Default: Ok.","rows=number- (only for /input) increases the size of the input control. Default: 1.","Example:"]},{"l":"Arguments for /echo","p":["/echo supports the following values for the additional severity argument that sets the style of the displayed message.","warning","error","info(default)","success","Example:"]},{"l":"Variables","p":["/addglobalvar key=name or {{addglobalvar::name:increment}}— adds the increment to the value of the global variable.","/addvar key=name increment or {{addvar::name::increment}}— adds the increment to the value of the local variable.","/decglobalvar name or {{decglobalvar::name}}— decrements a value of the global variable by 1.","/decvar name or {{decvar::name}}— decrements a value of the local variable by 1.","/flushglobalvar name— deletes the value of the global variable.","/flushvar name— deletes the value of the local variable.","/getglobalvar name or {{getglobalvar::name}}— gets the value of the global variable.","/getvar name or {{getvar::name}}— gets the value of the local variable.","/incglobalvar name or {{incglobalvar::name}}— increments a value of the global variable by 1.","/incvar name or {{incvar::name}}— increments a value of the local variable by 1.","/setglobalvar key=name or {{setglobalvar::name::value}}— sets the value of the global variable.","/setvar key=name value or {{setvar::name::value}}— sets the value of the local variable.","All slash commands for variable manipulation write the resulting value into the pipe for the next command to use.","For macros, only the \"get\", \"inc\", and \"dec\" type macro returns the value, \"add\" and \"set\" are replaced with an empty string instead.","Global variables — saved to the settings.json and exist everywhere across the app.","If a command argument accepts a variable name and both local and global variables exist with the same name, then the local variable takes priority.","Increment in the /addvar command performs an addition or subtraction of the value if both increment and the variable value can be converted to a number, or otherwise does the string concatenation.","Local variables — saved to the metadata of the current chat, and unique to it.","Now, let's consider the following example:","Since the variables are saved and not flushed between the script executions, you can reference the variable in other scripts and via macros, and it will resolve to the same value as during the execution of the example script. To guarantee that the value will be discarded, add the /flushvar command to the script.","The default value of previously undefined variables is an empty string or a zero of it is first used in the /addvar, /incvar, /decvar command.","The getvar command is used to retrieve the value of the variable and pass it through the pipe.","The getvar macro is used to display the value in the /echo command.","The value is passed to the /imagine command (provided by the Image Generation plugin) to be used as its input prompt.","The value of the user input is saved in the local variable named SDinput.","Variables are used to store and manipulate data in scripts, using either commands or macros. The variables could be one of the following types:"]},{"l":"Arrays and objects","p":["Variable values can contain JSON-serialized arrays or key-value pairs (objects).","Examples:","Array: [apple,banana,orange]","Object: {fruits:[apple,banana,orange]}","The following modifications can be applied to commands to work with these variables:","/len commands gets a number of items in the array.","index=number/string named argument can be added /getvar or /setvar and their global counterparts to get or set sub-values by either a zero-based index for arrays or a string key for objects.","If a numeric index is used on a nonexistent variable, the variable will be created as an empty array [].","If a string index is used on a nonexistent variable, the variable will be created as an empty object {}.","/addvar and /addglobalvar commands support pushing a new value to array-typed variables."]},{"l":"Flow control - conditionals","p":["You can use the /if command to create conditional expressions that branch the execution based on the defined rules.","Note that","syntax is also supported, however {: closures :} will help you write cleaner scripts.","Let's review the following example:","This script evaluates the user input against a required value and displays different messages, depending on the input value."]},{"l":"Arguments for /if","p":["left is the first operand. Let's call it A.","right is the second operand. Let's call it B.","rule is the operation to be applied to the operands.","else is the optional string of subcommands to be executed if the result of boolean comparison is false.","Unnamed argument is the subcommand to be executed if the result of boolean comparison is true.","The operand values are evaluated in the following order:","Numeric literals","Local variable names","Global variable names","String literals","String values of named arguments could be escaped with quotes to allow multi-word strings. Quotes are then discarded."]},{"l":"Boolean operations","p":["Supported rules for boolean comparison are the following. An operation applied to the operands results in either a true or false value.","eq(equals) => A = B","neq(not equals) => A != B","lt(less than) => A < B","gt(greater than) => A > B","lte(less than or equals) => A <= B","gte(greater than or equals) => A >= B","not(unary negation) => !A","in(includes substring) => A includes B, case insensitive","nin(not includes substring) => A not includes B, case insensitive"]},{"l":"Subcommands","p":["A subcommand is a string containing a list of slash commands to execute.","To use command batching in subcommands, the command separator character should be escaped (see below).","Since macro values are executed when the conditional is entered, not when the subcommand is executed, a macro could be additionally escaped to delay their evaluation to the subcommand execution time.","The result of the subcommands execution is piped to the command after /if.","The /abort command interrupts the script execution when encountered.","/if commands can be used as a ternary operator. The following example will pass a \"true\" string to the next command the variable a equals 5, and a \"false\" string otherwise."]},{"l":"Escape Sequences"},{"l":"Macros","p":["Escaping of macros works just like before. However, with closures, you will need to escape macros a lot less often than before. Either escape the two opening curly braces, or both the opening and closing pair."]},{"l":"Pipes","p":["Pipes don't need to be escaped in closures (when used as command separators). Everywhere where you want to use a literal pipe character instead of a command separator, you need to escape it.","With the parser flag STRICT_ESCAPING you don't need to escape pipes in quoted values."]},{"l":"Quotes","p":["To use a literal quote-character inside a quoted value, the character must be escaped."]},{"l":"Spaces","p":["To use space in the value of a named argument, you either have to surround the value in quote, or escape the space character."]},{"l":"Closure Delimiters","p":["If you want to use the character combinations used to mark the beginning or end of a closure, you have to escape the sequence with a single backslash."]},{"l":"Pipe Breakers","p":["To prevent the previous command's output from being automatically injected as the unnamed argument into the next command, put double pipes between the two commands."]},{"l":"Closures","p":["Closures (block statements, lambdas, anonymous functions, whatever you want to call them) are a series of commands wrapped between {: and :}, that are only evaluated once that part of the code is executed."]},{"l":"Sub-Commands","p":["Closures make using sub-commands a lot easier and get rid of the need to escape pipes and macros."]},{"l":"Scopes","p":["Closures have their own scope and support scoped variables. Scoped variables are declared with /let, their values set and retrieved with /var. Another way to get a scoped variable is the {{var::}} macro.","Within a closure, you have access to all variables declared within that same closure or in one of its ancestors. You don't have access to variables declared in a closure's descendants. If a variable is declared with the same name as a variable that was declared in one of the closure's ancestors, you don't have access to the ancestor variable in this closure and its descendants."]},{"l":"Named Closures","p":["Closures can be assigned to variables (only scoped variables) to be called at a later point or to be used as sub-commands.","/: can also be used to execute Quick Replies, as it is just a shorthand for /run."]},{"l":"Closure Arguments","p":["Named closures can take named arguments, just like slash commands. The arguments can have default values."]},{"l":"Closures and Piped Arguments","p":["The piped value from a parent closure will not be automatically injected into the first command of a child closure. You can still explicitly reference the parent's piped value with {{pipe}}, but if you leave the unnamed argument of the first command inside a closure blank, the value will not be automatically injected."]},{"l":"Immediately Executed Closures","p":["Closures can be immediately executed, meaning they will be replaced with their return value. This is helpful in places where no explicit support for closures exists, and to shorten some commands that would otherwise require a lot of intermediate variables.","In addition to running named closures saved inside scoped variables, the /run command can also be used to execute closures immediately."]},{"l":"Comments","p":["A comment is a human-readable explanation or annotation in the script code. Comments don't break pipes."]},{"l":"Block Comments","p":["Block comments can be used to quickly comment out multiple commands at once. They will not terminate on a pipe."]},{"l":"Flow Control"},{"l":"Loops: /while and /times","p":["If you need to run some command in a loop until a certain condition is met, use the /while command.","On each step of the loop it compares the value of variable A with the value of variable B, and if the condition yields true, then executes any valid slash command enclosed in quotes, otherwise exists the loop. This command doesn't write anything to the output pipe."]},{"l":"Arguments for /while","p":["The set of available boolean comparisons, handing of variables, literal values, and subcommands is the same as for the /if command.","The optional guard named argument ( on by default) is used to protect against endless loops, limiting the number of iterations to 100. To disable and allow endless loops, set guard=off.","This example adds 1 to the value of i until it reaches 10, then outputs the resulting value (10 in this case)."]},{"l":"Arguments for /times","p":["Runs a subcommand a specified number of times.","/times (repeats) (command)– any valid slash command enclosed in quotes repeats a number of times, e.g. /setvar key=i 1 | /times 5 /addvar key=i 1 adds 1 to the value of \"i\" 5 times.","{{timesIndex}} is replaced with the iteration number (zero-based), e.g. /times 4 {:/echo {{timesIndex}}:} echoes the numbers 0 through 4.","Loops are limited to 100 iterations by default, pass guard=off to disable."]},{"l":"Breaking out of Loops and Closures","p":["The /break command can be used to break out of a loop (/while or /times) or a closure early. The unnamed argument of /break can be used to pass a value different from the current pipe along./break is currently implemented in the following commands:","/while- exits the loop early","/times- exits the loop early","/run(with a closure or closure via variable) - exits the closure early","/:(with a closure) - exits the closure early"]},{"l":"Math operations","p":["/abs (a)– performs an absolute value operation of a value, e.g. /abs -10","/add (a b c d)– performs an addition of the set of values, e.g. /add 10 i 30 j","/cos (a)– performs a cosine operation of a value, e.g. /cos i","/div (a b)– performs a division of two values, e.g. /div 10 i","/log (a)– performs a natural logarithm operation of a value, e.g. /log i","/max (a b c d)– returns a maximum from the set of values, e.g. /max 1 0 4 k","/min (a b c d)– return a minimum from the set of values, e.g. /min 5 4 i 2","/mod (a b)– performs a modulo operation of two values, e.g. /mod i 2","/mul (a b c d)– performs a multiplication of the set of values, e.g. /mul 10 i 30 j","/pow (a b)– performs a power operation of two values, e.g. /pow i 2","/rand (round=round|ceil|floor from=number=0 to=number=1)– returns a random number between from and to, e.g. /rand or /rand 10 or /rand from=5 to=10. Ranges are inclusive. The returned value will contain a fractional part. Use round named argument to get an integral value, e.g. /rand round=ceil to round up, round=floor to round down, and round=round to round to nearest.","/round (a)– performs a rounding to the nearest integer operation of a value, e.g. /round 3.14","/sin (a)– performs a sine operation of a value, e.g. /sin i","/sqrt (a)– performs a square root operation of a value, e.g. /sqrt 9","/sub (a b)– performs a subtraction of two values, e.g. /sub i 5","All of the following operations accept a series of numbers or variable names and output the result to the pipe.","Invalid operations (such as division by zero), and operations that result in a NaN value or infinity return zero.","List of operations:","Multiplication, addition, minimum and maximum accept an unlimited number of arguments separated by spaces.","Sine, cosine, natural logarithm, square root, absolute value, and rounding accept one argument.","Subtraction, division, exponentiation, and modulo accept two arguments separated by spaces."]},{"l":"Example 1: get an area of a circle with a radius of 50."},{"l":"Example 2: calculate a factorial of 5."},{"l":"Using the LLM","p":["Scripts can make requests to your currently connected LLM API using the following commands:","/gen (prompt)— generates text using the provided prompt for the selected character and including chat messages.","/genraw (prompt)— generates text using just the provided prompt, ignoring the current character and chat.","/trigger— triggers a normal generation (equivalent to clicking a \"Send\" button). If in group chat, you can optionally provide a 1-based group member index or a character name to have them reply, otherwise triggers a group round according to the group settings."]},{"l":"Arguments for /gen and /genraw","p":["lock— can be on or off. Specifies whether a user input should be blocked while the generation is in progress. Default: off.","stop— JSON-serialized array of strings. Adds a custom stop string (if the API supports it) just for this generation. Default: none.","instruct(only /genraw) — can be on or off. Allows to use instruct formatting on the input prompt (if instruct mode is enabled and the API supports it). Set to off to force pure prompts. Default: on.","as(for Text Completion APIs) — can be system(default) or char. Defines how the last prompt line will be formatted. char will use a character name, system will use no or neutral name.","The generated text is then passed through the pipe to the next command and can be saved to a variable or displaced using the I/O capabilities:","Cthulhu Says","or to insert the generated message as a response from your character:"]},{"l":"Temporal character","p":["If you are not in a group chat, scripts may temporarily make a request to the currently connected LLM as a different character.","/ask (prompt)— generates text using the provided prompt for a specified character and including chat messages. Please note that swipes of the response from this character will revert back to the current character."]},{"l":"Arguments for /ask","p":["name— Required. The name of the character to ask (or a unique character identifier, such as an avatar key). This must be provided as a named argument.","return— Specifies how the return value should be provided. Defaults to pipe(output via the command pipe). Other options can be specified if supported by the API."]},{"l":"Prompt injections","p":["Scripts can add custom LLM prompt injections, making it essentially an equivalent of unlimited Author's Notes.","/inject (text)— inserts any text into the normal LLM prompt for the current chat, and requires a unique identifier. Saved to chat metadata.","/listinjects— shows a list of all prompt injections added by scripts for the current chat in a system message.","/flushinjects— deletes all prompt injections added by scripts for the current chat.","/note (text)— sets the Author's Note value for the current chat. Saved to chat metadata.","/interval— sets the Author's Note insertion interval for the current chat.","/depth— sets the Author's Note insertion depth for the in-chat position.","/position— sets the Author's Note position for the current chat."]},{"l":"Arguments for /inject","p":["id— an identifier string or a reference to a variable. Consequent calls of /inject with the same ID will overwrite the previous text injection. Required argument.","position— sets a position for the injection. Default: after. Possible values:","after: after the main prompt.","before: before main prompt.","chat: in-chat.","depth— sets an injection depth for the in-chat position. 0 means insertion after the last message, 1 - before the last message, etc. Default: 4.","Unnamed argument is a text to be injected. An empty string will unset the previous value for the provided identifier."]},{"l":"Access chat messages"},{"l":"Read messages","p":["You can access messages in the currently selected chat using the /messages command.","The names argument is used to specify whether you want to include character names or not, default: on.","In an unnamed argument, it accepts a message index or range in the start-finish format. Ranges are inclusive!","If the range is unsatisfiable, i.e. an invalid index or more messages than exist are requested, then an empty string is returned.","Messages that are hidden from the prompt (denoted by the ghost icon) are excluded from the output.","If you want to know the index of the latest message, use the {{lastMessageId}} macro, and {{lastMessage}} will get you the message itself.","To calculate the start index for a range, for example, when you need to get the last N messages, use variable subtraction. This example will get you 3 last messages in the chat:"]},{"l":"Send messages","p":["A script can send messages as either a user, character, persona, neutral narrator, or add comments.","/send (text)— adds a message as the currently selected persona.","/sendas name=charname (text)— adds a message as any character, matching by their name. name argument is required. Use the {{char}} macro to send as the current character.","/sys (text)— adds a message from the neutral narrator that doesn't belong to the user or character. The displayed name is purely cosmetic and can be customized with the /sysname command.","/comment (text)— adds a hidden comment that is displayed in the chat but is not visible to the prompt.","/addswipe (text)— adds a swipe to the last character message. Can't add a swipe to the user or hidden messages.","/hide (message id or range)— hides one or several messages from the prompt based on the provided message index or inclusive range in the start-finish format.","/unhide (message id or range)— returns one or several messages to the prompt based on the provided message index or inclusive range in the start-finish format.","/send, /sendas, /sys, and /comment commands optionally accept a named argument at with a zero-based numeric value (or a variable name that contains such a value) that specifies an exact position of message insertion. By default new messages are inserted at the end of the chat log.","This will insert a user message at the beginning of the conversation history:"]},{"l":"Delete messages","p":["These commands are potentially destructive and have no \"undo\" function. Check the /backups/ folder if you accidentally deleted something important.","/cut (message id or range)— cuts one or several messages from the chat based on the provided message index or inclusive range in the start-finish format.","/del (number)— deletes last N messages from the chat.","/delswipe (1-based swipe id)— deletes a swipe from the last character message based on the provided 1-based swipe ID.","/delname (character name)— deletes all messages in the current chat that belong to a character with the specified name.","/delchat— deletes the current chat."]},{"l":"World Info commands","p":["World Info (also known as Lorebook) is a highly utilitarian tool for dynamically inserting data into the prompt. See the dedicated page for more detailed explanation: World Info.","/getchatbook– gets a name of the chat-bound World Info file or create a new one if was unbound, and pass it down the pipe.","/findentry file=bookName field=fieldName [text]– finds a UID of the record from the specified file (or a variable pointing to a file name) using fuzzy matching of a field value with the provided text (default field: key) and passes the UID down the pipe, e.g. /findentry file=chatLore field=key Shadowfang.","/getentryfield file=bookName field=field [UID]– gets a field value (default field: content) of the record with the UID from the specified World Info file (or a variable pointing to a file name) and passes the value down the pipe, e.g. /getentryfield file=chatLore field=content 123.","/setentryfield file=bookName uid=UID field=field [text]– sets a field value (default field: content) of the record with the UID (or a variable pointing to UID) from the specified World Info file (or a variable pointing to a file name). To set multiple values for key fields, use a comma-delimited list as a text value, e.g. /setentryfield file=chatLore uid=123 field=key Shadowfang,sword,weapon.","/createentry file=bookName key=keyValue [content text]– creates a new record in the specified file (or a variable pointing to a file name) with the key and content (both of these arguments are optional) and passes the UID down the pipe, e.g. /createentry file=chatLore key=Shadowfang The sword of the king."]},{"l":"Valid entry fields","p":["(see below)","0 = AND ANY","0 = before main prompt","0 = System","1 = after main prompt","1 = NOT ALL","1 = User","2 = Assistant","2 = NOT ANY","2 = top of Author's Note","3 = AND ALL","3 = bottom of Author's Note","4 = in-chat at depth","5 = top of example messages","6 = bottom of example messages","Automation ID","automationId","Boolean (1/0)","Case-Sensitive","caseSensitive","Character Filter Exclude Mode","Character Filter Names","Character Filter Tags","characterFilterExclude","characterFilterNames","characterFilterTags","comment","constant","Constant Status","content","depth","Depth Role","disable","Disabled Status","excludeRecursion","Field","group","Group Scoring","groupOverride","groupWeight","Inclusion Group","Inclusion Group Prioritize","Inclusion Group Weight","key","keysecondary","List of strings","Logic","Logic values","Match Character Depth Prompt","Match Character Description","Match Character Personality","Match Creator Notes","Match Persona Description","Match Scenario","Match Whole Words","matchCharacterDepthPrompt","matchCharacterDescription","matchCharacterPersonality","matchCreatorNotes","matchPersonaDescription","matchScenario","matchWholeWords","Non-recursable","Number","Number (0-100)","Number (0-999)","Optional Filter","order","position","Position values","Primary Keywords","probability","role","Role values(Position = 4 only)","Scan Depth","scanDepth","selectiveLogic","String","Title / Memo","Trigger%","UI element","useGroupScoring","Value type","vectorized","Vectorized Status"]},{"l":"Example 1: Read a content from the chat lorebook by key"},{"l":"Example 2: Create a chat lorebook entry with key and content"},{"l":"Example 3: Expand an existing lorebook entry with new information from the chat"},{"l":"Text manipulation","p":["There's a variety of useful text manipulation utility commands to be used in various script scenarios.","/trimtokens— trims the input to the specified number of text tokens from the start or from the end and outputs the result to the pipe.","/trimstart— trims the input to the start of the first complete sentence and outputs the result to the pipe.","/trimend— trims the input to the end of the last complete sentence and outputs the result to the pipe.","/fuzzy— performs fuzzy matching of the input text to the list of strings, outputting the best string match to the pipe.","/regex name=scriptName [text]— executes a regex script from the Regex extension for the specified text. The script must be enabled."]},{"l":"Arguments for /trimtokens","p":["direction sets the direction for trimming, which can be either start or end. Default: end.","limit sets the amount of tokens to left in the output. Can also specify a variable name containing the number. Required argument.","Unnamed argument is the input text to be trimmed."]},{"l":"Arguments for /fuzzy","p":["list is a JSON-serialized array of strings containing the candidates. Can also specify a variable name containing the list. Required argument.","Unnamed argument is the input text to be matched. Output is one of the candidates matching the input most closely."]},{"l":"Autocomplete","p":["Autocomplete is enabled both on the chat input, and the large Quick Reply editor.","Autocomplete works anywhere in your input. Even with multiple piped commands and nested closures.","Autocomplete supports three ways of looking up matching commands ( User Settings-> STscript Matching).","Starts with The \"old\" way. Only commands that begin exactly with the typed value will show up.","Includes All commands that include the type value will show up. Example: When entering /delete, the commands /qr-delete and /qr-set-delete will show up in the autocomplete list (/qr- delete, /qr-set- delete).","Fuzzy All commands that can be fuzzy-matched against the typed value will show up. Example: When entering /seas, the command /sendas will show up in the autocomplete list (/ se nd as).","Command arguments are supported by autocomplete as well. The list will show up for required arguments automatically. For optional arguments, press Ctrl+ Space to open the list of available options.","When entering /: to execute a closure or QR, autocomplete will show a list of scoped variables and QRs.","Autocomplete has limited support for macros (in slash commands). Type {{ to get a list of available macros.","Use the up and down arrow keys to select an option from the list of autocomplete options.","Press Enter or Tab or click on an option to place the option at the cursor.","Press Escape to close the autocomplete list.","Press Ctrl+ Space to open the autocomplete list or toggle the selected option's details."]},{"l":"Parser Flags","p":["The parser accepts flags to modify its behavior. These flags can be toggled on and off at any point in a script and all following input will be evaluated accordingly. You can set your default flags in user settings."]},{"l":"Strict Escaping","p":["Changes with STRICT_ESCAPING enabled are as follows."]},{"i":"pipes-1","l":"Pipes","p":["Pipes don't need to be escaped in quoted values."]},{"l":"Backslashes","p":["A backslash in front of a symbol can be escaped to provide the literal backslash followed by the functional symbol."]},{"l":"Replace Variable Macros","p":["This flag helps to avoid double-substitutions when the variable values contain text that could be interpreted as macros. The {{var::}} macros get substituted last and no further substitutions happen on the resulting text / variable value.","Replaces all {{getvar::}} and {{getglobalvar::}} macros with {{var::}}. Behind the scenes, the parser will insert a series of command executors before the command with the replaced macros:","call /let to save the current {{pipe}} to a scoped variable","call /getvar or /getglobalvar to get the variable used in the macro","call /let to save the retrieved variable to a scoped variable","call /return with the saved {{pipe}} value to restore the correct piped value for the next command"]},{"l":"Quick Replies: script library and auto-execution","p":["Quick Replies is a built-in SillyTavern extension that provides an easy way to store and execute your scripts."]},{"l":"Configuring Quick Replies","p":["In order to get started, enable open the extensions panel (stacked blocks icon), and expand the Quick Replies menu.","Quick Reply","Quick Replies are disabled by default, you need to enable them first. Then you will see a bar appearing above your chat input bar.","You can set the displayed button text label (we recommend using emojis for brevity) and the script that will be executed when you click the button.","The number of buttons is controlled by the Number of slots settings (max = 100), adjust it according to your needs and click \"Apply\" when done.","Inject user input automatically recommended to be disabled when using STscript, otherwise it may interfere with your inputs, use the {{input}} macro to get the current value of the input bar in scripts instead.","Quick Reply presets allow to have multiple sets of predefined Quick Replies and switch between manually or by using the /qrset (name of set) command. Don't forget to click \"Update\" before switching to a different set to write your changes to the currently used preset!"]},{"l":"Manual execution","p":["Now you can add your first script to the library. Pick any free slot (or create one), type \"Click me\" into the left box to set the label, then paste this into the right box:","Then click 5 times on the button that appeared above the chat bar. Every click increments the variable clicks by one and displays a different message when the value equals 5 and resets the variable."]},{"l":"Automatic execution","p":["Open the modal menu by clicking the ⋮ button for the created command.","In this menu you can do the following:","Edit the script in a convenient full-screen editor","Hide the button from the chat bar, making it accessible only for auto-execution.","Enable automatic execution on one or more of the following conditions:","App startup","Sending a user message to the chat","Receiving an AI message in the chat","Opening a character or group chat","Triggering a reply from a group member","Activating a World Info entry using the same Automation ID","Provide a custom tool tip for the quick reply (text displayed when hovering over the quick reply in your UI)","Execute the script for test purposes","Commands are executed automatically only if the Quick Replies extension is enabled.","For example, you can display a message after sending five user messages by adding the following script and setting it to auto-execute on the user message."]},{"l":"Debugger","p":["A basic debugger exists inside the expanded Quick Reply editor. Set breakpoints with /breakpoint | anywhere in your script. When executing the script from the QR editor, the execution will be interrupted at that point, allowing you to examine the currently available variables, pipe, command arguments, and more, and to step through the rest of the code one by one.","QR Editor Debugger"]},{"l":"Calling procedures","p":["A /run command can call scripts defined in the Quick Replies by their label, basically providing the ability to define procedures and return results from them. This allows to have reusable script blocks that other scripts could reference. The last result from the procedure's pipe is passed to the next command after it.","Let's create two Quick Replies:","Label:","GetRandom","Command:","GetMessage","Clicking on the GetMessage button will call the GetRandom procedure which will resolve the {{roll}} macro and pass the number to the caller, displaying it to the user.","Procedures do not accept named or unnamed arguments, but can reference the same variables as the caller.","Avoid recursion when calling procedures as it may produce the \"call stack exceeded\" error if handled unadvisedly."]},{"l":"Calling procedures from a different Quick Reply preset","p":["You can call a procedure from a different quick reply preset using the a.b syntax, where a = QR preset name and b = QR label name","By default, the system will first look for a quick reply label a.b, so if one of your labels is literally \"QRpreset1.QRlabel1\" it will try to run that. If no such label is found, it will search for a QR preset name \"QRpreset1\" with a QR labeled \"QRlabel1\"."]},{"l":"Quick Replies management commands"},{"l":"Create Quick Reply","p":["/qr-create (arguments, [message])– creates a new Quick Reply, example: /qr-create set=MyPreset label=MyButton /echo 123","Arguments:","label- string - text on the button, e.g., label=MyButton","set- string - name of the QR set, e.g., set=PresetName1","hidden- bool - whether the button should be hidden, e.g., hidden=true","startup- bool - auto execute on app startup, e.g., startup=true","user- bool - auto execute on user message, e.g., user=true","bot- bool - auto execute on AI message, e.g., bot=true","load- bool - auto execute on chat load, e.g., load=true","title- bool - title / tooltip to be shown on button, e.g., title=My Fancy Button"]},{"l":"Delete Quick Reply","p":["/qr-delete (set=string [label])– deletes Quick Reply"]},{"l":"Update Quick Reply","p":["/qr-update (arguments, [message])– updates Quick Reply, example: /qr-update set=MyPreset label=MyButton newlabel=MyRenamedButton /echo 123","Arguments:","newlabel- string - new text fort the button, e.g. newlabel=MyRenamedButton","label- string - text on the button, e.g., label=MyButton","set- string - name of the QR set, e.g., set=PresetName1","hidden- bool - whether the button should be hidden, e.g., hidden=true","startup- bool - auto execute on app startup, e.g., startup=true","user- bool - auto execute on user message, e.g., user=true","bot- bool - auto execute on AI message, e.g., bot=true","load- bool - auto execute on chat load, e.g., load=true","title- bool - title / tooltip to be shown on button, e.g., title=My Fancy Button"]},{"i":"#","p":["qr-get- retrieves all of a Quick Reply's properties, eample: /qr-get set=myQrSet id=42"]},{"l":"Create or update QR preset","p":["/qr-presetupdate (arguments [label]) or /qr-presetadd (arguments [label])","Arguments:","enabled- bool - enable or disable the preset","nosend- bool - disable send / insert in user input (invalid for slash commands)","before- bool - place QR before user input","slots- int - number of slots","inject- bool - inject user input automatically (if disabled use {{input}})","Create a new preset (overrides existing ones), example: /qr-presetadd slots=3 MyNewPreset"]},{"l":"Add QR context menu","p":["/qr-contextadd (set=string label=string chain=bool [preset name])– add context menu preset to a QR, example: /qr-contextadd set=MyPreset label=MyButton chain=true MyOtherPreset"]},{"l":"Remove all context menus","p":["/qr-contextclear (set=string [label])– remove all context menu presets from a QR, example: /qr-contextclear set=MyPreset MyButton"]},{"l":"Remove one context menu","p":["/qr-contextdel (set=string label=string [preset name])– remove context menu preset from a QR, example: /qr-contextdel set=MyPreset label=MyButton MyOtherPreset"]},{"l":"Quick Reply value escaping","p":["|{} can be escaped with backslash in the QR message / command.","For example, use /qr-create label=MyButton /getvar myvar \\| /echo \\{\\{pipe\\}\\} to create a QR that calls /getvar myvar | /echo {{pipe}}."]},{"l":"Extension commands","p":["SillyTavern extensions (both built-in, downloadable and third-party) can add their own slash command. Below is just an example of the capabilities in the official extensions. The list may be incomplete, make sure to check /help slash for the most complete list of available commands.","/websearch (query)— searches snippets of the web pages online for the specified query and returns the result into the pipe. Provided by the Web Search extension.","/imagine (prompt)— generates an image using the provided prompt. Provided by the Image Generation extension.","/emote (sprite)— sets a sprite for the active character by fuzzy matching its name. Provided by the Character Expressions extension.","/costume (subfolder)— sets a sprite set override for the active character. Provided by the Character Expressions extension.","/music (name)— force changes a played background music file by its name. Provided by the Dynamic Audio extension.","/ambient (name)— force changes a played ambient sound file by its name. Provided by the Dynamic Audio extension.","/roll (dice formula)— adds a hidden message to the chat with the result of a dice roll. Provided by the D&D Dice extension."]},{"l":"UI interaction","p":["Scripts can also interact with SillyTavern's UI: navigate through the chats or change styling parameters."]},{"l":"Character navigation","p":["/random— opens a chat with the random character.","/go (name)— opens a chat with the character of the specified name. First, searches for the exact name match, then by a prefix, then by a substring."]},{"l":"UI styling","p":["/bubble— sets the message style to the \"bubble chat\" style.","/flat— sets the message style to the \"flat chat\" style.","/single— sets the message style to the \"single document\" style.","/movingui (name)— activates a MovingUI preset by name.","/resetui— resets the MovingUI panels state to their original positions.","/panels— toggles the UI panels visibility: top bar, left and right drawers.","/bg (name)— finds and sets a background using fuzzy names matching. Respect the chat background lock state.","/lockbg— locks the background image for the current chat.","/unlockbg— unlocks the background image for the current chat."]},{"l":"More examples"},{"l":"Generate chat summary (by @IkariDevGIT)"},{"l":"Buttons popup usage"},{"l":"Get Nth Fibonacci's number (using Binet's formula)","p":["Hint: Set value of fib_no to the desired number"]},{"l":"Recursive Factorial (using closures)"}],[{"l":"Function Calling","p":["Function Calling allows adding dynamic functionality to your extensions by letting the LLM use structured data that you then can use to trigger a specific functionality of the extension."]},{"l":"Example use cases","p":["Query external APIs for additional information (news, weather, web search, etc.).","Perform calculations or conversions based on user input.","Store and recall important memories or facts, including RAG and database queries.","Introduce true randomness into the conversation (dice rolls, coin flips, etc.)."]},{"l":"Officially supported extensions using function calling","p":["Image Generation(built-in) - generate images based on user prompts.","Web Search- trigger a web search for a query.","RSS- fetch the latest news from RSS feeds.","AccuWeather- fetch the weather information from AccuWeather.","D&D Dice- roll dice for D&D games."]},{"l":"Prerequisites and limitations","p":["This feature is only available for certain Chat Completion sources: OpenAI, Claude, MistralAI, Groq, Cohere, OpenRouter, AI21, Google AI Studio, Google Vertex AI, DeepSeek, AI/ML API and Custom API sources.","Text Completion APIs don't support function calls, but some locally-hosted backends like Ollama and TabbyAPI may run in Custom OpenAI-compatible mode under Chat Completion.","The support for function calling must be explicitly allowed by the user first. This is done by enabling the \"Enable function calling\" option in the AI Response Configuration panel.","There is no guarantee that an LLM will perform any function calls at all. Most of them require an explicit \"activation\" through the prompt (e.g., the user asking to \"Roll a dice\", \"Get the weather\", etc.).","Not all prompts can trigger a tool call. Continuations, impersonation, background ('quiet') prompts are not allowed to trigger a tool call. They can still use past successful tool calls in their responses."]},{"l":"How to make a function tool"},{"l":"Check if the feature is supported","p":["To determine if the function tool calling feature is supported, you can call isToolCallingSupported from the SillyTavern.getContext() object. This will check if the current API supports function tool calling and if it's enabled in the settings. Here is an example of how to check if the feature is supported:"]},{"l":"Register a function","p":["To register a function tool, you need to call the registerFunctionTool function from the SillyTavern.getContext() object and pass the required parameters. Here is an example of how to register a function tool:"]},{"l":"Unregister a function","p":["To deactivate a function tool, you need to call the unregisterFunctionTool function from the SillyTavern.getContext() object and pass the name of the function tool to disable. Here is an example of how to unregister a function tool:"]},{"l":"Tips and tricks","p":["Successful tool calls are saved as a part of the visible history and will be displayed in the chat UI, so you can inspect the actual parameters and results. If that is not desirable, set the stealth: true flag when registering a function tool.","If you don't want to see the tool call in the chat history. If you want to stylize or hide them with custom CSS, target a toolCall class on .mes elements, i.e. .mes.toolCall { display: none; } or .mes.toolCall { color: #999; }."]}],[{"l":"UI Extensions","p":["UI extensions expand SillyTavern's functionality by hooking into its events and API. They run in a browser context and have practically unrestricted access to the DOM, JavaScript APIs, and the SillyTavern context. Extensions can modify the UI, call internal APIs, and interact with chat data. This guide explains how to create your own extensions (JavaScript knowledge is required).","Go here: Extensions.","To extend the functionality of the Node.js server, see the Server Plugins page.","Can't write JavaScript?","Consider STscript as a simpler alternative to writing a full-fledged extension.","Go through the MDN Course and come back when you're done."]},{"l":"Extension submissions","p":["Want to contribute your extensions to the official content repository? Contact us!","To ensure that all extensions are safe and easy to use, we have a few requirements:","Your extension must be open-source and have a libre license (see Choose a License). If you are unsure, AGPLv3 is a good choice.","Extensions must be compatible with the latest release version of SillyTavern. Please be ready to update your extension if something in the core changes.","Extensions must be well-documented. This includes a README file with installation instructions, usage examples, and a list of features.","Extensions that have a server plugin requirement to function will not be accepted."]},{"l":"Examples","p":["See live examples of simple SillyTavern extensions:","https://github.com/city-unit/st-extension-example- basic extension template. Showcases manifest creation, local script imports, adding a settings UI panel, and persistent extension settings usage.","https://github.com/search?q=topic%3Aextension+org%3ASillyTaverntype=Repositories- a list of all official SillyTavern extensions on GitHub."]},{"l":"Bundling","p":["Extensions can also utilize bundling to isolate themselves from the rest of the modules and use any dependencies from NPM, including UI frameworks like Vue, React, etc.","https://github.com/SillyTavern/Extension-WebpackTemplate- template repository of an extension using TypeScript and Webpack (no React).","https://github.com/SillyTavern/Extension-ReactTemplate- template repository of a bare-bones extension using React and Webpack.","To use relative imports from the bundle, you may need to create an import wrapper. Here's an example for Webpack:"]},{"l":"manifest.json","p":["Every extension must have a folder in data/user-handle/extensions and a manifest.json file, which contains metadata about the extension and a path to a JS script file that is the entry point of the extension.","Downloadable extensions are mounted into the /scripts/extensions/third-party folder when serving over HTTP, so relative imports should be used based on that. To ease local development, consider placing your extension repository in the /scripts/extensions/third-party folder (the \"Install for all users\" option)."]},{"l":"Manifest fields","p":["display_name is required. It is displayed in the \"Manage Extensions\" menu.","loading_order is optional. A higher number loads later.","js is the main JS file reference and is required.","css is an optional style file reference.","author is required. It should contain the name or contact info of the author(s).","auto_update is set to true if the extension should auto-update when the version of the ST package changes.","i18n is an optional object that specifies the supported locales and their corresponding JSON files (see below).","dependencies is an optional array of strings specifying other extensions that this extension depends on.","generate_interceptor is an optional string that specifies the name of a global function called on text generation requests.","minimum_client_version is an optional string that specifies the minimum SillyTavern version required for this extension to work."]},{"l":"Dependencies","p":["Extensions can also depend on other SillyTavern extensions. The extension will not load if any of these dependencies are missing or disabled.","Dependencies are specified by their folder name as it appears in the public/extensions directory.","Examples:","Built-in extensions: vectors, caption","Third-party extensions: third-party/Extension-WebLLM, third-party/Extension-Mermaid"]},{"l":"Deprecated fields","p":["requires is an optional array of strings specifying required Extras modules. The extension won't be loaded if the connected Extras API doesn't provide all listed modules.","optional is an optional array of strings specifying optional Extras modules. The extension will still load if these are missing, and the extension should handle their absence gracefully.","To check which modules are currently provided by the connected Extras API, import the modules array from scripts/extensions.js."]},{"l":"Scripting"},{"l":"Using getContext","p":["The getContext() function in the SillyTavern global object gives you access to the SillyTavern context, which is a collection of all the main app state objects, useful functions, and utilities.","You can find the full list of available properties and functions in the SillyTavern source code.","If you're missing any of the functions/properties in getContext, please get in touch with the developers or send us a pull request!"]},{"l":"Shared libraries","p":["Most of the npm libraries used internally by the SillyTavern frontend are shared in the libs property of the SillyTavern global object.","lodash- Utility library. Docs.","localforage- Browser storage library. Docs.","Fuse- Fuzzy search library. Docs.","DOMPurify- HTML sanitization library. Docs.","Handlebars- Templating library. Docs.","moment- Date/time manipulation library. Docs.","showdown- Markdown converter library. Docs.","You can find the full list of exported libraries in the SillyTavern source code.","Example: Using the DOMPurify library."]},{"l":"TypeScript notice","p":["If you want access to autocomplete for all methods in the SillyTavern global object (and you probably do), including getContext() and libs, you should add a TypeScript .d.ts module declaration. This declaration should import global types from SillyTavern's source, depending on your extension's location. Below is an example that works for both installation types: \"all users\" and \"current user.\"","global.d.ts- place this file in the root of your extension directory (next to manifest.json):"]},{"l":"Importing from other files","p":["Using imports from SillyTavern code is unreliable and can break at any time if the internal structure of ST's modules changes. getContext provides a more stable API.","Unless you're building a bundled extension, you can import variables and functions from other JS files.","For example, this code snippet will generate a reply from the currently selected API in the background:"]},{"l":"State management"},{"l":"Persistent settings","p":["When an extension needs to persist its state, it can use the extensionSettings object from the getContext() function to store and retrieve data. An extension can store any JSON-serializable data in the settings object and must use a unique key to avoid conflicts with other extensions.","To persist the settings, use the saveSettingsDebounced() function, which will save the settings to the server."]},{"l":"Chat metadata","p":["To bind some data to a specific chat, you can use the chatMetadata object from the getContext() function. This object allows you to store arbitrary data associated with a chat, which can be useful for storing extension-specific state.","To persist the metadata, use the saveMetadata() function, which will save the metadata to the server.","Do not save the reference to chatMetadata in a long-lived variable, as the reference will change when the chat is switched. Always use SillyTavern.getContext().chatMetadata to access the current chat metadata.","The CHAT_CHANGED event is emitted when the chat is switched, so you can listen to this event to update your extension's state accordingly. See more in the Listening to events section."]},{"l":"Character cards","p":["SillyTavern fully supports Character Cards V2 Specification, which allows to store arbitrary data in the character card JSON data.","This is useful for extensions that need to store additional data associated with the character and make it shareable when exporting the character card.","To write data to the character card extensions data field, use the writeExtensionField function from the getContext() function. This function takes a character ID, a string key, and a value to write. The value must be JSON-serializable.","Despite being called characterId, it's not a \"real\" unique identifier but rather an index of the character in the characters array.","The index of the current character is provided by the characterId property in the context. If you want to write data to the currently selected character, use SillyTavern.getContext().characterId. If you need to store data for another character, find the index by searching for the character in the characters array.","Caution: characterId is undefined in group chats or when no character is selected!"]},{"l":"Settings presets","p":["Arbitrary JSON data can be stored in the settings presets of the main API types. It will be exported and imported along with the preset JSON, so you can use it to store extension-specific settings for the preset. The following API types support data extensions in settings presets:","Chat Completion","Text Completion","NovelAI","KoboldAI / AI Horde","To read or write the data, you first need to get the PresetManager instance from the context:","The PRESET_CHANGED and MAIN_API_CHANGED events are emitted when the preset is changed or the main API is switched, so you can listen to these events to update your extension's state accordingly. See more in the Listening to events section."]},{"l":"Internationalization","p":["For general information on providing translations, see the Internationalization page.","Extensions can provide additional localized strings for use with the t, translate functions and the data-i18n attribute in HTML templates.","See the list of supported locales here ( lang key): https://github.com/SillyTavern/SillyTavern/blob/release/public/locales/lang.json"]},{"l":"Direct addLocaleData call","p":["Pass a locale code and an object with the translations to the addLocaleData function. Overrides of existing keys are NOT allowed. If the passed locale code is not a currently chosen locale, the data will be silently ignored."]},{"l":"Via the extension manifest","p":["Add an i18n object with a list of supported locales and their corresponding JSON file paths (relative to your extension's directory) to the manifest."]},{"l":"Registering slash commands (new way)","p":["While registerSlashCommand still exists for backward compatibility, new slash commands should now be registered through SlashCommandParser.addCommandObject() to provide extended details about the command and its parameters to the parser (and, in turn, to autocomplete and the command help).","All registered commands can be used in STscript in any possible way."]},{"l":"Events"},{"l":"Listening to events","p":["Use eventSource.on(eventType, eventHandler) to listen for events:","The main event types are:","APP_READY: the app is fully loaded and ready to use. It will auto-fire every time a new listener is attached after the app is ready.","MESSAGE_RECEIVED: the LLM message is generated and recorded into the chat object but not yet rendered in the UI.","MESSAGE_SENT: the message is sent by the user and recorded into the chat object but not yet rendered in the UI.","USER_MESSAGE_RENDERED: the message sent by a user is rendered in the UI.","CHARACTER_MESSAGE_RENDERED: the generated LLM message is rendered in the UI.","CHAT_CHANGED: the chat has been switched (e.g., switched to another character, or another chat was loaded).","GENERATION_AFTER_COMMANDS: the generation is about to start after processing slash commands.","GENERATION_STOPPED: the generation was stopped by the user.","GENERATION_ENDED: the generation has been completed or has errored out.","SETTINGS_UPDATED: the application settings have been updated.","The rest can be found in the source.","The way each event passes its data to the listener is not uniform. Some events don't emit any data; some pass an object or a primitive value. Please refer to the source code where the event is emitted to see what data it passes, or check with the debugger."]},{"l":"Emitting events","p":["You can produce any application events from extensions, including custom events, by calling eventSource.emit(eventType, ...eventData):"]},{"l":"Prompt Interceptors","p":["Prompt Interceptors provide a way for extensions to perform any activity such as modifying the chat data, adding injections, or aborting the generation before a text generation request is made.","Interceptors from different extensions are run sequentially. The order is determined by the loading_order field in their respective manifest.json files. Extensions with lower loading_order values run earlier. If loading_order is not specified, display_name is used as a fallback. If neither is specified, the order is undefined."]},{"l":"Registering an Interceptor","p":["To define a prompt interceptor, add a generate_interceptor field to your extension's manifest.json file. The value should be the name of a global function that will be called by SillyTavern."]},{"l":"Interceptor Function","p":["The generate_interceptor function is a global function that will be called upon generation requests that are not dry runs. It must be defined in the global scope (e.g., globalThis.myCustomInterceptorFunction = async function(...) { ... }) and can return a Promise if it needs to perform any asynchronous operations.","The interceptor function receives the following arguments:","chat: An array of message objects representing the chat history that will be used for prompt building. You can modify this array directly (e.g., add, remove, or alter messages). Please note that messages are mutable, so any changes you make to the array will be reflected in the actual chat history. If you want the changes to be ephemeral, use structuredClone to create a deep copy of the message object.","contextSize: A number indicating the current context size (in tokens) calculated for the upcoming generation.","abort: A function that, when called, will signal to prevent the text generation from proceeding. It accepts a boolean parameter that prevents any subsequent interceptors from running if true.","type: A string indicating the type or trigger of the generation (e.g., 'quiet', 'regenerate', 'impersonate', 'swipe', etc.). This helps the interceptor apply logic conditionally based on how the generation was initiated.","Example Implementation:"]},{"l":"Generating text","p":["SillyTavern provides several functions to generate text in different contexts using the currently chosen LLM API. These functions allow you to generate text in the context of a chat, raw generation without any context, or with structured outputs."]},{"l":"Within a chat context","p":["The generateQuietPrompt() function is used to generate text in the context of a chat with an added \"quiet\" prompt (post-history instruction) in the background (the output is not rendered in the UI). This is useful for generating text without interrupting the user experience while also keeping the relevant chat and character data intact, such as generating a summary or an image prompt."]},{"l":"Raw generation","p":["The generateRaw() function is used to generate text without any chat context. It is useful when you want to fully control the prompt-building process.","It accepts a prompt as a Text Completion string or an array of Chat Completion objects, constructing the request with an appropriate format depending on the selected API type, e.g., converting between chat/text modes, applying instruct formatting, etc. You can also pass an additional systemPrompt and a prefill to the function for even more control over the generation process."]},{"l":"Structured Outputs","p":["Currently only supported by the Chat Completion API. The availability varies based on the selected source and model. If the selected model does not support structured outputs, the generation will either fail or will return an empty object ('{}'). Check the documentation for the specific API you are using to see if structured outputs are supported.","You can use the structured outputs feature to ensure the model produces a valid JSON object that adheres to a provided JSON Schema. This is useful for extensions that require structured data, such as state tracking, data classification, etc.","To use structured outputs, you must pass a JSON schema object to generateRaw() or generateQuietPrompt(). The model will then generate a response that matches the schema, and it will be returned as a stringified JSON object.","The outputs are not validated against the schema, you must handle the parsing and validation of the generated output yourself. If the model fails to generate a valid JSON object, the function will return an empty object ('{}').","Zod is a popular library to generate and validate JSON schemas. Its use will not be covered here."]},{"l":"Registering custom macros","p":["You can register custom macros that can be used anywhere where macro substitutions are supported, e.g. in the character card fields, STscript commands, prompt templates, etc.","To register a macro, use the registerMacro() function from the SillyTavern.getContext() object. The function accepts a macro name that should be a unique string, and a string or a function that returns a string. The function will be called with a unique nonce string that will be different between each substituteParams call.","When a custom macro is no longer needed, remove it using the unregisterMacro() function:","Important details and known limitations regarding custom macros:","Currently only simple string replacement macros are supported. We're working on adding support for more complex macros in the future.","Macros that use functions to provide a value must be synchronous. Returning a Promise will not work.","You do not need to wrap the macro name in double curly braces ({{ }}) when registering it. SillyTavern will do that for you.","Since macros are plain regular expression substitutions, registering a lot of macros will cause performance issues, so use them sparingly."]},{"l":"Do Extras request","p":["The Extras API is deprecated. It's not recommended to use it in new extensions.","The doExtrasFetch() function allows you to make requests to your SillyTavern Extras API server.","For example, to call the /api/summarize endpoint:","getApiUrl() returns the base URL of the Extras server.","The doExtrasFetch() function:","Adds the Authorization and Bypass-Tunnel-Reminder headers","Handles fetching the result","Returns the result (the response object)","This makes it easy to call your Extras API from your extension.","You can specify:","The request method: GET, POST, etc.","Additional headers","The body for POST requests","Any other fetch options"]}],[{"l":"Server Plugins","p":["These plugins allow for adding functionality that is impossible to achieve using UI extensions alone, such as creating new API endpoints or using Node.JS packages that are unavailable in a browser environment.","Plugins are contained in the plugins directory of SillyTavern and are loaded on server startup, but only if enableServerPlugins is set to true in the config.yaml file.","Server Plugins are not sandboxed. This means they can potentially gain access to your entire file system, or introduce a wide range of security vulnerabilities in a way that normal UI extensions cannot. Only install server plugins from developers you trust!","For a list of all official server plugins, see the GitHub organization list: https://github.com/search?q=topic%3Aplugin+org%3ASillyTaverntype=Repositories"]},{"l":"Types of plugins"},{"l":"Files","p":["An executable JavaScript file with a \".js\" (for CommonJS modules) or \".mjs\" (for ES modules) extension containing a module that exports an init function. This function accepts an Express router (created specifically for your plugin) as an argument and returns a Promise.","The module should also export an info object containing information about the plugin ( id, name, and description strings). This will provide information about the plugin to the loader.","You can register routes via the router that will be registered under the /api/plugins/{id}/{route} path. For example, router.get('/foo') for the example plugin will produce a route like this: /api/plugins/example/foo.","A plugin can also optionally export an exit function that performs clean-up when shutting down the server. It should have no arguments and must return a Promise.","TypeScript contract for plugin exports:","See below for a \"Hello world!\" plugin example:"]},{"l":"Directories","p":["You can load a plugin from a subdirectory in the plugins directory in one of the following ways (in order of precedence):","A package.json file that contains a path to an executable file in the \"main\" field.","An index.js file for CommonJS modules.","An index.mjs file for ES modules.","A resulting file must export an init function and an info object with the same requirements as for individual files.","Example of a directory plugin (with an index.js file): https://github.com/SillyTavern/SillyTavern-DiscordRichPresence-Server"]},{"l":"Bundling","p":["It is preferable to use a bundler (such as Webpack or Browserify) that will package all the requirements into one file. Make sure to set \"Node\" as a build target.","Template repository for plugins using Webpack and TypeScript: https://github.com/SillyTavern/Plugin-WebpackTemplate"]}],[{"l":"Internationalization (i18n)","p":["SillyTavern supports multiple languages. This guide explains how to add and manage translations.","You're probably here because some piece of text is untranslated in your language, and it's driving you nuts. First I'll show you how I fixed some missing translations in the Chinese (Traditional) locale. Each was missing for a different reason, so you'll get a good idea of how to fix your own missing translations.","In the second half, we look at","how i18n works in SillyTavern,","writing translations and code to use them,","debug functions to find missing translations,","adding a new language,","and contributing your changes.","If you're developing an extension or modifying the core code, write your HTML and JavaScript with i18n in mind. This way your work is ready for other people to translate it into their language.","Nobody knows 15 languages by themselves. We work together to make SillyTavern accessible to everyone.","Everyone in the world should be able to use their own language on phones and computers."]},{"l":"Let's fix some missing translations!","p":["All 3 of these issues required code changes to fix. If you're adding a new translation, you might not need to touch the code at all. Just add the translation to the JSON file. It just so happens that somebody recently added a large number of missing translations to the Chinese (Traditional) JSON file, so the remaining issues were all in the code. In other locales there are plenty of missing translations you can fix without touching the code."]},{"l":"Generate Image","p":["... which we can add to the JSON file just after the \"Generate Image\" translation.","After some discussion with Claude, we're actually going to go with the following translations:","But while we have the HTML open, what's with Stop Image Generation just under it? The HTML doesn't look right.","First fix the HTML:","generate-image-lang.png","generate-image-post.png","generate-image-pre.png","If we generate an image and then open the wand menu while it's generating, we see untranslated text.","Japanese: \"Stop Image Generation\": \"画像生成を停止\"","Now it works! Reload the page and see.","Right-click on the element and inspect it. You'll see the HTML:","Simplified Chinese: \"Stop Image Generation\": \"中止图像生成\"","stop-generating-image-pre.png","stop-generating-post-2.png","The text \"Generate Image\" is untranslated in the Chinese (Traditional) locale. Why?","This isn't enough to fix the issue. There are no translations for \"Stop Image Generation\" in the Chinese (Traditional) file. We can add it! Here's one possible translation:","Traditional Chinese: \"Stop Image Generation\": \"終止圖片生成\"","We are in luck, that string Generate Image is in many of the language files, including in Chinese (Traditional).","Where is its data-i18n attribute? It's missing! Let's add it. We find it in the source code:","Why isn't it showing up? We have to wire the element up correctly:"]},{"l":"Generate Caption","p":["\"Generate Caption\" is untranslated in the Chinese (Traditional) locale. Let's fix it!","generate-image-post.png","Where is it? Inspect the element.","Turns out that this HTML is produced by JavaScript. Let's find the source code.","We will first have to fix the code:","There are also no translations for \"Generate Caption\" in the Chinese (Traditional) file. Let's add it!","We will use the following translations:","Traditional Chinese: \"Generate Caption\": \"生成圖片說明\"","Simplified Chinese: \"Generate Caption\": \"生成图片说明\"","Japanese: \"Generate Caption\": \"画像説明を生成\"","generate-caption-post.png"]},{"l":"Inspect Prompts","p":["The text \"Inspect Prompts\" is untranslated in the Chinese (Traditional) locale. Why? This one is a bit more complicated. The text is generated by JavaScript, and the translation is missing.","Well wouldn't you know it... neither phrase is in the i18n files. Let's add them.","Now we have to fix the JavaScript code. It has to use the t function to get the translation.","We got these suggestions from Claude. Keep the strings, ignore the code. They have to be added to the JSON files.","We will merge those into the JSON files.","toggle-prompt-inspection-post-tt.png","A pity about that tooltip. The problem is that the code doesn't use the t function.","We will have to fix that in the extension code.","We also need to add the translations to the JSON files.","Prompt inspector is a separate extension, so we will PR the code fixes to that repo: https://github.com/SillyTavern/Extension-PromptInspector/pull/1","The translations will be added to the main SillyTavern repo. https://github.com/SillyTavern/SillyTavern/pull/3198","start-inspecting-post.png"]},{"l":"Language files","p":["Each language has a JSON file in public/locales/ named with its language code (e.g., ru-ru.json).","The file contains key-value pairs where:","Keys are either the original English text or unique identifiers","Values are the translated text","Example:"]},{"l":"How translations work","p":["There are two ways translations are used in the application:","HTML Elements: Using data-i18n attributes","The default text in the HTML will be replaced with the translated text if available.","Template Strings: In the JavaScript code using the t function","These strings should be translated keeping the ${0}, ${1}, etc. placeholders intact.","SillyTavern uses HTML elements with data-i18n attributes to mark translatable content. There are several ways to use this:"]},{"l":"1. Translating Element Text","p":["For simple text content:","This replaces the element's text content with the translation of \"Role:\"."]},{"l":"2. Translating Attributes","p":["To translate an attribute like a title or placeholder:","The [title] prefix indicates which attribute to translate. The rest of the attribute value is the text that will be used as a lookup key in the JSON file. It is common for coders to use the English text as the key, but it is not required. The key can be any unique identifier.","The original English text must be present in the corresponding attribute ( title=Insert prompt) though. It's used as a fallback if the translation is missing. Most notably, there is no translation file for English.","Here is an example of using a unique identifier no_items_text as the key, rather than the English text:"]},{"l":"3. Multiple Translations Per Element","p":["Some elements need both content and attribute translations, separated by semicolons. The most common pattern is translating both the element's text content and its title attribute:","This translates:","The element's text content using the key \"Authorize\"","The title attribute using the key \"Get your OpenRouter API token using OAuth flow. You will be redirected to openrouter.ai\"","Note that both the title attribute and the element's text content are provided in English as fallbacks.","You can also translate multiple attributes:","The corresponding translations in your language file would look like:","When the page loads, the system:","Finds all elements with data-i18n attributes","Parses any attribute prefixes like [title] or [placeholder]","Looks up each key in your language's JSON file","Replaces the element's content or attributes with the translated text"]},{"l":"Dynamic Text","p":["For dynamic text in JavaScript code, translations use either:","Template literals with the t function:","Direct translation function:"]},{"l":"Variable Placeholders","p":["Some strings contain placeholders for dynamic values using ${0}, ${1}, etc:","Keep the placeholders the same for key and translation. The system will replace ${0} with the value of presetName, etc."]},{"l":"Finding missing translations","p":["Let's say you don't just want to fix one annoying missing translation, you want to find them all.","That's a big ambition! Even fixing one translation is worth it. But if you want to catch 'em all, you need a tool."]},{"l":"SillyTavern-i18n","p":["https://github.com/SillyTavern/SillyTavern-i18n","Tools for working with frontend localization files.","Features:","Automatically add new keys to translate from HTML files.","Prune missing keys from localization files.","Use automatic Google translation to auto-populate missing values.","Sort JSON files by keys."]},{"l":"Inbuilt debug functions","p":["These are under User Settings> Debug Menu."]},{"l":"Get missing translations","p":["Detects missing localization data in the current locale and dumps the data into the browser console. If the current locale is English, searches all other locales.","The console will show a table of missing translations with:","key: The text or identifier needing translation","language: Your current language code","value: The English text to translate"]},{"l":"Apply locale","p":["Reapplies the currently selected locale to the page","they don't catch missing translations in JavaScript code","they don't catch missing data-i18n attributes in HTML, they just catch untranslated keys","there are bugs in the code for getMissingTranslations: keys should not be prefixed with [title] or [placeholder]"]},{"l":"Adding a new language","p":["To add support for a new language:","Add your language to public/locales/lang.json:","Create public/locales/xx-xx.json with your translations"]},{"l":"Contributing","p":["When your translations are ready:","Verify your JSON file is valid","Test thoroughly in the application","Submit via GitHub pull request"]}],[{"l":"Administration","p":["Despite following many security best practices, the SillyTavern server is not secure enough for public internet exposure.","NEVER HOST ANY INSTANCES TO THE OPEN INTERNET WITHOUT ENSURING PROPER SECURITY MEASURES FIRST.","WE ARE NOT RESPONSIBLE FOR ANY DAMAGE OR LOSSES IN CASES OF UNAUTHORIZED ACCESS DUE TO IMPROPER OR INADEQUATE SECURITY IMPLEMENTATION.","config.yaml","The main configuration file for SillyTavern that contains various settings, such as the network settings, security settings, and backend-specific options.","Multi-user","To share your SillyTavern instance with others, you can create multiple user accounts. Each user has their own settings, extensions, and data. User accounts can also be password-protected.","Remote access","You can access your SillyTavern instance from your phone, tablet, or another computer.","VPNs and Tunneling","To access your SillyTavern instance from the internet, you can use a VPN or a tunneling service like Cloudflare Zero Trust, ngrok, or Tailscale.","Reverse proxying","For enthusiasts, you can set up a reverse proxy to access your SillyTavern instance from the internet."]},{"l":"Security checklist","p":["This is just a recommendation. Please consult a web application security specialist before making your ST instance live.","Keep your operating system and runtime software like Node.js updated. This will ensure that your system is up-to-date with the latest security patches and fixes which can help prevent potential vulnerabilities.","Use a whitelist and a network firewall. Only allow trusted IP ranges to access the server.","Enable basic authentication. It acts as a \"master password\" before you can proceed to the front-end app.","Alternatively, configure external authentication. Some known services for that are Authelia and authentik. See more in the SSO guide.","Never leave admin accounts passwordless. A server will warn you upon the startup if you have any unprotected admin accounts.","Use the discreet login setting outside of the local network. This will hide the user list from any potential outsiders.","Check the access logs often. They are written to the server console and the access.log file and provide information on incoming connections, such as IP address and user agent.","Configure HTTPS. For a localhost server, you can generate and use a self-signed certificate. Otherwise, you may need to deploy a proxying web server like Traefik or Caddy.","Find more on secure proxying in the following guide: Reverse Proxying SillyTavern."]}],[{"l":"Configuration File","p":["This documentation may be obsolete, incomplete, or incorrect. Please refer to the default config.yaml in your installation for the most up-to-date list of settings.","WARNING: DO NOT EDIT THE DEFAULT CONFIG DIRECTLY. THIS WON'T HAVE ANY POSITIVE EFFECT. EDIT ITS COPY IN THE REPOSITORY ROOT INSTEAD.","config.yaml is the main configuration file for the SillyTavern server that you can find in the repository root directory after completing the installation. It is a YAML file that contains various settings, such as the network settings, security settings, and backend-specific options. The changes made to this file will take effect after restarting the server.","New settings that added to the upstream version will be automatically populated with the default values when you run npm install(or specifically, the post-install.js script) after updating the repository. You can then modify these settings as needed.","For nested settings, dot notation is used to indicate the hierarchy. For example, protocol.ipv6: false refers to the ipv6 setting under the protocol section with a value of false."]},{"l":"Command-Line Arguments","p":["You can pass command-line arguments to SillyTavern server startup to override some settings in config.yaml."]},{"l":"Examples"},{"l":"Supported arguments","p":["--basicAuthMode","--browserLaunchAvoidLocalhost","--browserLaunchEnabled","--browserLaunchHostname","--browserLaunchPort","--certPath","--configPath","--corsProxy","--dataRoot","--disableCsrf","--dnsPreferIPv6","--enableIPv4","--enableIPv6","--global","--keyPath","--listen","--listenAddressIPv4","--listenAddressIPv6","--port","--requestProxyBypass","--requestProxyEnabled","--requestProxyUrl","--ssl","--version","--whitelist","array","Automatically launches SillyTavern in the browser","Avoids using 'localhost' for browser launch in auto mode","boolean","Description","Disables CSRF protection (NOT RECOMMENDED)","Enables basic authentication","Enables SSL","Enables the CORS proxy","Enables the IPv4 protocol","Enables the IPv6 protocol","Enables the use of a proxy for outgoing requests","Enables whitelist mode","Forces the use of system-wide paths for application data","Makes SillyTavern listen on all network interfaces","None of the arguments are required. If you don't provide them, SillyTavern will use the settings in config.yaml.","number","Option","Overrides the path to the config.yaml file (standalone mode only)","Overrides the port for browser launch","Prefers IPv6 for DNS","Sets the browser launch hostname","Sets the path to your certificate file","Sets the path to your private key file","Sets the port under which SillyTavern will run","Sets the request proxy bypass list (space-separated list of hosts)","Sets the request proxy URL (HTTP or SOCKS protocols)","Sets the root directory for data storage (standalone mode only)","Shows the version number","Specifies the IPv4 address to listen on","Specifies the IPv6 address to listen on","string","Type"]},{"l":"Environment Variables","p":["Configuration may also be set via environment variables which will override the values in the config.yaml file.","The environment variables should be prefixed with SILLYTAVERN_ and use uppercase letters for the setting names. For example, the dataRoot setting can be overridden with the SILLYTAVERN_DATAROOT environment variable.","The nested settings should be separated by underscores. For example, protocol.ipv6 can be overridden with the SILLYTAVERN_PROTOCOL_IPV6 environment variable.","Configurations that expect arrays or objects should be JSON-stringified. For example, to override the whitelist setting with the SILLYTAVERN_WHITELIST environment variable, you should set it as a JSON string: SILLYTAVERN_WHITELIST='[127.0.0.1, ::1]'.","If using Node.js >= 20, you can also store the environment variables in a .env file and pass it to the server using the --env-file flag. For example, to use the .env file located in the repository root, you can start the server with the following command:","Alternatively, pass the environment variables directly via the command line:","See more on using environment variables in the Node.js documentation."]},{"l":"Data Configuration","p":["./data","Any valid directory path","dataRoot","Default","Description","Enable on-demand tokenizer downloads","enableDownloadableTokenizers","false","Permitted Values","Root directory for user data storage (standalone mode only)","Setting","Skip new default content checks","skipContentCheck","true","true, false"]},{"l":"Logging Configuration","p":["Setting","Description","Default","Permitted Values","logging.minLogLevel","Minimum log level to display in the terminal","0(DEBUG)","(DEBUG = 0, INFO = 1, WARN = 2, ERROR = 3)","logging.enableAccessLog","Write server access log to file and console","true","true, false"]},{"l":"Network Configuration","p":["'[::]'","0.0.0.0","8000","Any valid port number (1-65535)","Default","Description","dnsPreferIPv6","Enable listening for incoming connections","Enable listening on IPv4 protocol","Enable listening on IPv6 protocol","false","listen","Listen on specific IPv4 address","Listen on specific IPv6 address","listenAddress.ipv4","listenAddress.ipv6","Permitted Values","port","Prefer IPv6 for DNS resolution","protocol.ipv4","protocol.ipv6","Server listening port","Setting","true","true, false","true, false, auto","Valid IPv4 address","Valid IPv6 address"]},{"l":"SSL Configuration","p":["./certs/cert.pem","./certs/privkey.pem","Default","Description","Enable SSL/TLS","false","Path to SSL certificate","Path to SSL private key","Permitted Values","Setting","ssl.certPath","ssl.enabled","ssl.keyPath","true, false","Valid file path"]},{"l":"Security Configuration","p":["[::1, 127.0.0.1]","Allow API keys exposure in the UI","allowKeysExposure","Array of valid IP addresses","Automatically whitelist Docker host IPs","Check forwarded headers for whitelisted IPs","Default","Description","Disable CSRF protection (not recommended)","Disable startup security checks (not recommended)","disableCsrfProtection","Enable CORS proxy middleware","Enable IP whitelist filtering","enableCorsProxy","enableForwardedWhitelist","false","List of allowed IP addresses","Permitted Values","securityOverride","Setting","true","true, false","whitelist","whitelistDockerHosts","whitelistMode"]},{"l":"User Authentication","p":["-1(disabled)","Any number (-1 to disable, 0 for browser close, >0 for timeout)","Any string","autheliaAuth","Basic auth password","Basic auth username","basicAuthMode","basicAuthUser.password","basicAuthUser.username","Default","Description","Enable Authelia-based auto login. See: SSO","Enable basic authentication","Enable multi-user mode","enableDiscreetLogin","enableUserAccounts","false","Hide user list on login screen","password","Permitted Values","perUserBasicAuth","sessionTimeout","Setting","true, false","Use account credentials for basic auth","user","User session timeout in seconds"]},{"l":"Rate Limiting Configuration","p":["Setting","Description","Default","Permitted Values","rateLimiting.preferRealIpHeader","Use X-Real-IP header instead of socket IP for rate limiting","false","true, false"]},{"l":"Request Proxy Configuration","p":["[localhost, 127.0.0.1]","Array of hostnames/IPs","Default","Description","Enable proxy for outgoing requests","false","Hosts to bypass proxy","null","Permitted Values","Proxy server URL","requestProxy.bypass","requestProxy.enabled","requestProxy.url","Setting","true, false","Valid proxy URL (e.g., socks5://username:password@example.com:1080)"]},{"l":"Browser Launch Configuration","p":["-1","-1(use server port), any valid port number","auto","auto, any valid hostname (e.g., localhost, st.example.com)","Avoid using 'localhost' in a launch URL","Browser to use for opening the URL","browserLaunch.avoidLocalhost","browserLaunch.browser","browserLaunch.enabled","browserLaunch.hostname","browserLaunch.port","Default","default, chrome, firefox, edge, brave","Description","false","Open the browser automatically on server startup","Override the hostname for browser launch","Override the port for browser launch","Permitted Values","Previously known as \"Autorun\" settings.","Setting","true","true, false"]},{"l":"Performance Configuration","p":["Setting","Description","Default","Permitted Values","performance.lazyLoadCharacters","Lazy-load character data","true","true, false","performance.useDiskCache","Enables disk caching for character cards","performance.memoryCacheCapacity","Maximum memory cache capacity","100mb","Human-readable size (e.g., 100mb, 1gb)"]},{"l":"Cache Buster Configuration","p":["Requires localhost or a domain with HTTPS, otherwise will not work!","Setting","Description","Default","Permitted Values","cacheBuster.enabled","Clear browser cache on first load or after uploading image files","false","true, false","cacheBuster.userAgentPattern","Only clear cache for the specified user agent regex pattern. Example: 'firefox'(case-insensitive)","''","Any valid regex string"]},{"l":"Thumbnailing Configuration","p":["[160, 90]","[96, 144]","0-100","95","Array of two numbers (width, height)","Avatar thumbnails size","Background thumbnails size","Default","Description","Enable thumbnail generation","Image format for thumbnails","JPEG thumbnail quality","jpg","jpg, png","Permitted Values","Persona thumbnails size","Setting","thumbnails.dimensions.avatar","thumbnails.dimensions.bg","thumbnails.dimensions.persona","thumbnails.enabled","thumbnails.format","thumbnails.quality","true","true, false"]},{"l":"Backup Configuration","p":["-1","10000","50","Any positive integer","Any positive integer or -1","Backup throttle interval (ms)","backups.chat.checkIntegrity","backups.chat.enabled","backups.chat.maxTotalBackups","backups.chat.throttleInterval","backups.common.numberOfBackups","Default","Description","Enable automatic chat backups","Maximum total chat backups to keep","Number of backups to keep","Permitted Values","Setting","true","true, false","Verify integrity of chat files before saving"]},{"l":"Extensions Configuration","p":["Auto-update extensions (if enabled by the extension manifest)","Cohee/distilbert-base-uncased-go-emotions-onnx","Cohee/jina-embeddings-v2-base-en","Default","Description","Enable automatic model downloads","Enable UI extensions","extensions.autoUpdate","extensions.enabled","extensions.models.autoDownload","extensions.models.captioning","extensions.models.classification","extensions.models.embedding","extensions.models.speechToText","extensions.models.textToSpeech","HuggingFace model ID for classification","HuggingFace model ID for embeddings","HuggingFace model ID for image captioning","HuggingFace model ID for speech-to-text","HuggingFace model ID for text-to-speech","Permitted Values","Setting","true","true, false","Valid model ID","Xenova/speecht5_tts","Xenova/vit-gpt2-image-captioning","Xenova/whisper-small"]},{"l":"Server Plugins","p":["Setting","Description","Default","Permitted Values","enableServerPlugins","Enable server-side plugins","false","true, false","enableServerPluginsAutoUpdate","Attempt to automatically update server plugins on startup","true"]},{"l":"API Integration Settings"},{"l":"OpenAI Configuration","p":["Setting","Description","Default","Permitted Values","promptPlaceholder","Default message for empty prompts","[Start a new chat]","Any string","openai.randomizeUserId","Randomize user ID for API calls","false","true, false","openai.captionSystemPrompt","System message for caption completion"]},{"l":"MistralAI Configuration","p":["Setting","Description","Default","Permitted Values","mistral.enablePrefix","Enable reply prefilling. The prefix will be echoed in the response","false","true, false"]},{"l":"Ollama Configuration","p":["Setting","Description","Default","Permitted Values","ollama.keepAlive","Model keep-alive duration (seconds)","-1","-1(indefinite), 0(immediate unload), positive integer","ollama.batchSize","Controls the \"num_batch\" (batch size) parameter of the generation request","-1(model default), positive integer"]},{"l":"Claude Configuration","p":["-1","-1(disabled), 0 or positive integer","claude.cachingAtDepth","claude.enableSystemPromptCache","claude.extendedTTL","Default","Description","Enable message history caching","Enable system prompt caching","false","Permitted Values","See: Prompt Caching","Setting","true, false","Use 1h TTL instead of the default 5m. Note that this also increases the cost of the request.","Use with caution and only when the prompt prefix is static and doesn't change between requests. {{random}} macro, lorebooks, vectors, summaries, etc. will likely invalidate the cache and you'll just waste money on cache misses. Behavior may be unpredictable and no guarantees can or will be made."]},{"l":"Google AI Studio Configuration","p":["Setting","Description","Default","Permitted Values","gemini.apiVersion","API endpoint version","v1beta","v1beta, v1alpha"]},{"l":"DeepL Configuration","p":["Setting","Description","Default","Permitted Values","deepl.formality","Translation formality level","default, more, less, prefer_more, prefer_less"]}],[{"l":"Multi-user mode","p":["Multi-user mode allows several people to use one SillyTavern server. Each user has their own settings, extensions, and data. User accounts can also be password-protected.","User passwords provide basic privacy between users of a multi-user setup. They are not a security feature and should not be considered as such. All user data (including chat history, API keys, and other sensitive information) is stored in plain text on the server. It can be viewed and modified by anyone with access to the server's filesystem. Do not use SillyTavern on a public server or with untrusted users."]},{"l":"Configuration","p":["To enable and use the multi-user mode, edit the config.yaml file:","When the user account setting is disabled, a default-user fallback admin account is utilized for storing the user data.","When the discreet login setting is disabled, a list of active users is displayed on the login screen. If enabled, a user must enter their handle manually.","You can't delete the default-user account from the users list because it is used for serving the user data in case if enableUserAccounts is set to false. But you can disable it to hide it from the list and disallow logins."]},{"l":"User handles","p":["A handle is the unique identifier of a user. It can consist only of lowercase letters, numbers, and dashes.","A path to the user data directory assumes using the following pattern: %DATA_ROOT%/%USER_HANDLE%.","Examples of valid user handles:","default-user","juan555","flux-the-cat","cool-guy1337"]},{"l":"Roles","p":["Admin- can manage (create, delete, modify) other users. Can install extensions for all users.","User- can't manage other users. Can install extensions only for themselves.","Except for having admin panel access, both user roles are functionally identical and can use a full range of SillyTavern features without any restrictions. An implementation of user permissions is TBD.","All user accounts are created as regular users first, and then could be promoted to admins if needed."]},{"l":"Login screen","p":["There you can select a user account to use. Has two styles, depending on the enableDiscreetLogin config value.","The login screen is bypassed and not displayed when you have only one active user and it is not password protected."]},{"l":"User profile","p":["You can access an account self-management menu using an \"Account\" button under the \"User settings\" panel in the top menu bar.","Display name - used in the login screen, can be changed. Does not correlate with personas and is not visible for the AI APIs - you can still use as many personas as you want.","Profile picture - used in the login screen. You can either use a custom picture, the default persona picture (if set), or the last used persona otherwise.","Password - a lock icon reflects the account protection status (open lock = no password). A password can be set, changed, or removed using the \"Change Password\" button.","Settings Snapshots - access and review the backups of your settings.json file, with the ability to create or restore snapshots.","Download Backup - download an archive of your user data folder.","Reset Settings - reset factory default settings, while leaving other data (character, chats) intact."]},{"l":"Password recovery","p":["A password can be recovered from a login screen. You need access to the server console to get a one-time recovery code (consisting of 4 digits).","Alternatively, you can use a utility script in the SillyTavern server to reset a password by providing the user handle."]},{"l":"Content scaffolding","p":["To add custom content for users, you can use the content scaffolding feature. This feature allows you to define a set of files that will be copied to each user's data directory when the server starts up.","You must create an index.json file in the /default/scaffold directory for this feature to work. The syntax is the same as for default content. All file paths should be relative to the /default/scaffold directory, and you can organize files using subdirectories.","Scaffolded files are copied before default files, which means they will override any default files (presets/settings/etc.) that have the same file name.","Every user data directory has a content.log file that lists all files copied from the scaffold and default directories. Remove this file to force the server to sync the content again on the next restart."]},{"l":"Recognized content types","p":["'avatar'","'background'","'character'","'context'","'instruct'","'kobold_preset'","'moving_ui'","'novel_preset'","'openai_preset'","'quick_replies'","'reasoning'","'settings'","'sprites'","'sysprompt'","'textgen_preset'","'theme'","'workflow'","'world'","Background image","Character card","Character sprites","Chat Completion preset","ComfyUI workflow","Context Formatting template","Instruct Mode template","KoboldAI Classic preset","MovingUI preset","NovelAI preset","Persona avatar","Quick Replies set","Reasoning Formatting template","settings.json","System Prompt template","Text Completion preset","Type","UI theme","Value","World Info file"]},{"l":"Example (/default/scaffold/index.json)"}],[{"l":"Single Sign-On (SSO)","p":["SSO allows you to create users and secure many different pages using a login portal presented on sites you want to secure. While it is complex to setup, it is a good way to both learn SSO and secure your ST instance out on the internet more.","Authelia and Authentik are open-source SSO providers that can be used with SillyTavern."]},{"l":"Sign in with SSO","p":["If your SSO-provided username exactly matches the username of a SillyTavern user account, you can sign in to SillyTavern as that user by SSO.","To do this, enable autheliaAuth in config.yaml.","This augments or replaces the built-in password management component of a multi-user mode setup."]},{"l":"Replacing HTTP BA","p":["SSO can also replace HTTP Basic Authentication as an access control mechanism for remote connections.","This is recommended because SSO provides better security and functionality than HTTP BA.","To use an SSO provider in place of HTTP BA, enable securityOverride in config.yaml. Otherwise, SillyTavern will refuse to start."]}],[{"l":"Remote connections","p":["Most often this is for people who want to use SillyTavern on their mobile phones while their PC runs the ST server within the same WiFi network.","It is also the first step for allowing remote connections from outside the local network.","You should not use port forwarding to expose your ST server to the internet. Instead, use a VPN or a tunneling service like Cloudflare Zero Trust, ngrok, or Tailscale. See the VPN and Tunneling guide for more information.","NEVER HOST ANY INSTANCES TO THE OPEN INTERNET WITHOUT ENSURING PROPER SECURITY MEASURES FIRST.","WE ARE NOT RESPONSIBLE FOR ANY DAMAGE OR LOSSES IN CASES OF UNAUTHORIZED ACCESS DUE TO IMPROPER OR INADEQUATE SECURITY IMPLEMENTATION."]},{"l":"Allowing remote connections","p":["By default, the ST server only accepts connections from the machine that it's running on (localhost). To allow it to listen for connections from other devices, set the listen option in config.yaml to true.","All modifications to config.yaml in this document refer to the one in the SillyTavern root directory (/SillyTavern/config.yaml), not /SillyTavern/default/config.yaml.","When ST is listening for remote connections, you should see this message in the console:","and some explanation about what that means.","When ST is not listening for remote connections, you should see this message in the console:"]},{"l":"Access control configuration","p":["After enabling remote connection listening, you must configure at least one access control method. Otherwise, the server will not start."]},{"l":"Whitelist-Based access control","p":["To enable access control via a whitelist, edit the config.yaml file in the SillyTavern root directory (/SillyTavern/config.yaml):","Start SillyTavern at least once to generate the necessary configuration files.","Open /SillyTavern/config.yaml in a text editor.","Find the whitelist section and add the IP addresses you wish to allow:","List each IP address separately.","Ensure 127.0.0.1 is included, or you will be unable to connect from the host machine.","Supports individual IPs, CIDR masks (e.g., 10.0.0.0/24), and wildcard (*) ranges.","Save the config.yaml file.","Restart your SillyTavern server."]},{"l":"Example config.yaml whitelist configuration","p":["Allow any device on the local network:","If unsure about your local network's address range, use the whitelist above.","Allows two specific devices to connect:","Allows any device on the 192.168.0.* subnet to connect:","Allow network connections for all IPv4 devices:"]},{"l":"Disabling whitelist-based access control","p":["To disable access control via a whitelist:","Set whitelistMode to false in /SillyTavern/config.yaml.","Remove or rename whitelist.txt(if it exists) in the SillyTavern base installation folder.","Restart your SillyTavern server."]},{"l":"Not recommended: using whitelist.txt","p":["If whitelist.txt exists, it takes precedence over the whitelist settings in config.yaml.","However, since all other configurations are managed within config.yaml, and whitelist.txt may encounter permission issues or become locked, the system could silently revert to using the config.yaml whitelist.","Editing config.yaml directly is both simpler and more reliable.","If you still prefer using whitelist.txt:","Create a new text file named whitelist.txt in the SillyTavern base installation folder.","Open it in a text editor and add the allowed IP addresses.","Save the file and restart your SillyTavern server."]},{"l":"Example whitelist.txt configuration","p":["This allows any device on the local network to connect."]},{"l":"Access control by HTTP Basic Authentication","p":["HTTP Basic Authentication does not provide strong security.","There is no rate-limiting to prevent brute-force attacks. If this is a concern, it is recommended to use a reverse proxy with TLS and rate-limiting, and a dedicated authentication service.","The server will ask for username and password whenever a client connects via HTTP. This only works if the Remote connections (listen: true) are enabled.","To enable HTTP BA, Open config.yaml in the SillyTavern base directory and search for basicAuthMode Set basicAuthMode to true and set username and password. Note: config.yaml will only exist if ST has been executed before at least once.","Alternatively you can enable basic auth as follows:","In this perUserBasicAuth mode the basic auth's username and password will be the same as any valid multi user account that has a password. Additionally SillyTavern will login directly to that account. Ensure you have an account with a password prior to enabling perUserBasicAuth.","Save the file and restart SillyTavern if it was already running. You should be prompted for username and password when connecting to your ST. Both username and password are transmitted in plain text. If you are concerned about this, you can serve ST via HTTPS."]},{"l":"Connecting to your SillyTavern instance"},{"l":"Getting the IP address for the ST host machine","p":["After the whitelist has been setup, you'll need the IP of the ST-hosting device.","If the ST-hosting device is on the same wifi network, you will use the ST-host's internal wifi IP:","For Windows: windows button > type cmd.exe in the search bar > type ipconfig in the console, hit Enter > look for IPv4 listing.","If you (or someone else) wants to connect to your hosted ST while not being on the same network, you will need the public IP of your ST-hosting device.","While using the ST-hosting device, access this page and look for for IPv4. This is what you would use to connect from the remote device."]},{"l":"Connecting to the ST server","p":["Whatever IP you ended up with for your situation, you will put that IP address and port number into the remote device's web browser.","A typical address for an ST host on the same wifi network would look like:","http://192.168.0.5:8000","Use http:// NOT https://"]},{"l":"Connection logging","p":["New connections to the server are displayed in the console window and logged in the access.log file in the SillyTavern base directory.","A console message for a browser on the same machine as the server looks like:","A console message for a browser on a different machine on the same network as the server might look like:","If a connection is refused, the console message will look like:","access.log will contain the connection information, with timestamps, but not whether the connection was accepted or refused."]},{"l":"Troubleshooting","p":["Still unable to connect?","If the connection attempt appears in the console, but is forbidden, it is a whitelist issue.","If ST is listening for remote connections but the connection attempt does not appear in the console, it is a network issue.","If ST is not listening for remote connections, it is a reading issue."]},{"l":"Network issues","p":["On Windows, the application may be blocked by the application firewall. The quickest way to fix this is to uninstall and reinstall node.js, and when prompted by the firewall, allow it to access the network. Otherwise, you will need to manually allow the node.js application through the Windows application firewall.","On Windows 11, enable the Private Network profile type in Settings > Network and Internet > Ethernet. This is VERY important for Windows 11, otherwise, you would be unable to connect even with the aforementioned firewall rules.","On Linux, you may need to allow the port through the firewall. The command to do this is sudo ufw allow 8000. This will allow traffic on port 8000.","Do not modify the port forwarding settings on your router. This is not necessary for accessing ST within your local network, and can expose your server to the internet.","If you are trying to access your ST server from outside your local network, and it's not working, identify whether the problem is between the remote device and the tunnel/VPN endpoint, or between the tunnel endpoint on the server and the ST service. Otherwise you will spend a lot of time troubleshooting the wrong thing."]},{"l":"HTTPS"},{"l":"Start SillyTavern with TLS/SSL","p":["To encrypt traffic from and to your ST instance, start the server with the --ssl flag.","Example:","As per default, ST will search for your certificates inside the certs folder. If your files are located elsewhere, you can use the --keyPath and --certPath arguments.","The user you're running SillyTavern with requires read permissions on the certificate files."]},{"l":"How to get a certificate","p":["The simplest, quickest way to get a certificate is by using certbot."]}],[{"l":"VPNs and Tunneling","p":["VPNs and tunnels are a secure way to access your home network from anywhere in the world. This guide will show you how to use a VPN or a tunnel to access your SillyTavern instance from anywhere."]},{"l":"Methods","p":["Use a home-made VPN.","Several routers come with the ability to host a VPN server (primarily OpenVPN or WireGuard) in the router administration page. Refer to your router's manual to setup a VPN and add your devices to the VPN. Once connected, just go to the private IP you have set for SillyTavern and you can connect just fine. Easier for users and for Windows use.","Use Cloudflare Zero Trust.","Cloudflare Zero Trust is a free organizational feature in Cloudflare that allows you to add 50 users. This will proxy your traffic through Cloudflare and by adding your ST PC as a tunnel using cloudflared, you can connect to your ST instance as if you were home.","Do note that after making a tunnel, you will have to add a route to your router's private IP addresses and calculate IP CIDR values to have full local access on the go using Cloudflare Zero Trust.","Use a standalone Cloudflare or ngrok tunnel.","Similar to how AI backends can connect, you can also connect your ST instance via a Cloudflare Tunnel and open the Cloudflare Tunnel page. However, you will have to copy and paste each new link generated by Cloudflare/NGROK each time you want to use ST on-the-go.","Use Tailscale.","Tailscale is a VPN provider enabling a secure remote connection to your PC."]},{"l":"Tailscale setup","p":["Tailscale is a VPN provider enabling a secure remote connection to your PC. An open-source implementation of the Tailscale server exists and you can also host the server using Headscale, but that is outside of the scope of this tutorial."]},{"l":"1. Creating an account","p":["Go to Tailscale's website and create a new account.","NOTE: For everyday use by a single person Tailscale will be permanently free. If you fear hidden costs, just don't add any payment options."]},{"l":"2. Setting up clients","p":["Go to Tailscale's download page and download the client/app on the device you have SillyTavern running on and on the device you want to use from a remote location.","Log in on both devices with your previously created account.","Go to Tailscale's admin page and approve both devices.","Take note of both of the connected devices' names."]},{"l":"3. Adding your devices to the whitelist","p":["Add your connecting device's machine name (the one you want to use SillyTavern with) to SillyTavern's whitelist by following Managing whitelisted IPs."]},{"l":"4. Connecting","p":["Now whenever you want to use SillyTavern from anywhere all you have to do is:","Have Tailscale turned on on both the PC hosting SillyTavern and your device that wants to use it remotely.","Open a browser on the device that wants to connect and go to http://machine name of PC running st:8000/"]},{"l":"5. Sharing SillyTavern instance with a friend (optional)","p":["Tell your friend to create their own Tailscale account and download the client on their device.","Go to Tailscale's admin page.","Hover over the three-dot button on your PC hosting SillyTavern and press \"Share...\" or press the three-dot button and press \"Sharing settings...\".","Uncheck \"Allow use as an exit node\" (unless you want your friend to be able to route all their internet traffic through your PC).","Either send the link as an email or change the tab to \"Copy share link\", press the big blue button with the same text, and send it to your friend in any other way.","After clicking your share link, your friend will see your PC pop up in their Tailscale network.","Send your friend the same link you use to access SillyTavern as explained in the last step.","NOTE: This will give your friend full access to any services running locally on your PC like SillyTavern, automatic1111, etc. Only do this if you truly trust your friend."]}],[{"l":"Reverse proxying","p":["This section does not refer to OpenAI/Claude reverse proxies. This refers exclusively to HTTP/HTTPS Reverse Proxies.","Is Termux confusing to setup? Are you tired of updating and installing ST on every device you have? Want organization of your chats and characters? Well you are in luck. This guide will hopefully cover how to host SillyTavern on your PC where you can connect from anywhere and chat to your bots on the same PC you use to run AI models!","This guide is not meant for beginners. This will be very technical."]},{"l":"Fair Warning","p":["This guide is not for Windows users. We recommend using a Linux VM or WSL2 to follow this guide.","You must have prior knowledge of","Linux console commands","DNS Records","Public IP addresses","Docker","You will have to buy a domain for yourself and configure a CNAME for your SillyTavern page. We suggest adding or buying the domain on Cloudflare as this guide will cover how to do this with Cloudflare itself."]},{"l":"Installation"},{"l":"Linux (Bare-Metal SillyTavern)","p":["A","Auto","Before enabling perUserBasicAuth ensure you have a valid multi-user setup with working passwords.","cd into appdata/traefik and using nano or a similar editor, create a file name config.yml and paste the following. Replace PRIVATE_IP with the private IP you obtained, and silly.DOMAIN.com with the name of your subdomain and domain page, then save the file.","cd into secrets/cloudflare and using nano or a similar editor, create a file named CF_DNS_API_KEY and paste your key inside.","Click on Continue to summary followed by Create Token.","Click on Create Token then Create Custom Token and make sure you give your token the following permissions.","CNAME","Copy the Token Key given to you and store it somewhere secure.","Create a acme.json file using touch and set the permissions of it to 600.","Create another record of the CNAME type, then click Save. Here is an example on how it should appear on the Cloudflare dashboard.","Do not install Docker Desktop.","DOMAIN.com","Enjoy! :D","Execute chown, replacing with your Linux username to set the permissions in the docker folder.","Follow the steps in Manage Docker as a non-root user in the Docker post-installation guide here.","For Linux, we will reverse proxying SillyTavern through Traefik. There are other options such as NGINX or Caddy, but for this guide, we will use Traefik as it is what we use ourselves.","Get the private IP of your computer using ifconfig or from your router.","Get your public IP of your modem by Googling what's my ip.","Go to your root folder in Linux and make a new folder named docker.","Go to your SillyTavern folder and edit config.yaml to enable listen mode and basic authentication, whilst disabling whitelistMode.","If nothing happens after several minutes, check the container logs for Traefik for any possible errors.","Install Docker by following the Docker installation guide here.","It is recommended to set your private IP to a Static IP. Refer to your router's manual or Google to configure static IPs.","Login to Cloudflare and click on your Domain, followed by Get your API token.","Make a folder inside the docker folder, that being appdata and inside appdata being traefik. Enter the appdata/traefik folder afterwards.","Make a folder inside the docker folder, that being secrets and inside secrets being cloudflare.","Make sure to change the default username and password to something strong that you can remember.","Most residential/home networks use Dynamic IPs which are renewed after months of use. If you have a dynamic IP, use either DDClient or remember to check and change your public IP ever so often on the Cloudflare Dashboard.","N/A","Name (required)","Or to use the SillyTavern accounts as usernames and passwords:","Proxied","Proxy Status","PUBLIC_IP","Return back to the docker folder.","Return to your domain page and go to DNS. Create a new record using Add record and create two A type keys like the ones below. Replace PUBLIC_IP with your own public IP, then click Save.","Run Docker Compose using the following commands:","silly","Target (required)","TTL","Type","Using nano or a similar editor, create a file name docker-compose.yaml and paste the following. Save the file afterwards.","Using nano or a similar editor, create a file name traefik.yml and paste the following. Replace the template email with your own, then save the file.","Wait a few minutes, then open your domain page you made for ST. At the end of it, you should be able to open SillyTavern from anywhere you go just with one URL and one account.","www","Zone -> DNS -> Edit","Zone -> Zone -> Read"]},{"l":"Linux (Docker SillyTavern)","p":["A","Auto","cd into secrets/cloudflare and using nano or a similar editor, create a file named CF_DNS_API_KEY and paste your key inside.","Click on Continue to summary followed by Create Token.","Click on Create Token then Create Custom Token and make sure you give your token the following permissions.","CNAME","Copy the Token Key given to you and store it somewhere secure.","Create another record of the CNAME type, then click Save. Here is an example on how it should appear on the Cloudflare dashboard.","Do note that we run SillyTavern on bare-metal over Docker. This is a rough idea of what we would do on Docker with other Docker containers we tend to use with ST.","DOMAIN.com","Enjoy! :D","Follow Steps 1-11 of Linux (Bare-Metal SillyTavern).","Git clone SillyTavern into the docker folder.","Go to your SillyTavern folder ( appdata/sillytavern/config) and edit config.yaml to enable listen mode and basic authentication, whilst disabling whitelistMode.","If nothing happens after several minutes, check the container logs for Traefik for any possible errors.","Login to Cloudflare and click on your Domain, followed by Get your API token.","Make sure to change the default username and password to something strong that you can remember.","N/A","Name (required)","Proxied","Proxy Status","PUBLIC_IP","Return to your domain page and go to DNS. Create a new record using Add record and create two A type keys like the ones below. Replace PUBLIC_IP with your own public IP and the example domain with your domain, then click Save.","Run Docker Compose using the following commands:","silly","Start the SillyTavern Docker container again.","Stop the SillyTavern Docker container.","Target (required)","TTL","Type","Using nano or a similar editor, create a file name docker-compose.yaml and paste the following. Replace silly.DOMAIN.com with the subdomain you added above, the save the file afterwards.","Wait a few minutes, then open your domain page you made for ST. At the end of it, you should be able to open SillyTavern from anywhere you go just with one URL and one account.","www","Zone -> DNS -> Edit","Zone -> Zone -> Read"]},{"l":"Updating your Cloudflare DNS","p":["DDClient allows you to sync your public IP to Cloudflare in the situation that your ISP changes it, allowing you to continue accessing your ST instance as if nothing ever happened."]}],[{"l":"License and credits","p":["This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.","See the GNU Affero General Public License for more details.","Original TavernAI 1.2.8 by Humi: MIT License"]},{"l":"Pre-v1.9.0 Contributors","p":["The git commit history was squashed to the state of release 1.9.0.","Unfortunately, losing commit history also means losing the code contribution history. If you contributed to the SillyTavern development and want to see yourself credited in the README file and Docs website, please get in touch with us!"]},{"l":"Documentation Contributors","p":["Click the image below to see the full list of SillyTavern documentation contributors.","Contributors"]}]]